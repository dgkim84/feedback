[{"name":"Android에서 @Inject, @Test","published":1366076777,"description":"<div><p>NHN Business Platform 웹플랫폼개발랩 정상혁</p>\n<p>&#64;Inject와 &#64;Test는 최근 Java 프로그래밍의 경향을 함축하는 상징입니다. &#64;Inject는 javax.inject.Inject&#39; 애노테이션을 가리키기도 하지만, 이 글의 맥락에서는 &#64;Autowire, &#64;Resource 등 의존 관계 주입(dependency injection)을 표시하는 애노테이션의 대표라고 이해해 주었으면 합니다. &#64;Test는 JUnit4 &#39;org.junit.Test&#39; 애노테이션으로, 테스트 코드를 표시합니다.\n</p>\n<p>최근의 많은 Java 프로그래밍 환경에서는 주요 객체간의 의존 관계를 &#64;Inject로 정의하고, 실제 실행 환경에서는 프레임워크, 컨테이너가 객체를 조립하는 역할을 합니다. 그리고 &#64;Test로 표시된 테스트 코드에서는 테스트하고자 하는 대상이 아닌 부분은 가짜 객체로 교체해서 실행합니다. &#64;Inject를 써서 얻은 장점은 여러 가지이지만, &#64;Test가 붙은 메서드를 작성하기 쉽게 한다는 점에서 둘은 밀접한 관계가 있습니다. 단위 테스트(unit test)의 중요성이 강조되는 분위기가 의존 관계 주입의 인기에 촉매가 되기도 했습니다[1].\n</p>\n<p>그런데 과연 Android에서도 &#64;Inject와 &#64;Test를 사용하면 좋은 점이 있을까요? 그리고 &#64;Inject와 &#64;Test를 사용하려면 어떤 도구를 쓰고, 개발 과정 중에 무엇을 바꿔야 할까요? 이 글에서는 이 질문에 대한 고민을 정리해보고자 합니다. Eclipse에서 moreUnit이라는 플러그인을 설치하면 단축키 Ctrl &#43; J를 눌러 실행 코드와 테스트 코드 사이를 빠르게 오가면서 개발할 수 있습니다. 이 글에서도 비슷한 느낌으로 &#64;Inject와 &#64;Test 사이를 오가며 Android에서의 활용을 검토하겠습니다.\n</p>\n<h2>Dependency Injection(DI)의 이점\n</h2><p>의존 관계 주입(dependency injection, 이하 DI)을 활용한 프로그래밍에서는 객체가 자신이 사용할 객체를 스스로 선택하지 않고, 제3의 객체가 사용할 객체를 주입한다. 의존 관계 역전(Inversion of control)이라고 불리는 이 과정에서 반드시 프레임워크가 필요하지는 않다. 객체의 관계를 조립하는 팩토리 클래스를 만들어서 사용할 수도 있다. 다만 DI 프레임워크는 객체 조립 과정을 더 편리하게 한다.\n</p>\n<p>DI의 이점은 크게 세 가지를 들 수 있다. 이미 Spring과 같은 DI 프레임워크를 경험한 사람들에게 새로운 내용은 아닐 것이다.\n</p>\n<p>첫째, 객체의 생성 주기를 제어한다. DI 스타일이 유행하기 전까지는 한 번 생성해서 계속 재활용할 객체의 singleton 패턴을 직접 구현했다. 객체 생성 지점을 통제하기 위해서, 생성자를 private으로 바꾸고 getInstance() 메서드를 추가하는 등 각 클래스마다 코드를 추가해야 했다. DI 프레임워크에서는 ApplicaitonContext, Injector, ObjectGraph 등으로 불리는 통합 객체 저장소에 일반적인 객체를 등록하고, 이를 사용하는 쪽에서 &#64;Inject같은 애노테이션으로 표시하여 객체를 주입받는다. 애플리케이션에서 한 번만 생성하던 객체를 사용자의 요청이 있을 때마다 생성되도록 변경할 때에도 이 객체를 사용하는 객체 측의 코드는 크게 변경할 필요가 없다.\n</p>\n<p>둘째, 객체에 부가 기능을 추가한다. AOP(Aspect Oriented Programming)를 이용하면, 의존하는 객체에 같은 규약을 유지한 채로 로깅, 보안, 트랜잭션 처리, Exception 처리 등의 부가 기능을 추가할 수 있어서, 반복되는 코드를 줄이고 유연하게 각종 운영 정책을 변경할 수 있다.\n</p>\n<p>셋째, 실행 환경에 따라 구현 객체를 바꿔치기한다. 예를 들면 다음과 같은 상황에서 사용할 수 있다.\n</p>\n<ul><li>WAS에 따라서 다른 구현 객체로 바꾸기(예: Tomcat이나 Jetty를 사용할 때에는 DataSourceTransactionManager를 사용하고, JBoss를 사용할 때에는 WAS에서 JNDI(Java Naming and Directory Interface)로 제공되는 JTA(Java Transaction API) 규약의 TransactionManager를 사용)\n</li><li>로컬에서 Call by Value로 호출되는 비즈니스 객체를 원격 호출 객체로 바꾸기(Spring Remote 모듈)\n</li><li>테스트 코드에서 테스트 대상이 아닌 객체를 테스트 전용(test double 또는 mock) 객체로 바꾸기\n</li></ul><p>정리하면, DI 프레임워크는 중요한 객체 생성에 관여하여, 객체의 생성 주기나 구현 방식을 바꿔야 할 때 코드를 적게 수정할 수 있게 한다.\n</p>\n<p>또한 DI 스타일을 의식해서 개발을 하다 보면, 객체 간 역할을 명확히 분담하게 되어 모듈별로 독립적인 작업을 진행하는 데 도움이 된다. 물론 DI 프로그래밍 스타일과 프레임워크를 활용하면서 그에 어울리는 클래스 설계 방식을 고려해야 그런 이점을 얻을 수 있으며, 단지 프레임워크를 쓰기만 한다고 해서 그런 이점이 생기지는 않는다.\n</p>\n<p>주로 Java 진영에서 발달한 DI 기술은 C#, .NET, Python, Ruby 등에서도 DI 프레임워크가 탄생하는 데에 영향을 미쳤다. 반면 C, C&#43;&#43; 등은 리플렉션이나 GC 등의 기능이 부족해서 DI 프레임워크가 발전하기 어려운 면이 있다[2]. DI 프레임워크는 Java의 대표적인 특성이라 할 수 있다. \n</p>\n<p>Java에서 &#64;javax.inject.Inject는 표준 규약인 JSR-330[3]에서 정의하고, Spring, Google Guice, Jboss Seam, Glassfish와 같은 JavaEE6 표준 WAS 등이 지원한다.\n</p>\n<h2>Android에서도 &#64;Inject가 의미 있을까\n</h2><p>앞에서 봤듯이 적어도 Java의 서버 모듈에서는 DI 모델이 프로그래밍 세상을 지배했다고 말해도 과언이 아니다. 하지만 그런 장점이 Android에서 이어질 수 있을까? Android에서 DI 프레임워크를 사용하는 데는 여러 장벽이 있다.\n</p>\n<p>첫째, 용량에 부담이 된다. 서버에서는 jar 파일 하나를 추가해도 큰 영향이 없지만, 모바일 기기에서는 훨씬 한정된 자원을 이용하기 때문에 jar 파일의 용량, apk 파일의 용량, 메모리 사용량에 민감하다. DI 프레임워크를 사용하기 위해 애플리케이션의 용량이 늘어난다면, 그 이득이 정말 비용을 상쇄할만한지 더욱 냉정하게 평가하게 된다.\n</p>\n<p>둘째, 성능에 부담이 된다. 프레임워크를 사용하면 실행 시에 콜스택이 늘어날 수 있다. 일반 호출에 비해 성능이 안 좋은 리플렉션도 DI 프레임워크에서 많이 사용된다. 의존 관계를 해석하기 위해 애플리케이션 초기 로딩에 더 많은 일을 해야 할 가능성도 크다. 서버 쪽에서는 무시해도 좋은 정도의 부담일 수 있지만, 모바일 기기에서는 더욱 민감하고 조심스럽다.\n</p>\n<p>물론 앞으로 모바일 기기의 하드웨어와 Android가 계속 발전하면 지금보다 애플리케이션 수준의 성능 최적화가 덜 중요해질 수도 있다. 그러나 많은 사용자가 사용할 수 있게 하려면 오래 전에 출시된 저사양 기기도 고려해야 한다. 특히 애플리케이션이 전세계를 대상으로 한다면 더욱 그렇다. 우리나라는 고사양 기기와 최신 버전 Android의 보급률이 높지만, 전세계에서는 2013년 3월 현재 Gingerbread(Android 2.3) 이하 버전을 사용하는 사용자가 53.7%나 된다[4]. Android에서는 유연하고 튼튼한 설계보다 하드웨어에 맞는 최적화를 중요하게 여기는 경향이 있으며, 저사양 기기가 시장에 있는 동안은 이 경향이 계속될 것이다.\n</p>\n<p>예를 들면, Interface는 변경에 유연하게 대응할 수 있게 하고 Enum은 개발자의 실수를 막아주기 때문에 Java 개발에서는 많이 사용하지만, Android에서는 한때 최적화 관점에서 둘 다 권장하지 않았다. 이제는 큰 영향이 없다고 해도 많은 개발자들은 아직도 이를 의식하고 있다.\n</p>\n<p>셋째, Android 애플리케이션의 실행 환경인 Dalvik에서는 cglib과 같은 런타임 바이트 코드 생성 라이브러리를 사용할 수 없다. 이로 인해 프레임워크의 기능이 한정되어 장점이 줄어든다. Spring과 같은 DI 프레임워크에서는 런타임 바이트 코드 생성을 많이 이용한다. 대표적으로 인터페이스가 없는 클래스에 AOP를 적용할 때 cglib과 같은 기술을 사용하는데, Android에서는 런타임 바이트 코드 생성으로 비슷한 기능을 구현할 수 없다.\n</p>\n<p>그렇다고 프레임워크를 적용하기 위해서는 주요 기능을 모두 인터페이스로 선언해야 한다면 프레임워크를 적용하는 데 불편한 점이 많아진다. 애플리케이션 개발자가 작성해야 할 코드의 분량이 늘어나고, 기존 코드에 적용할 때는 구조를 많이 바꾸어야 하기 떄문이다. 여러 Android 프레임워크에서 이를 어떻게 극복했는지는 뒤에서 살펴보겠다.\n</p>\n<p>넷째, 대체로 애플리케이션의 규모가 작아서 DI의 유연성으로 얻는 이득이 크지 않다. 화면 개수나 코드 분량으로 비교하면 Android 애플리케이션은 서버 쪽보다 규모가 작은 경우가 많다. 이렇게 작은 애플리케이션은 서버처럼 WAS의 종류를 바꿀 일도 없고, 모든 주요 객체에 기능을 더하는 등의 큰 변경이 별로 없기 때문에 유연성이 크게 필요하지는 않다. 얻는 이득이 불확실한데, DI를 쓰기 위해 성능이나 용량에 대한 부담을 감수하기는 결정을 내리기는 어렵다.\n</p>\n<p>다섯째, Android 기본 프레임워크와 DI 프레임워크의 조화를 고려해야 한다. Activity, Service 등 주요 객체는 이미 Android 기본 프레임워크에서 등록되고 고유한 라이프사이클이 정의되어 있다. 특히 Activity의 생성, 소멸, 시작, 정지 등의 라이프사이클은 애플리케이션 개발자가 늘 의식하고 정교하게 그 안에서 할 일을 배분해야 한다. 이렇게 객체 등록과 라이프사이클 관리가 Android에 특화되어 있는데, 모든 객체에 일반화된 접근을 하는 DI 프레임워크를 동시에 사용하면 이득이 있을지 고민해야 할 것이다.\n</p>\n<p>그리고 View 객체와 같은 Android UI 클래스의 속성은 주로 XML 안에서 정의하고, Android가 객체 생성을 담당한다. 이 부분은 이미 DI 스타일과 유사하다. View 클래스를 쓰는 Activity에서는 findViewById(int) 메서드로 참조를 얻는데, 이는 dependency lookup 방식이다. Android DI 프레임워크는 View 객체의 생성 지점을 Android에 맡긴 채 findByViewId()와 같은 메서드를 DI 스타일로 대체할 방법을 제공해야 할 것이다.\n</p>\n<h2>Android에서도 &#64;Test가 의미 있을까\n</h2><p>이번에는 &#64;Test를 살펴보자. 마찬가지로 Android에서는 테스트 코드를 작성하기 어렵게 하는 요소가 많다.\n</p>\n<p>첫째, Android 기본 프레임워크의 구조에는 Mock을 적용하기 어렵다. Android에서는 의존하는 객체를 가져올 때 Activity.getViewById(int), getSystemService(String)와 같은 상위 클래스 메서드를 활용한다. 따라서 테스트용 가짜 객체를 끼워 넣으려면 상위 클래스의 동작을 가로채야 한다. 이런 경우에는 Mockito의 spy() 메서드를 사용하는 등 특별한 방법을 동원해야 한다. 그리고 그런 특별한 방법으로만 테스트가 가능하다는 것은 설계를 개선해야 한다는 신호라고 보기도 한다. Mockito매뉴얼에서도 spy() 메서드는 레거시 코드를 테스트할 때와 같은 특별한 상황에서만 사용하라고 설명한다[5]. 객체 간의 의존 관계를 가져오는 코드 외에 getAssets() 메서드와 같이 자원을 가져오는 코드도 마찬가지다. Android에서 테스트 코드는 언제나 상위 클래스의 동작을 추적해서 어디서부터 테스트를 위한 환경과 연결시킬 것인가를 고민하게 한다. Activity나 Context와 같은 슈퍼 클래스가 너무 많은 역할을 한다고 생각한다.\n</p>\n<p>서버 쪽의 Java에서는 상속보다는 위임으로 POJO(특정 실행 환경에 종속적이지 않은 단순한 Java 객체)를 활용하고 DI를 이용해 의존 관계를 구성한다. 이는 테스트용 객체를 활용하기 쉬운 구조다. Android에서도 DI 프레임워크를 적용하면 테스트용 객체를 주입하기 편하지만 앞 단락에서 말한 런타임 시 성능과 용량의 문제 등에 다시 부딪친다.\n</p>\n<p>둘째, 기본 제공되는 Mock클래스의 기능이 빈약하다. android.test.mock 아래에 MockContext, MockApplication, MockResource 등 여러 Mock 클래스가 제공되기는 한다. 그러나 이 클래스들은 대부분의 동작을 UnsupportedOperationException을 던지는 껍데기일 뿐이다. 필요한 동작은 아래 코드처럼 직접 override해서 구현해야 한다.\n</p>\n<p><strong>예제 1 MockContext override</strong></p>\nstatic public class MockServiceContext extends MockContext {\n   &#64;Overrride\n   public getSystemService(String name){\n    ……\n   }\n}\n\n<p>웹 개발에서 자주 쓰는 Spring의 MockHttpServetRequest와 같은 클래스에서는 테스트에 필요한 동작이 기본적으로 구현되어 있는데, 그런 클래스와 비교하면 Android의 기본 Mock클래스는 상당히 불편하다.\n</p>\n<p>셋째, 기본 제공 테스트 프레임워크가 사용하기 쉽지 않다. Activity를 테스트하는 데에는 ActivityTestCase, ActivityUnitTestCase, ActivityInstrumentationTestCase2의 세 가지 클래스를 쓸 수 있는데, 이를 경우에 따라 능숙하게 활용하는 경지에 이르기까지는 시행착오를 겪어야 한다. 이 클래스가 다른 용도를 가진 이유는 Android의 독특한 스레드 모델 때문인데, 이를 깊이 이해해야만 제대로 활용할 수 있다. 이 클래스를 사용하여 테스트하다 보면 예상하지 못하게 동작하는데, 이에 대한 내용은 잘 문서화되어 있지도 않다. 예를 들면 아래와 같은 상황이 있다.\n</p>\n<ul><li>ActivityUnitTestCase에서 Dialog생성 등에 Event가 전달되면 BadToken Exception이 발생한다[6].\n</li><li>ActivityInstrumentationTestCase2에서 Dialog 객체를 생성 후 dismiss() 메서드를 호출하지 않으면 leak window Exception이 발생한다[7].\n</li></ul><p>실제 프로젝트에서 위의 현상을 겪었고, 원인을 파악하는 데 꽤 많은 시간을 허비했었다.\n</p>\n<p>그리고 ActivityUnitTestCase와 같은 기본 테스트 클래스들이 JUnit3 기반으로 되어 있다는 점도 아쉽다. 이미 JUnit4가 나온 지 한참 지났는데도 자유로운 메서드 명이나 Exception 테스트와 같은 JUnit4의 장점을 활용할 수 없다. Android 테스트에서는 테스트의 성격을 구분하고 필요해 따라 선택해서 실행할 수 있도록 &#64;SmallTest, &#64;MediumTest, &#64;LargetTest와 같은 애노테이션을 제공한다. 이미 JUnit보다 더 정교하게 구분된 애노테이션을 활용하고도 있으면서도 기본 틀은 JUnit3라는 점은 균형이 맞지 않아 보인다.\n</p>\n<p>넷째, 느린 테스트 실행 속도다. Android에서 JUnit 테스트를 작성하려는 의욕을 꺾는 가장 치명적인 장벽이다. 보통의 Java 환경에서는 IDE 안에서 로컬 PC에 설치된 JVM으로 JUnit 테스트를 실행시키고 바로 결과를 확인한다. 반면 Android의 실행 환경은 특별한 JVM인 Dalvik이기 때문에 JUnit 기반의 테스트도 에뮬레이터나 실제 기기에서 실행되어야 한다. 그래서 코드를 한 줄만 수정해도 apk 파일로 만들어 기기에 설치한 후에야 테스트할 수 있다. 여기에 걸리는 시간이 일반적인 JUnit 테스트에 비하면 매우 길다. 기기의 사양에 따라 다르지만 애플리케이션의 용량이 큰 경우 패키징과 설치에 수십 초가 걸리기도 했다. 그래서 빠르게 테스트 코드와 실행 코드를 수정해 가면서 디버깅하고 코드를 개선하는 리듬을 탈 수가 없다.\n</p>\n<p>&#34;Working Efficiently with Legacy Code&#34;라는 책의 저자는 테스트 실행 시간이 0.1초가 넘어가면 느린 단위 테스트이고, 느린 테스트는 단위 테스트가 아니라고 주장했다[8]. 이 말은 단위 테스트와 아닌 것을 구분하기 위한 엄격한 기준이라기보다는, 단위 테스트가 갖추어야 할 특성과 가치를 강조하는 설명이라고 생각한다. 이 말에 따르면 Android에서 빠른 피드백이라는 가치가 있는 단위 테스트는 불가능하다는 좌절을 느낄 만도 하다. 그리고 통합 테스트의 의미만으로 JUnit을 써도 여전히 아쉬운 점이 많다. 에뮬레이터 상태에 따라서 테스트 성공 여부가 달라지기도 하기 때문이다.\n</p>\n<p>다섯째, UI 테스트 본연의 어려움이다. 많은 Android 코드는 UI 생성과 이벤트를 다루고 있는데, 다른 분야에서도 이런 코드는 테스트하고 어렵고, 자동화 테스트는 깨지기가 쉽다. UI 객체의 속성은 자주 바뀌고, 익명 클래스 등을 통해서 처리되는 이벤트는 밖에서는 Mock 객체로 바꾸고 추적하기가 어렵다. \n</p>\n<h2>그럼에도 불구하고\n</h2><p>그럼 과연 Android에서는 DI 프레임워크나 테스트코드가 의미 없는 것일까? 그렇지는 않다고 생각한다.\n</p>\n<p>우선 Android에서 반복되는 View, Resource, SystemService에 대한 참조를 가져오는 코드를 DI 스타일로 개선하면 좀 더 코드가 짧아지고 가독성이 좋아지리라 기대할 수 있다. 핵심 클래스의 의존 관계가 DI로 표시되면 객체 간 관계를 파악하기 좀 더 쉽다. 기존에 웹 개발을 하면서 DI 스타일에 익숙한 개발자들이 새롭게 애플리케이션 개발을 한다면 더 빨리 코드에 익숙해질 수도 있다.\n</p>\n<p>애플리케이션의 규모가 작아서 유연성이 필요하지 않다고 해도, DI 스타일이 제공하는 testability는 여전히 중요하다. 기기에서 테스트를 실행하기 전에 단위 테스트로 부분적인 기능을 검증할 수 있다면, 개발하고 오류를 수정하는 주기가 짧아진다. 이를 통해 초기 기능 개발의 시간을 줄이고, 향후에 더 빠르게 기능을 추가할 수 있을 것이다.\n</p>\n<p>먼저 Android의 DI 프레임워크에서는 앞에서 말한 과제를 어떻게 풀고 있는지 살펴보겠다.\n</p>\n<h2>DI 프레임워크\n</h2><p>여기에서는 Android에서 DI를 사용할 수 있는 프레임워크를 살펴보겠다. Android DI 프레임워크는 대표적으로 다음 6개가 있다.\n</p>\n<ul><li>Roboguice\n</li><li>Android Annotations\n</li><li>Transfuse\n</li><li>DroidParts\n</li><li>Dagger\n</li><li>Yasdic\n</li></ul><h3>항목별 비교\n</h3><p>Android DI 프레임워크의 특징은 다음과 같다. 이 중에는 DI만 제공하는 프레임워크도 있고, DI를 비롯하여 많은 기능을 제공하는 프레임워크도 있다.\n</p>\n<p><strong>표 1 Android DI 프레임워크의 특징\n</strong></p>\n<div><table><tbody><tr><td><p><strong>프레임워크</strong></p>\n</td><td><p><strong>Android 전용</strong></p>\n</td><td><p><strong>Annotation Processing 활용</strong></p>\n</td><td><p><strong>최근 활동(2013년 4월 1일 기준)</strong></p>\n</td><td><p><strong>문서 수준</strong></p>\n</td><td><p><strong>JSR330 지원</strong></p>\n</td></tr><tr><td><p><strong>최신 버전</strong></p>\n</td><td><p><strong>최근 릴리스</strong></p>\n</td><td><p><strong>최근 커밋</strong></p>\n</td></tr><tr><td><p>Roboguice</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td><td><p>2.0</p>\n</td><td><p>2012. 4. 23.</p>\n</td><td><p>2013. 2. 5.</p>\n</td><td><p>상</p>\n</td><td><p>O</p>\n</td></tr><tr><td><p>Android Annotations</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>2.7.1</p>\n</td><td><p>2013. 03. 4.</p>\n</td><td><p>2013. 3. 5.</p>\n</td><td><p>상</p>\n</td><td><p>X</p>\n</td></tr><tr><td><p>Transfuse</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>0.1.2</p>\n</td><td><p>2012. 11. 06.</p>\n</td><td><p>2013. 2. 1.</p>\n</td><td><p>상</p>\n</td><td><p>O</p>\n</td></tr><tr><td><p>DroidParts</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td><td><p>1.2.1</p>\n</td><td><p>2013. 3. 30.</p>\n</td><td><p>2013. 3. 30.</p>\n</td><td><p>중</p>\n</td><td><p>X</p>\n</td></tr><tr><td><p>Dagger</p>\n</td><td><p>X</p>\n</td><td><p>O</p>\n</td><td><p>0.9.1</p>\n</td><td><p>2012. 11. 12.</p>\n</td><td><p>2013. 3. 28.</p>\n</td><td><p>중</p>\n</td><td><p>O</p>\n</td></tr><tr><td><p>Yasdic</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>1.0</p>\n</td><td><p>2009. 6. 29.</p>\n</td><td><p>2009. 10. 22.</p>\n</td><td><p>중</p>\n</td><td><p>X</p>\n</td></tr></tbody></table></div><h4>Android 전용 여부\n</h4><p>Dagger와 Yasdic을 제외한 나머지는 모두 Android 전용 프레임워크다. Dagger와 Yasdic은 Android 전용은 아니지만 경량이라 Android에서 문제 없이 실행된다. Dagger는 Android를 염두에 두고 개발했다고 밝히고 있다. 다만 Android 전용이 아닌 프레임워크는 View injection 등 Android에 특화된 DI 기능이 없으므로 View, Resource, SystemService등 Android의 기본 구성 요소를 DI로 사용하고 싶을 때에는 다소 불편하다.\n</p>\n<p>Roboguice는 Android 전용이지만 핵심 DI 기능은 Google Guice에 의존적인데, 이 Google Guice 버전은 Android 전용이 아니다. 따라서 필수 바이너리가 비교적 크다.\n</p>\n<p>안드로이드 전용 프레임워크 중 Roboguice, Android Annotations, Transfuse의 용량을 비교해 보았다. Dagger와 Yasdic은 View injection 등 안드로이드에 특화된 기능을 제공하지 않아서 제외했다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 DroidParts, Transfuse, Android Annotations, Roboguice 용량 비교\n</strong></p>\n<p>jar 용량은 apk 파일에 필수로 패키징돼서 들어가야 할 파일만 용량을 합계해서 계산했다. Android Annotions와 Transfuse에서 컴파일할 때만 필요한 jar 파일은 apk 파일에서는 참조할 필요가 없으므로 제외했다. Roboguice가 약 622KB로 가장 용량이 컸고, Android Annotions는 62KB로 가장 작았다.\n</p>\n<p>apk 추가 용량은 프레임워크를 안 썼을 때에 비교해 늘어난 apk 파일의 크기를 정리했다. 이를 위해 테스트용 앱을 먼저 프레임워크 없이 구현한 후에 각각의 프레임워크를 적용해서 다시 같은 기능을 구현했다. 용량 측정에 사용한 애플리케이션은 간단한 날짜 계산기로, Fragment 4개와 Activity 1개로 이루어졌고, DI 프레임워크에서 View Injection과 Resource Injection기능을 활용했다. 뒤에서 안내할 SVN 주소에서 이 애플리케이션의 소스를 확인할 수 있다. 역시나 Android Annoations가 가장 적은 용량으로 불과 10.6KB이 더 늘어났다.\n</p>\n<p>Transfuse는 적용을 하려면 애플리케이션 구조를 많이 바뀌어야 하는 문제가 있어서 apk 추가 용량은 검증하지 못했는데, Android Annoations와 jar 파일 크기나 구현 원리가 비슷하기 때문에 apk 파일에 추가되는 용량도 비슷할 것으로 추정한다.\n</p>\n<h4>최근 프로젝트 활성화 수준\n</h4><p>Yasdic을 제외한 나머지는 모두 비교적 최근에 커밋이 있었다. Android Annotations와 DroidParts는 최근에 새 버전도 릴리스한 것으로 보아 활발하게 개발 활동이 이뤄지고 있는 것으로 보인다.\n</p>\n<h4>문서 수준\n</h4><p>Androi Annotations, Transfuse, Roboguice가 비교적 높은 수준으로 문서화되어 있다.\n</p>\n<h4>JSR-330 지원여부\n</h4><p>JSR-330은 앞에서 언급했듯이 &#64;javax.inject.Inject처럼 표준으로 정의된 애노테이션이다. 기능은 같더라도 표준 애노테이션을 활용하면 모듈의 이식성을 더 높일 수 있다. Roboguice, Transfuse, Dagger가 JSR-330을 지원한다.\n</p>\n<h4>Injection 대상 지원 범위\n</h4><p>다음은 Android와 아무런 의존성이 없는 POJO 클래스를 비롯하여, View, SystemService 등 Android에 특화된 DI를 지원하고 있는지 여부를 정리한 표다. 예를 들면 View injection이 지원되는 프레임워크에서는 Activity.findViewById를 &#64;InjectView와 같은 애노테이션으로 대체할 수 있다.\n</p>\n<p><strong>표 2 프레임워크의 Injection 대상 지원 범위\n</strong></p>\n<div><table><tbody><tr><td><p><strong>프레임워크</strong></p>\n</td><td><p><strong>POJO</strong></p>\n</td><td><p><strong>View</strong></p>\n</td><td><p><strong>Resource</strong></p>\n</td><td><p><strong>System Service</strong></p>\n</td><td><p><strong>Extra bundle</strong></p>\n</td><td><p><strong>Application</strong></p>\n</td><td><p><strong>Fragment</strong></p>\n</td></tr><tr><td><p>Roboguice</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td></tr><tr><td><p>Android Annotations</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td></tr><tr><td><p>Transfuse</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td></tr><tr><td><p>DroidParts</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td><td><p>O</p>\n</td></tr><tr><td><p>Dagger</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td></tr><tr><td><p>Yasdic</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td><td><p>X</p>\n</td></tr></tbody></table></div><p>위 프레임워크 중 Android 전용 프레임워크는 모두 Android에 특화된 DI 기능과 이를 위한 애노테이션을 지원한다. Android Annotations가 가장 넓은 범위를 지원하고, 그 다음으로는 DroidParts와 Roboguice순이다.\n</p>\n<p>각 프레임워크에서 View injection을 어떻게 지원하는지 예를 들어 살펴보자. 먼저 일반적인 Android 프로그래밍 방식에서는 findViewById와 Casting으로 View객체를 가져온다.\n</p>\n<p><strong>예제 2 Android에서 일반적인 View 객체 탐색</strong></p>\npublic class WeatherActivity extends Activity {\n    EditText city;\n     &#64;Override\n    protected void onCreate(Bundle savedState) {\n        super.onCreate(savedState) );\n        setContentView(R.layout.weather);\n        city &#61; (EditText) findViewById(R.id.city);\n    }\n…\n}\n\n<p>이를 각 프레임워크에서 구현한 방식은 다음과 같다.\n</p>\n<p><strong>예제 3 Roboguice의 View injection</strong></p>\n&#64;ContentView(R.layout.weather)\nclass WeatherActivity extends RoboActivity {\n    &#64;InjectView(R.id.city) TextView city;\n\n    public void onCreate(Bundle savedState) { \n        super.onCreate(savedState);\n        city.setText(&#34;Test&#34;);\n....\n    } \n}\n\n<p><strong>예제 4 Android Annotations의 View injection</strong></p>\n&#64;EActivity(R.layout.weather)\npublic class WeatherActivity extends Activity {\n    &#64;ViewById TextView  city;\n\n    &#64;AfterViews\n        void initText() {\n        city.setText(&#34;Test&#34;);\n    }\n….\n}\n\n<p><strong>예제 5 DroidParts의 View injection</strong></p>\nclass WeatherActivity extends prg.droidparts.activity.Activity{ \n    &#64;InjectView(id&#61;R.id.city)  TextView city;\n    &#64;Override\n    public void onPreInject() {\n        setContentView(R.layout.weather);\n    }\n\n    &#64;Override\n    protected void onCreate(Bundle savedState) {\n        super.onCreate(savedState);\n        city.setText(&#34;Test&#34;);\n    }\n}\n\n<p><strong>예제 6 Transfuse의 view injection</strong></p>\n&#64;Activity(label &#61; &#34;&#64;string/app_name&#34;)\n&#64;Layout(R.layout.city)\npublic class WeatherActivity {\n    &#64;Inject &#64;View(R.id.city)\n    TextView city;\n\n    &#64;OnCreate\n    public void initText() {\n        city.setText(&#34;test&#34;);\n    }\n}\n\n<p>&#64;Inject, &#64;InjectView 등 유사한 표기법을 지원하는 것을 확인할 수 있다. 단 이 애노테이션을 인식해서 처리하는 방식은 프레임워크마다 조금씩 다른데, Roboguice나 DroidParts는 프레임워크가 제공하는 상위 클래스에서 의존성을 주입하고, Android Annotations와 Transfuse는 애노테이션 프로세싱(annotation processing)으로 컴파일 타임에 코드를 생성한다. 그래서 Android Annotations는 Android의 기본 Activity 클래스를 상속받고, Transfuse는 아예 상위 클래스가 없는 코드를 보여준다.\n</p>\n<h4>애노테이션 프로세싱 활용 여부\n</h4><p>앞에서 잠시 언급한 애노테이션 프로세싱은 소스 코드를 컴파일할 때 애노테이션 정보를 읽어서 소스 코드를 조작할 수 있는 기술이다. Java 6부터 기본 Java 컴파일러에 포함되었고, QueryDSL, Lombok에서도 이를 활용하고 있다.\n</p>\n<p>런타임에 성능과 용량에 부담이 적기 때문에 Android에서는 이 기술이 특히 유용하다. DI 프레임워크로 조사 대상이었던 프레임워크뿐만 아니라, Android의 ORM(Object-relational mapping)인 Storm이라는 프레임워크에서도 이를 활용하고 있다. Android에서는 애노테이션 프로세싱이 런타임 바이트 코드 조작 기술을 많이 대체하고 있는 것으로 보인다.\n</p>\n<p>참고로 Android에서 바이트 코드 조작 기술인 cglib이나 ASM을 대체할 수 있는 기술은 Dexmaker(<a href=\"https://code.google.com/p/dexmaker/\">https://code.google.com/p/dexmaker/</a>)가 있다. Dexmaker는 Dalvik에서 실행될 수 있는 .dex 형식의 바이트 코드를 생성한다. 뒤에서 언급할 Mockito의 최신 버전이나 테스트 실행 프레임워크인 Vogar(<a href=\"https://code.google.com/p/vogar/\">https://code.google.com/p/vogar/</a>)에서는 이를 활용하고 있는데, 아직 DI 프레임워크에 활용된 사례는 찾지 못했다.\n</p>\n<h3>프로젝트별 평가\n</h3><h4>Roboguice\n</h4><p>유명한 애플리케이션에서 사용한 사례가 많은 DI 프레임워크이다. Facebook messenger, Groupon, Google Docs, Tripit, Digg에서 사용하고, NHN에서도 네이버 카페 애플리케이션이 사용하고 있다.\n</p>\n<p>최신 버전에서는 JSR-330의 &#64;Inject 애노테이션을 지원하고, Goggle Guice와 유사한 방식으로 DI를 사용할 수 있다는 장점이 있다. 애노테이션 프로세싱을 사용하지 않아서 다소 성능이나 용량에 부담이 있다.\n</p>\n<h4>Android Annotations\n</h4><p>iLive 등 많은 애플리케이션에서 쓰이고 있으나, 이를 활용한 애플리케이션의 유명세는 Roboguice보다는 약해 보인다.\n</p>\n<p>애플리케이션 개발자가 만드는 클래스에서는 프레임워크가 제공하는 특정 상위클래스를 상속하지 않지 않고 Activity 등 원래 Android에서 사용하는 클래스를 상속해서 구현한 후, 애노테이션 프로세싱으로 애플리케이션 개발자가 만든 클래스의 하위 클래스를 만드는 방식으로 동작한다. 이런 방식 때문에 Roboguice, GreenDroid, ActionBarSherlock 등 다른 프레임워크와 병행해서 사용할 수 있다.\n</p>\n<p>그리고 View나 리소스의 ID를 직접 지정하지 않아도 변수 이름이나 메서드 이름으로도 추론할 수 있기 때문에 다른 소스 코드를 더욱 파격적으로 줄일 수 있다. DI 외에도 &#64;Click 애노테이션으로 이벤트 메서드 지정, &#64;Rest 애노테이션과 &#64;Get 애노테이션으로 Spring RestTemplate을 호출하는 등 Android에서 코드를 줄일 수 있는 많은 기능을 제공한다.\n</p>\n<p>단점으로는 애노테이션 프로세싱을 활용하기 때문에 IDE 설정이 처음에 다소 번거로운데, IntelliJ에서는 환경 구성이 잘 되지 않는다는 반응이 많다[9]. 그리고 자동 생성되는 클래스는 끝에 언더바(_)가 붙으므로, 클래스를 참조하는 XML 선언에서는 이를 고려해서 클래스 이름을 지정해야 한다.\n</p>\n<h4>Transfuse\n</h4><p>&#64;Activity와 같은 애노테이션을 활용하면 아예 Android의 상위 클래스를 상속받지 않을 수 있다. 심지어 onCreate()같은 메서드도 override 방식이 아닌, &#64;OnCreate와 같은 애노테이션으로 지정한다.\n</p>\n<p>JSR-330과 간단한 AOP를 지원하면서도 애노테이션 프로세싱을 활용하여 런타임의 부담이 적다는 장점이 있다. Activity 등록이나 Intent-filter처럼 AndroidManifest.xml에 들어갈 내용도 애노테이션 안에 포함해서 선언한다. 이 때문에 기존 애플리케이션에는 점진적으로 적용하기 어렵다는 단점이 있다.\n</p>\n<p>가장 파격적으로 애노테이션을 활용한 프레임워크이고, 따라서 사용자에 따라서 선호도가 엇갈릴 것이라고 생각한다.\n</p>\n<h4>DroidParts\n</h4><p>DroidParts는 DI뿐만 아니라 RestClient, JSON 해석, ORM, Async 작업 처리 등 많은 기능을 제공하는 프레임워크다. 이는 종합 선물 세트 같은 프레임워크를 원하는 사용자에게 장점일 수 있다.\n</p>\n<p>DI 기능으로는 POJO뿐만 아니라 View, SystemService, Resource, BundleExtra 등의 Android 구성 요소를 DI 스타일로 개발할 수 있다.\n</p>\n<p>문서화가 다소 부족하고, 애노테이션 프로세싱 방식보다는 런타임에서 처리하는 일이 많다는 단점이 있다.\n</p>\n<h4>Dagger\n</h4><p>JSR-330을 지원하면서 애노테이션 프로세싱을 활용하는 경량 DI 프레임워크이지만 Android만을 위한 기능은 부족하다. 아직 프로젝트 초창기고, 문서도 많지 않다.\n</p>\n<h4>Yasdic\n</h4><p>더 이상 업데이트되지 않고, 홈페이지에서도 Roboguice 같은 다른 프레임워크를 사용하는 것을 권장하고 있다.\n</p>\n<h3>총평\n</h3><p>Android에서 DI 프레임워크가 쓰이기 어려운 장벽으로 용량 부담, 성능 부담, Dalvik의 제약, 애플리케이션의 규모를 들었다. 이를 기준으로 다시 프레임워크들의 특성을 살펴보자.\n</p>\n<p>첫째, 용량 부담을 줄이기 위해 패키지 구성을 경량화했다. 서버 쪽에서 쓰이는 Spring이나 Google Guice등을 그대로 쓰지 않고, Android를 감안해서 작은 용량으로 개발하거나 의존성을 최소한으로 줄였다. 특히 애노테이션 프로세싱은 라이브러리에서 컴파일타임에 의존하는 부분과 런타임에 의존하는 부분을 구분해서 더욱 용량을 줄였다. \n</p>\n<p>둘째, 성능 부담을 줄이기 위해서, 런타임에서 콜스택을 늘리지 않고 컴파일 타임에서 동작하는 애노테이션 프로세싱을 적극 활용했다. \n</p>\n<p>셋째, Dalvik에서는 바이트 코드 조작 기술을 쓸 수 없지만, 애노테이션 프로세싱을 사용하여 소스를 생성한 후 컴파일하는 방법으로 대체했다.\n</p>\n<p>넷째, 애플리케이션의 규모가 작아도 View나 Resource 같은 자원을 가져오는 코드가 간결해진다는 이점이 있다.\n</p>\n<p>위 특성을 살펴보면 Android DI 프레임워크에서 애노테이션 프로세싱이 상당히 중요한 역할을 한다는 것을 알 수 있다. 따라서 애노테이션 프로세싱을 적극적으로 활용하면서 다양한 구성 요소에 injection을 지원하는 Android Annotations에 가장 높은 점수를 주고 싶다.\n</p>\n<p>Roboguice는 비록 애노테이션 프로세싱 방식은 아니지만, 유명한 레퍼런스 애플리케이션이 많기 때문에 적용 사례를 중요시하는 관점에서는 높이 평가할 만하다. 즉, Android용 DI 프레임워크를 선택한다면 Android Annotations와 Roboguice가 가장 우선순위가 높다고 생각한다.\n</p>\n<p>Transfuse는 파격에 가까울 정도로 적극적으로 애노테이션을 활용한다는 점에서 그 설계 방식을 참고하고 앞으로 발전을 지켜볼 만하다. 하나의 프레임워크에서 DI를 포함한 다양한 기능을 제공하는 사례를 참고하고 싶다면 DroidParts도 도움이 될 수 있다. 즉, Transfuse와 DroidParts는 강력히 추천하지는 않지만 분석 대상으로 유용하다.\n</p>\n<p>Dagger와 Yasdic은 추천하지 않는다. 아직 프로젝트 초창기고 Android에 특화된 기능이 없어서 이점이 크지 않아 보인다. 특히 Yasdic은 현재 기능도 빈약한 데다가 발전 가능성도 없으니 깨끗이 잊어버리면 되겠다.\n</p>\n<p>본격적인 평가를 내리려면 먼저 Android Annotations와 Roboguice를 활용하여 많은 실무 사례를 축적해야 할 것이다.\n</p>\n<h2>Test 프레임워크\n</h2><h3>Android에서 &#64;Mock\n</h3><p>이제 다시 &#64;Test 얘기로 돌아와서 테스트 코드를 작성할 때 남아 있는 장벽을 넘을 수 있을지 고민해 보자. 우선 첫 번째 장벽이었던 Android 기본 프레임워크의 구조는 DI 프레임워크를 적용하여 극복할 수 있다. 그런데 두 번째 문제인 빈약한 기본 Mock 클래스는 어떻게 극복할 수 있을까?\n</p>\n<p>다행히 Mockito의 현재 최신 버전인 1.9.5는 Dalvik에서도 실행된다[10]. 1.9.1 미만 버전을 Dalvik에서 실행하면 cglib을 이용하여 Mock 객체를 생성하는 부분에서 오류가 발생한다. \n</p>\n<p>이후 버전의 Mockito는 Dexmaker(<a href=\"http://code.google.com/p/dexmaker/\">http://code.google.com/p/dexmaker/</a>)라는 라이브러리를 활용해서 Dalvik에서는 cglib 같은 바이트 코드 조작 라이브러리를 쓸 수 없다는 한계를 극복했다.\n</p>\n<p>지금은 이렇게 간단하게 이야기할 수 있지만, 그전까지는 Android에서 더 나은 Mock 라이브러리를 적용하기 위한 여러 힘겨운 시도가 있었다. 앞에서 말한 Dalvik의 제약 조건 때문에 인터페이스에 대한 mocking만 지원하는 EasyMock 2.5.x 버전을 Android에서 사용하는 사람들도 있었다. Android-mock(<a href=\"https://code.google.com/p/android-mock/\">https://code.google.com/p/android-mock/</a>)이라는 EasyMock을 활용한 것이다. 이미 Mockito나 EasyMock의 최신 버전에서 제약 사항이 적은 Mock을 사용했던 적이 있다면 이렇게 Mock을 위해서 인터페이스를 만들어야 하는 번거로움이 큰 장벽으로 느껴진다.\n</p>\n<p>이 밖에도 ScalaMock, Lmock 등을 이용해서 테스트할 수도 있지만, 이미 많은 사용자들이 익숙한 Mockito에 비해 큰 장점은 없다. 그리고 PowerMock을 이용해 개발자 JVM에서 Android 코드를 테스트하려는 시도를 한 사람들도 있었다[11].\n</p>\n<h3>표준 JVM에서 &#64;Test\n</h3><p>이제 기본 Mock 지원 객체가 빈약하다는 문제는 어느 정도 보강이 가능해졌다. 그렇다면 테스트에 시간이 오래 걸린다는 문제는 어떻게 해결할 수 있을까?\n</p>\n<p>테스트 준비 과정에 apk 패키징과 설치 과정이 포함되는 한 테스트 실행 속도를 개선하는 데에는 한계가 있다. 그렇다면 이 과정 없이 테스트를 실행할 수는 없을까? 우리가 일반적인 Java 프로그램을 개발할 때처럼, 개발자 PC의 JVM에서 바로 실행할 수도 있다.\n</p>\n<p>일반 JVM의 실행 환경은 Android 기기의 Dalvik과 많이 다른데 이런 테스트가 의미 있을지 우려하는 사람도 많을 것이다. Dalvik의 제약 사항 때문에 발생하는 오류를 검출하지 못하여, 테스트를 통과해도 단말에서는 실행되지 않는 코드도 있을 것이다. 하지만 어차피 테스트 코드에서는 완벽한 검증이 불가능하다. 그래도 완전한 테스트를 실행하지 않는 것보다는 불완전한 테스트를 실행하는 것이 낫다[12].\n</p>\n<p>임베디드 C 분야의 TDD 기법을 살펴봐도 개발자가 쓰는 장비에서 테스트를 실행하는 방법을 적극적으로 활용하고 있다. 임베디드 개발 분야에서도 빌드 시간과 업로드 시간이 길면, 수정, 타깃 컴파일, 로드, 테스트를 실행하는 사이클에서 귀중한 시간을 낭비하게 하고, 결국 한 번의 빌드에서 너무 많은 수정 내용을 반영하도록 유도하여 디버깅이 어려워진다. 이 분야의 전문가 제임스 그레닝은 임베디드 분야에서 TDD를 활용하면 개발 시스템상에서 버그를 제거하여 시간이 오래 걸리는 타깃 컴파일-링크-업로드 작업의 횟수를 줄일 수 있다고 주장한다. 제임스 그레닝은 임베디드 TDD 사이클을 5단계로 정의하는데, 그 중 1단계인 &#39;TDD 마이크로 사이클&#39;에서는 개발 장비에서 코드를 작성하고 테스트한다. 그리고 마지막 5단계에 타깃 하드웨어에서 인수 테스트를 실행한다[13].\n</p>\n<p>Android 테스트를 일반 JVM에서 실행하는 방법이 진정한 문제는 회피한 차선책으로 여겨질 수도 있지만, 임베디드 분야의 TDD 방식과 유사한 관점으로 보면 개발자 JVM에서 빠르게 실행하는 테스트가 진정한 유닛 테스트라고 할 수 있다.\n</p>\n<p>Robolectric이라는 프레임워크를 쓰면 Android 코드를 일반 JVM에서 테스트할 수 있다. Robolectric은 JUnit4의 애노테이션을 지원한다. Android의 기본 테스트 프레임워크는 JUnit3기반이어서 &#64;Test와 같은 애노테이션을 사용할 수 없다. 이런 점에서도 Robolectric은 진정한 &#64;Test를 도와준다고 할 수 있다.\n</p>\n<p><strong>예제 7 Robolectric의 예제[14]\n</strong></p>\n&#64;RunWith(RobolectricTestRunner.class)\npublic class MyActivityTest {\n    private Activity activity;\n    private Button pressMeButton;\n    private TextView results;\n\n    &#64;Before\n    public void setUp() throws Exception {\n        activity &#61; new MyActivity();\n        activity.onCreate(null);\n        pressMeButton &#61; (Button) activity.findViewById(R.id.press_me_button);\n        results &#61; (TextView) activity.findViewById(R.id.results_text_view);\n    }\n\n    &#64;Test\n    public void shouldUpdateResultsWhenButtonIsClicked() throws Exception {\n        pressMeButton.performClick();\n        String resultsText &#61; results.getText().toString();\n        assertThat(resultsText, equalTo(&#34;Testing Android Rocks!&#34;));\n    }\n}\n\n<p>Robolectric은 ShadowActivity와 같은 테스트 전용 객체를 제공하기 때문에 Mockito 같은 범용적인 Mock 라이브러리를 사용할 때보다 Acitivity나 View 객체를 다루는 기능을 테스트하기에 편하다.\n</p>\n<p>Robolectric은 Activity 같은 UI 클래스를 테스트하지 않을 때도 유용하다. 유틸리티 클래스에서는 android.util.Log.i() 메서드 같은 Android에서 제공하는 정적(static) 메서드를 호출하는 경우가 많다. Robolectric은 그런 메서드의 호출도 가로채서 일반 JVM에서도 돌아가는 메서드로 만들어 준다.\n</p>\n<p>Robolectric의 단점은 첫째, 테스트 실행 속도가 일반 POJO 클래스를 실행할 때보다는 느리다는 것이다. PowerMock처럼 초기화 과정에서 바이트 코드 조작 기능으로 Android 클래스를 가로채는 코드를 심는데, 처음 테스트를 실행할 때 그 시간이 1 ~ 2초 정도 걸린다. 그래도 실제 장비나 에뮬레이터보다는 충분히 빠르다.\n</p>\n<p>둘째, 현재 최신 버전인 2.0-alpha-3에서도 fragment에 대한 테스트 기능이 아직 완벽하지 않는 등 기능의 빈 곳이 아직 존재한다는 것이다[15].\n</p>\n<p>셋째, Android &#43; Maven &#43; Eclipse 환경에서는 Robolectric을 쓴다면, apk를 빌드할 때 명령행에서 android-maven 플러그인으로만 수행해야 한다는 것이다. Maven에서 test-scope로 선언한 라이브러리가 있는 경우에 Eclipse에서 &#39;Run as Android Application&#39;을 실행할 때에는 이를 잘 제외시키지 못하기 때문인데[16], Robolectric의 라이브러리는 DEX 변경 과정에서 Eclipse가 아예 멈추게 한다. 이 문제를 피하는 다른 방법으로 원래의 Android 프로젝트 구조처럼 test 프로젝트를 별도의 Eclipse 프로젝트로 생성할 수도 있지만, 원래의 Maven 구조에서 벗어나게 된다는 점이 아쉽다.\n</p>\n<p>지금까지 언급한 오픈 소스 프레임워크인 Android annotation, Mockito, Robolectrice 등을 활용한 예제는 다음 주소에서 확인할 수 있다.\n</p>\n<ul><li><a href=\"https://dev.naver.com/svn/android-samples\">https://dev.naver.com/svn/android-samples</a>(아이디와 비밀번호는 모두 anonsvn)\n</li></ul><h3>블랙박스 방식의 UI 테스트\n</h3><p>Robotium이라는 오픈 소스 프레임워크는 Android에서 UI 테스트를 좀 더 편하게 실행할 수 있게 해준다. 웹의 Selenium과 비슷하게, 사용자가 보는 관점에서 이벤트를 발생시키고 결과를 확인할 수 있다. 애플리케이션 내부의 View같은 객체를 직접 참조해서 속성을 확인하는 대신에 애플리케이션을 블랙박스로 보고 테스트하는 방식이다. Roboletric으로 단위 테스트를 실행하고, Robotium으로 통합 테스트를 실행한다면 Android 테스트의 어려움을 약간은 덜 수 있다.\n</p>\n<p>하지만 앞에서 UI를 테스트하는 것은 어느 개발 환경을 막론하고 근본적인 어려움이 있다고 이야기했다. 이미 웹에서도 Selenium을 통한 UI테스트를 잘 유지하고 투자 대비 효과를 이끌어내는 것은 쉽지 않은 과제라는 것을 경험한 조직이 많다. 그래서 UI 요소가 아닌 클래스에서 되도록 많은 로직을 테스트할 수 있는 구조를 만드는 것이 더욱 중요하다. 즉, 테스트하기 어렵다면 이를 설계 개선의 신호로 보고, 테스트하기 쉬운 구조로 바꾸려는 시도를 먼저 해야 할 것이다. 그 결과로 코드 가독성이 높아지고, 추가 요구 사항을 수용하기 쉬운 구조가 될 수 있다.\n</p>\n<p>Robotium같은 블랙박스 테스트 방식은 처음에 접근하기가 쉬울 수 있으나, 버그를 발견해서 추적하기가 단위 테스트보다 어렵고, 설계 개선을 유도하지 못한다는 단점이 있다.\n</p>\n<h2>Android 개발 환경이 갈 길은?\n</h2><p>Android에서 &#64;Inject와 &#64;Test 방식의 개발을 도와주는 여러 가지 오픈 소스 프레임워크를 소개했다. 그러나 이런 프레임워크를 적용해도 모든 장벽이 말끔하게 사라지지는 않는다. DI 프레임워크가 아무리 용량을 줄여도 추가 라이브러리가 필요하고, 여러 애플리케이션에서 같은 라이브러리를 사용하면 중복해서 단말의 용량을 차지하게 된다. Robolectric이나 Mockito로 테스트가 더 편해져도 Android 기본 테스트 프레임워크를 사용해야 할 때도 있고, 같은 테스트를 JVM과 Dalvik에서 같이 실행해 보고 싶을 때는 어떻게 해야 할지 고민이 된다. \n</p>\n<p>이런 오픈 소스 프레임워크들의 이점을 언젠가는 Android 기본 프레임워크만으로도 누릴 수 있어야 한다고 생각한다. 그렇게 된다면 추가 용량 부담을 걱정하는 일도, Android 기본 기능과 어떻게 조화를 시킬지 고민하는 일도 조금은 적어질 것이다. 이렇게 많은 오픈 소스 프레임워크가 나온 것은 Android 기본 프레임워크가 충족시키지 못한 면이 많아서일 것이다. 자연스러운 피드백 사이클을 거친다면, 이런 오픈 소스의 성과는 다시 표준이나 기본 구현체에 반영되어야 한다.\n</p>\n<p>Java의 다른 분야에서도 그런 예는 수없이 많다. DI 프레임워크 자체가 JavaEE의 표준보다는 Spring이나 Google Guice를 통해 보급되었고, 거꾸로 JSR-330 같은 표준과 EJB 3.0 이후의 POJO 기반 프레임워크에 반영되었다.\n</p>\n<p>Eclipse RCP 플랫폼의 변화도 그 예가 될 수 있다. 다음은 Eclipse 3.x에서 도움말 시스템 관련 객체를 가져오는 코드이다.\n</p>\n<p><strong>예제 8 Eclipse 3.x에서 HelpSystem 관련 객체를 가져오는 코드</strong></p>\nclass MyView extends ViewPart {\n    public void createPartControl(Composite parent) {\n        Button button &#61; ...;\n        PlatformUI.getWorkbench().getHelpSystem().setHelp( button, &#34;com.example.button.help.id&#34;);\n        getViewSite().getActionBars().getStatusLineManager().\n        setMessage(&#34;Configuring system...&#34;);\n    }\n}\n\n<p>위와 같은 코드가 Eclipse 4.0에서는 다음과 같이 JSR-330의 &#64;Inject 등을 지원하는 DI 스타일로 바뀌어 플랫폼 종속적인 상위 클래스를 상속받지 않아도 된다.\n</p>\n<p><strong>예제 9 Eclipse 4.x에서 helpSystem 관련 객체를 가져오는 코드</strong></p>\nClass MyView {\n    &#64;Inject\n    public void create(Composite parent, IWorkbenchHelpSystem help) {\n        Button button &#61; ...;\n        help.setHelp(button, &#34;com.example.button.help.id&#34;);\n\n&#9;&#9;&#9;&#9;\n        slm.setMessage(&#34;Configuring system...&#34;);\n    }\n}\n\n<p>Eclipse 개발을 담당하는 쪽에서는 이런 변화가 의존성 파악의 어려움, 플랫폼 제공자와 사용자 코드의 강결합 문제 등 그동안 겪어온 어려움을 피하기 위한 것이라고 설명한다[17]. 이 결정에는 10년 동안의 Eclipse RCP 플랫폼 개발 경험이 반영되었다. 하위 호환성을 고려하지 않는다면 이런 형태가 Android 기본 프레임워크의 미래일지도 모른다.\n</p>\n<p>현재의 Android 기본 테스트프레임워크도 발전하는 과정에 있다. 2007년 Android의 초창기에는 JUnit 테스트를 개발자 JVM과 Eclipse에서밖에 실행할 수 없었다고 한다[18]. 그 후 실제 단말기와 에뮬레이터에서 JUnit 테스트가 실행될 수 있도록 발전했지만, 반대로 JVM에서 실행할 수 있는 방법은 없어졌다. Mockito와 Roboletric이 지원하는 기능처럼 표준 JVM과 Dalvik 테스트 모두에서 실행할 수 있게 하는 방향이 바람직하다고 생각한다. 임베디드 분야의 TDD 기법처럼, 패키징과 설치 전에 테스트할 수 있는 단계가 있어야 Android에서 진정한 의미의 TDD가 가능할 것이다. \n</p>\n<p>Android가 Java를 애플리케이션 개발 환경으로 택한 전략은 Android 생태계 활성화에 크게 이바지했다. 언어 외에도 Android 개발에 필요한 지식은 많다. 웹 개발만 해 온 Java개발자들에게는 Android의 API나 주요 객체의 생명 주기, UI 스레드 모델과 이벤트 전달 방식 등이 낯설다. 적어도 언어의 큰 장벽이 없다는 점은 새로 애플리케이션 개발을 하는 사람에게 큰 부담을 덜게 한다. 하지만 이에 머물지 않고, Android가 Java 생태계의 많은 부분을 수용해 갈수록 Android가 Java를 애플리케이션 개발 환경으로 택한 전략의 장점이 더 커질 것이다. 다른 영역이지만 Android에서는 새로운 빌드 도구로 Ant대신 Gradle을 고려하고 있다고 한다[19]. Java 생태계에서 떠오르는 기술을 비교적 빠른 시기에 수용하려는 움직임을 보인다는 점에서 큰 의미가 있다고 생각한다. 이미 Java 프로그래밍 모델의 많은 영역을 차지한 &#64;Inject, &#64;Test 방식을 어떻게 Android에 잘 녹여낼지가 Android에 남아있는 큰 숙제라고 할 수 있다.\n</p>\n<h2>마치며\n</h2><p>Android에서는 &#64;Inject, &#64;Test를 활용한 코드를 작성하는 데에 어려움이 있지만, Android Annotations, RoboGuice, Robolectric, Mockito을 활용하면 이를 다소 극복할 수 있다. 그리고 이렇게 지금의 여러 오픈 소스 프레임워크가 제공하는 기능들이 앞으로 Android 기본 프레임워크에도 반영되는 것이 근본적인 해결책일 것이다.\n</p>\n<p>지금은 Java 서버 개발자에게도 Android가 HTML이나 JavaScript처럼 필수 교양으로 인식되는 시대이다. Ajax 초창기에 비하면 요즘에는 Ajax를 어느 정도는 다룰 줄 아는 서버 개발자를 찾기 어렵지 않다. 마찬가지로, 앞으로는 서버 개발과 Android 클라이언트 개발을 모두 할 수 있는 사람이 더 많아질 것이다. 그럴수록 Java 서버 모듈 프로그래밍 방식과 Android 모듈 프로그래밍 방식의 차이를 줄이려는 시도가 늘어날 것이다. 그 과정에서 마치 Ajax에서 jQuery가 그랬던 것처럼 스타가 되는 기술도 나올 수도 있다. 우리는 지금 그 초창기에 서 있는지도 모른다.\n</p>\n<p>웹플랫폼개발랩에서도 이런 흐름에 맞춰 모바일 애플리케이션 개발에도 기여할 수 있는 다양한 방법을 탐색하고 있다. Stackoverflow처럼 정보를 공유할 수 있는 사이트를 사내에도 구축하거나 사내 API 클라이언트 모듈의 베스트 프랙티스를 찾는 등이 그 예다. 모바일 애플리케이션을 개발하면서 쌓아온 비급이 있는데 다른 조직으로는 퍼지지 못해서 아쉬웠다면, 이를 앞으로 어떻게 잘 공유할 수 있을지 함께 고민했으면 한다.\n</p>\n<h2>참고 자료\n</h2><ol><li>Dhanji R. Prasanna, &#34;Dependency Injection&#34;, Manning Publications, 2009, pp. 16.<br>&#34;A growing emphasis on unit testing continues to be a natural catalyst to the growth of DI popularity&#34;\n</li><li>Dhanji R. Prasanna, &#34;Dependency Injection&#34;, Manning Publications, 2009, pp. 19.\n</li><li><a href=\"http://jcp.org/en/jsr/detail?id&#61;330\">http://jcp.org/en/jsr/detail?id&#61;330</a>\n&#9;&#9;</li><li><a href=\"http://developer.android.com/about/dashboards/index.html\">http://developer.android.com/about/dashboards/index.html</a>\n&#9;&#9;</li><li><a href=\"http://docs.mockito.googlecode.com/hg/org/mockito/Mockito.html\">http://docs.mockito.googlecode.com/hg/org/mockito/Mockito.html</a><br>&#34;Real spies should be used carefully and occasionally, for example when dealing with legacy code.&#34;\n</li><li><a href=\"http://code.google.com/p/android/issues/detail?id&#61;14616\">http://code.google.com/p/android/issues/detail?id&#61;14616</a><br><a href=\"http://stackoverflow.com/questions/2365561/testing-dialog-in-androids-activityunittestcase\">http://stackoverflow.com/questions/2365561/testing-dialog-in-androids-activityunittestcase</a>\n&#9;&#9;</li><li><a href=\"http://stackoverflow.com/questions/2850573/activity-has-leaked-window-that-was-originally-added\">http://stackoverflow.com/questions/2850573/activity-has-leaked-window-that-was-originally-added</a>\n&#9;&#9;</li><li>Michael C. Feathers, &#34;Working Effectively with Legacy Code&#34;, Prentice Hall, 2004, pp. 13 ~ 14.<br>&#34;A unit test that takes 1/10th of a second to run is a slow unit test. (중략) Unit tests run fast. If they don&#39;t run fast, they aren&#39;t unit tests.&#34;\n</li><li>이 문제의 해결책과 그래도 잘 되지 않는다는 사람들의 반응은 <a href=\"http://www.jayway.com/2012/08/31/making-androidannotations-work-with-intellij-idea\">http://www.jayway.com/2012/08/31/making-androidannotations-work-with-intellij-idea</a>에서 확인할 수 있다.\n</li><li>Mockito의 릴리즈 노트(<a href=\"https://code.google.com/p/mockito/wiki/ReleaseNotes\">https://code.google.com/p/mockito/wiki/ReleaseNotes</a>) 중 1.9.5 rc-1 설명 참조\n</li><li>PowerMock으로 Android 코드를 테스트하는 예제는 <a href=\"https://sites.google.com/site/androiddevtesting/\">https://sites.google.com/site/androiddevtesting/</a> 참조\n</li><li>Martin Fowler, &#34;Refactoring: Improving the Design of Existing Code&#34;, Addison-Wesley Professional, 1999, pp. 98.<br>&#34;It is better to write and run incomplete tests than not to run complete test.&#34;\n</li><li>James W. Grenning, &#34;Test-Driven Development for Embedded C&#34;, The Pragmatic Bookshelf, 2011, pp. 33 ~ 34, 105 ~ 121.\n</li><li><a href=\"http://pivotal.github.com/robolectric/maven-quick-start.html\">http://pivotal.github.com/robolectric/maven-quick-start.html</a>\n&#9;&#9;</li><li><a href=\"https://groups.google.com/forum/#!topic/robolectric/A1oJ_jtIRSI\">https://groups.google.com/forum/#!topic/robolectric/A1oJ_jtIRSI</a>\n&#9;&#9;</li><li><a href=\"https://github.com/rgladwell/m2e-android/issues/57\">https://github.com/rgladwell/m2e-android/issues/57</a>\n&#9;&#9;</li><li><a href=\"http://wiki.eclipse.org/Eclipse4/RCP/Dependency_Injection\">http://wiki.eclipse.org/Eclipse4/RCP/Dependency_Injection</a>\n&#9;&#9;</li><li>Diego Torres miliano, &#34;Android Application Testing Guide&#34;, Packt Publishing, 2011, pp. 7 ~ 8.\n</li><li><a href=\"http://tools.android.com/tech-docs/new-build-system\">http://tools.android.com/tech-docs/new-build-system</a>\n&#9;&#9;</li></ol>\n\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 웹플랫폼개발랩 정상혁\n&#9;&#9;Java와 Linux 를 주로 쓰는 흔한 주류 개발자이다.  서버,클라이언트, UI 등 다양한 분야를 소화하는 프로그래머가 되려고 노력 중이다. NHN계열사의 여러 조직에서 신규 프로젝트 개발, 기술지원, 교육 업무를 수행해 왔다.\n&#9;&#9;<br>\n&#9;&#9;\n</div></div>"},{"name":"Java Reference와 GC","published":1364872590,"description":"<div><p>NHN Business Platform 웹플랫폼개발랩 박세훈\n&#9;</p>\n<p>Java의 가비지 컬렉터(Garbage Collector)는 그 동작 방식에 따라 매우 다양한 종류가 있지만 공통적으로 크게 다음 2가지 작업을 수행한다고 볼 수 있습니다.\n</p>\n<ol><li>힙(heap) 내의 객체 중에서 가비지(garbage)를 찾아낸다.\n</li><li>찾아낸 가비지를 처리해서 힙의 메모리를 회수한다.\n</li></ol><p>최초의 Java에서는 이들 가비지 컬렉션(Garbage Collection, 이하 GC) 작업에 애플리케이션의 사용자 코드가 관여하지 않도록 구현되어 있었습니다. 그러나 위 2가지 작업에서 좀 더 다양한 방법으로 객체를 처리하려는 요구가 있었습니다. 이에 따라 JDK 1.2부터는 java.lang.ref 패키지를 추가해 제한적이나마 사용자 코드와 GC가 상호작용할 수 있게 하고 있습니다.\n</p>\n<p>java.lang.ref 패키지는 전형적인 객체 참조인 strong reference 외에도 soft, weak, phantom 3가지의 새로운 참조 방식을 각각의 Reference 클래스로 제공합니다. 이 3가지 Reference 클래스를 애플리케이션에 사용하면 앞서 설명하였듯이 GC에 일정 부분 관여할 수 있고, LRU(Least Recently Used) 캐시 같이 특별한 작업을 하는 애플리케이션을 더 쉽게 작성할 수 있습니다. 이를 위해서는 GC에 대해서도 잘 이해해야 할 뿐 아니라, 이들 참조 방식의 동작도 잘 이해할 필요가 있습니다.\n</p>\n<h2>GC와 Reachability\n</h2><p>Java GC는 객체가 가비지인지 판별하기 위해서 reachability라는 개념을 사용한다. 어떤 객체에 유효한 참조가 있으면 &#39;reachable&#39;로, 없으면 &#39;unreachable&#39;로 구별하고, unreachable 객체를 가비지로 간주해 GC를 수행한다. 한 객체는 여러 다른 객체를 참조하고, 참조된 다른 객체들도 마찬가지로 또 다른 객체들을 참조할 수 있으므로 객체들은 참조 사슬을 이룬다. 이런 상황에서 유효한 참조 여부를 파악하려면 항상 유효한 최초의 참조가 있어야 하는데 이를 객체 참조의 root set이라고 한다.\n</p>\n<p>JVM에서 메모리 영역인 런타임 데이터 영역(runtime data area)의 구조를 그림으로 그리면 다음과 같다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 런타임 데이터 영역(Oracle HotSpot VM 기준)\n</strong></p>\n<p>런타임 데이터 영역은 위와 같이 스레드가 차지하는 영역들과, 객체를 생성 및 보관하는 하나의 큰 힙, 클래스 정보가 차지하는 영역인 메서드 영역, 크게 세 부분으로 나눌 수 있다. 위 그림에서 객체에 대한 참조는 화살표로 표시되어 있다. \n</p>\n<p>힙에 있는 객체들에 대한 참조는 다음 4가지 종류 중 하나이다.\n</p>\n<ul><li>힙 내의 다른 객체에 의한 참조\n</li><li>Java 스택, 즉 Java 메서드 실행 시에 사용하는 지역 변수와 파라미터들에 의한 참조\n</li><li>네이티브 스택, 즉 JNI(Java Native Interface)에 의해 생성된 객체에 대한 참조\n</li><li>메서드 영역의 정적 변수에 의한 참조\n</li></ul><p>이들 중 힙 내의 다른 객체에 의한 참조를 제외한 나머지 3개가 root set으로, reachability를 판가름하는 기준이 된다.\n</p>\n<p>reachability를 더 자세히 설명하기 위해 root set과 힙 내의 객체를 중심으로 다시 그리면 다음과 같다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 Reachable 객체와 Unreachable 객체\n</strong></p>\n<p>위 그림에서 보듯, root set으로부터 시작한 참조 사슬에 속한 객체들은 reachable 객체이고, 이 참조 사슬과 무관한 객체들이 unreachable 객체로 GC 대상이다. 오른쪽 아래 객체처럼 reachable 객체를 참조하더라도, 다른 reachable 객체가 이 객체를 참조하지 않는다면 이 객체는 unreachable 객체이다.\n</p>\n<p>이 그림에서 참조는 모두 java.lang.ref 패키지를 사용하지 않은 일반적인 참조이며, 이를 흔히 strong reference라 부른다.\n</p>\n<h2>Soft, Weak, Phantom Reference\n</h2><p>java.lang.ref는 soft reference와 weak reference, phantom reference를 클래스 형태로 제공한다. 예를 들면, java.lang.ref.WeakReference 클래스는 참조 대상인 객체를 캡슐화(encapsulate)한 WeakReference 객체를 생성한다. 이렇게 생성된 WeakReference 객체는 다른 객체와 달리 Java GC가 특별하게 취급한다(이에 대한 내용은 뒤에서 다룬다). 캡슐화된 내부 객체는 weak reference에 의해 참조된다.\n</p>\n<p>다음은 WeakReference 클래스가 객체를 생성하는 예이다.\n</p>\n<p></p>\n<code>WeakReference&lt;Sample&gt; wr &#61; new WeakReference&lt;Sample&gt;( new Sample());<br>Sample ex &#61; wr.get();<br>...<br>ex &#61; null;\n</code><p></p>\n<p>위 코드의 첫 번째 줄에서 생성한 WeakReference 클래스의 객체는 new() 메서드로 생성된 Sample 객체를 캡슐화한 객체이다. 참조된 Sample 객체는 두 번째 줄에서 get() 메서드를 통해 다른 참조에 대입된다. 이 시점에서는 WeakReference 객체 내의 참조와 ex 참조, 두 개의 참조가 처음 생성한 Sample 객체를 가리킨다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 3 Weak Reference 예 1\n</strong></p>\n<p>위 코드의 마지막 줄에서 ex 참조에 null을 대입하면 처음 생성한 Sample 객체는 오직 WeakReference 내부에서만 참조된다. 이 상태의 객체를 weakly reachable 객체라고 하는데, 이에 대한 자세한 내용은 뒤에서 다룬다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 4 Weak Reference 예 2\n</strong></p>\n<p>Java 스펙에서는 SoftReference, WeakReference, PhantomReference 3가지 클래스에 의해 생성된 객체를 &#34;reference object&#34;라고 부른다. 이는 흔히 strong reference로 표현되는 일반적인 참조나 다른 클래스의 객체와는 달리 3가지 Reference 클래스의 객체에 대해서만 사용하는 용어이다. 또한 이들 reference object에 의해 참조된 객체는 &#34;referent&#34;라고 부른다. Java 스펙 문서를 참조할 때 이들 용어를 명확히 알면 좀 더 이해하기 쉽다. 위의 소스 코드에서 new WeakReference() 생성자로 생성된 객체는 reference object이고, new Sample() 생성자로 생성된 객체는 referent이다.\n</p>\n<h2>Reference와 Reachability\n</h2><p>앞에서 설명한 것처럼, 원래 GC 대상 여부는 reachable인가 unreachable인가로만 구분하였고 이를 사용자 코드에서는 관여할 수 없었다. 그러나 java.lang.ref 패키지를 이용하여 reachable 객체들을 strongly reachable, softly reachable, weakly reachable, phantomly reachable로 더 자세히 구별하여 GC 때의 동작을 다르게 지정할 수 있게 되었다. 다시 말해, GC 대상 여부를 판별하는 부분에 사용자 코드가 개입할 수 있게 되었다.\n</p>\n<p>두 번째 그림에서 몇몇 객체들을 WeakReference로 바꾸어서 예를 들어보면 다음과 같다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 5 Reachable, Unreachable, Weakly Reachable 예제\n</strong></p>\n<p>녹색으로 표시한 중간의 두 객체는 WeakReference로만 참조된 weakly reachable 객체이고, 파란색 객체는 strongly reachable 객체이다. GC가 동작할 때, unreachable 객체뿐만 아니라 weakly reachable 객체도 가비지 객체로 간주되어 메모리에서 회수된다. root set으로부터 시작된 참조 사슬에 포함되어 있음에도 불구하고 GC가 동작할 때 회수되므로, 참조는 가능하지만 반드시 항상 유효할 필요는 없는 LRU 캐시와 같은 임시 객체들을 저장하는 구조를 쉽게 만들 수 있다. \n</p>\n<p>위 그림에서 WeakReference 객체 자체는 weakly reachable 객체가 아니라 strongly reachable 객체이다. 또한, 그림에서 A로 표시한 객체와 같이 WeakReference에 의해 참조되고 있으면서 동시에 root set에서 시작한 참조 사슬에 포함되어 있는 경우에는 weakly reachable 객체가 아니라 strongly reachable 객체이다.\n</p>\n<p>GC가 동작하여 어떤 객체를 weakly reachable 객체로 판명하면, GC는 WeakReference 객체에 있는 weakly reachable 객체에 대한 참조를 null로 설정한다. 이에 따라 weakly reachable 객체는 unreachable 객체와 마찬가지 상태가 되고, 가비지로 판명된 다른 객체들과 함께 메모리 회수 대상이 된다. \n</p>\n<h2>Strengths of Reachability\n</h2><p>앞에서 설명한 것처럼 reachability는 총 5종류가 있고 이는 GC가 객체를 처리하는 기준이 된다. Java 스펙에서는 이들 5종류의 reachability를 &#34;Strengths of Reachability&#34;라 부른다. 앞의 예제 그림에서는 weakly reachable만 예를 들었기 때문에 WeakReference만 표시하였으나, SoftReference, PhantomReference 등을 이용하여 여러 가지 방식으로 reachability를 지정할 수 있고 이에 따라 각 객체들의 GC 여부는 다양하게 달라지게 된다. 하나의 객체에 대한 참조의 개수나 참조 형태에는 아무런 제한이 없으므로, 하나의 객체는 여러 strong reference, soft reference, weak reference, phantom reference의 다양한 조합으로 참조될 수 있다.\n</p>\n<p>Java GC는 root set으로부터 시작해서 객체에 대한 모든 경로를 탐색하고 그 경로에 있는 reference object들을 조사하여 그 객체에 대한 reachability를 결정한다. 다양한 참조 관계의 결과, 하나의 객체는 다음 5가지 reachability 중 하나가 될 수 있다. \n</p>\n<ul><li>strongly reachable: root set으로부터 시작해서 어떤 reference object도 중간에 끼지 않은 상태로 참조 가능한 객체, 다시 말해, 객체까지 도달하는 여러 참조 사슬 중 reference object가 없는 사슬이 하나라도 있는 객체\n</li><li>softly reachable: strongly reachable 객체가 아닌 객체 중에서 weak reference, phantom reference 없이 soft reference만 통과하는 참조 사슬이 하나라도 있는 객체\n</li><li>weakly reachable: strongly reachable 객체도 softly reachable 객체도 아닌 객체 중에서, phantom reference 없이 weak reference만 통과하는 참조 사슬이 하나라도 있는 객체\n</li><li>phantomly reachable: strongly reachable 객체, softly reachable 객체, weakly reachable 객체 모두 해당되지 않는 객체. 이 객체는 파이널라이즈(finalize)되었지만 아직 메모리가 회수되지 않은 상태이다.\n</li><li>unreachable: root set으로부터 시작되는 참조 사슬로 참조되지 않는 객체\n</li></ul><p>다음 예의 경우 객체 B의 reachability는 softly reachable이다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 6 Softly Reachable\n</strong></p>\n<p>root set으로부터 바로 SoftReference를 통해서 B를 참조할 수 있기 때문이다. 만약 root set의 SoftReference에 대한 참조가 없다면(즉, 왼쪽 아래 화살표를 삭제한다면), 객체 B는 phantomly reachable이 된다.\n</p>\n<h2>Softly Reachable과 SoftReference\n</h2><p>softly reachable 객체, 즉 strong reachable이 아니면서 오직 SoftReferencce 객체로만 참조된 객체는 힙에 남아 있는 메모리의 크기와 해당 객체의 사용 빈도에 따라 GC 여부가 결정된다. 그래서 softly reachable 객체는 weakly reachable 객체와는 달리 GC가 동작할 때마다 회수되지 않으며 자주 사용될수록 더 오래 살아남게 된다. Oracle HotSpot VM에서는 softly reachable 객체의 GC를 조절하기 위해 다음 JVM 옵션을 제공한다.\n</p>\n<p></p>\n<code>-XX:SoftRefLRUPolicyMSPerMB&#61;&lt;N&gt;\n</code><p></p>\n<p>이 옵션의 기본값은 1000이다. \n</p>\n<p>softly reachable 객체의 GC 여부는 위 옵션의 &lt;N&gt;에 설정한 숫자에 따라 다음 수식에 의해 결정된다.\n</p>\n<p></p>\n<code>(마지막 strong reference가 GC된 때로부터 지금까지의 시간) &gt; (옵션 설정값 N) * (힙에 남아있는 메모리 크기)\n</code><p></p>\n<p>어떤 객체가 사용된다는 것은 strong reference에 의해 참조되는 것이므로 위 수식의 좌변은 해당 객체가 얼마나 자주 사용되는지를 의미한다. 옵션 설정값이 1000이고 남아 있는 메모리가 100MB이면, 수식의 우변은 1,000ms/MB * 100MB &#61; 100,000ms &#61; 100sec, 즉 100초가 된다(옵션 이름 마지막이 MSPerMB로 끝나므로 옵션 설정값의 단위는 ms/MB임을 알 수 있다). 따라서 softly reachable 객체가 100초 이상 사용되지 않으면 GC에 의해 회수 대상이 된다. 힙에 남아있는 메모리가 작을수록 우변의 값이 작아지므로, 힙이 거의 소진되면 대부분의 softly reachable 객체는 모두 메모리에서 회수되어 OutOfMemoryError를 막게 될 것이다.\n</p>\n<p>softly reachable 객체를 GC하기로 결정되면 앞서 설명한 WeakReference 경우와 마찬가지로 참조 사슬에 존재하는 SoftReference 객체 내의 softly reachable 객체에 대한 참조가 null로 설정되며, 이후 이 softly reachable객체는 unreachable 객체와 마찬가지가 되어 GC의해 메모리가 회수된다.\n</p>\n<h2>Weakly Reachable과 WeakReference\n</h2><p>weakly reachable 객체는 특별한 정책에 의해 GC 여부가 결정되는 softly reachable 객체와는 달리 GC를 수행할 때마다 회수 대상이 된다. 앞서 설명한 것처럼 WeakReference 내의 참조가 null로 설정되고 weakly reachable 객체는 unreachable 객체와 마찬가지 상태가 되어 GC에 의해 메모리가 회수된다. 그러나 GC가 실제로 언제 객체를 회수할지는 GC 알고리즘에 따라 모두 다르므로, GC가 수행될 때마다 반드시 메모리까지 회수된다고 보장하지는 않는다. 이는 softly reachable 객체는 물론 unreachable 객체도 마찬가지이다. GC가 GC 대상인 객체를 찾는 작업과 GC 대상인 객체를 처리하여 메모리를 회수하는 작업은 즉각적인 연속 작업이 아니며, GC 대상 객체의 메모리를 한 번에 모두 회수하지도 않는다.\n</p>\n<p>LRU 캐시와 같은 애플리케이션에서는 softly reachable 객체보다는 weakly reachable 객체가 유리하므로 LRU 캐시를 구현할 때에는 대체로 WeakReference를 사용한다. softly reachable 객체는 힙에 남아 있는 메모리가 많을수록 회수 가능성이 낮기 때문에, 다른 비즈니스 로직 객체들을 위해 어느 정도 비워두어야 할 힙 공간이 softly reachable 객체에 의해 일정 부분 점유된다. 따라서 전체 메모리 사용량이 높아지고 GC가 더 자주 일어나며 GC에 걸리는 시간도 상대적으로 길어지는 문제가 있다.\n</p>\n<h2>ReferenceQueue\n</h2><p>phantomly reachable 객체의 동작과 PhantomReference를 설명하기 전에 java.lang.ref 패키지에서 제공하는 ReferenceQueue 클래스에 대해 설명할 필요가 있다. \n</p>\n<p>SoftReference 객체나 WeakReference 객체가 참조하는 객체가 GC 대상이 되면 SoftReference 객체, WeakReference 객체 내의 참조는 null로 설정되고 SoftReference 객체, WeakReference 객체 자체는 ReferenceQueue에 enqueue된다. ReferenceQueue에 enqueue하는 작업은 GC에 의해 자동으로 수행된다. ReferenceQueue의 poll() 메서드나 remove() 메서드를 이용해 ReferenceQueue에 이들 reference object가 enqueue되었는지 확인하면 softly reachable 객체나 weakly reachable 객체가 GC되었는지를 파악할 수 있고, 이에 따라 관련된 리소스나 객체에 대한 후처리 작업을 할 수 있다. 어떤 객체가 더 이상 필요 없게 되었을 때 관련된 후처리를 해야 하는 애플리케이션에서 이 ReferenceQueue를 유용하게 사용할 수 있다. Java Collections 클래스 중에서 간단한 캐시를 구현하는 용도로 자주 사용되는 WeakHashMap 클래스는 이 ReferenceQueue와 WeakReference를 사용하여 구현되어 있다.\n</p>\n<p>SoftReference와 WeakReference는 ReferenceQueue를 사용할 수도 있고 사용하지 않을 수도 있다. 이는 이들 클래스의 생성자 중에서 ReferenceQueue를 인자로 받는 생성자를 사용하느냐 아니냐로 결정한다. 그러나 PhantomReference는 반드시 ReferenceQueue를 사용해야만 한다. PhantomReference의 생성자는 단 하나이며 항상 ReferenceQueue를 인자로 받는다. \n</p>\n<p></p>\n<code>ReferenceQueue&lt;Object&gt; rq &#61; new ReferenceQueue&lt;Object&gt;();<br>PhantomReference&lt;Object&gt; pr &#61; new PhantomReference&lt;Object&gt;(referent, rq);\n</code><p></p>\n<p>SoftReference, WeakReference는 객체 내부의 참조가 null로 설정된 이후에 ReferenceQueue에 enqueue되지만, PhantomReference는 객체 내부의 참조를 null로 설정하지 않고 참조된 객체를 phantomly reachable 객체로 만든 이후에 ReferenceQueue에 enqueue된다. 이를 통해 애플리케이션은 객체의 파이널라이즈 이후에 필요한 작업들을 처리할 수 있게 된다. 더 자세한 내용은 다음 절에서 설명한다.\n</p>\n<h2>Phantomly Reachable과 PhantomReference\n</h2><p>softly reachable과 weakly reachable, phantomly reachable은 많이 다르다. 이를 설명하기 위해서는 먼저 GC 동작을 설명해야 한다. GC 대상 객체를 찾는 작업과 GC 대상 객체를 처리하는 작업이 연속적이지 않 듯이, GC 대상 객체를 처리하는 작업과 할당된 메모리를 회수하는 작업도 연속된 작업이 아니다. GC 대상 객체를 처리하는 작업, 즉 객체의 파이널라이즈 작업이 이루어진 후에 GC 알고리즘에 따라 할당된 메모리를 회수한다.\n</p>\n<p>GC 대상 여부를 결정하는 부분에 관여하는 softly reachable, weakly reachable과는 달리, phantomly reachable은 파이널라이즈와 메모리 회수 사이에 관여한다. strongly reachable, softly reachable, weakly reachable에 해당하지 않고 PhantomReference로만 참조되는 객체는 먼저 파이널라이즈된 이후에 phantomly reachable로 간주된다. 다시 말해, 객체에 대한 참조가 PhantomReference만 남게 되면 해당 객체는 바로 파이널라이즈된다. GC가 객체를 처리하는 순서는 항상 다음과 같다.\n</p>\n<ol><li>soft references\n</li><li>weak references\n</li><li>파이널라이즈\n</li><li>phantom references\n</li><li>메모리 회수\n</li></ol><p>즉, 어떤 객체에 대해 GC 여부를 판별하는 작업은 이 객체의 reachability를 strongly, softly, weakly 순서로 먼저 판별하고, 모두 아니면 phantomly reachable 여부를 판별하기 전에 파이널라이즈를 진행한다. 그리고 대상 객체를 참조하는 PhantomReference가 있다면 phantomly reachable로 간주하여 PhantomReference를 ReferenceQueue에 넣고 파이널라이즈 이후 작업을 애플리케이션이 수행하게 하고 메모리 회수는 지연시킨다.\n</p>\n<p>앞서 설명한 것처럼 PhatomReference는 항상 ReferenceQueue를 필요로 한다. 그리고 PhantomReference의 get() 메서드는 SoftReference, WeakReference와 달리 항상 null을 반환한다. 따라서 한 번 phantomly reachable로 판명된 객체는 더 이상 사용될 수 없게 된다. 그리고 phantomly reachable로 판명된 객체에 대한 참조를 GC가 자동으로 null로 설정하지 않으므로, 후처리 작업 후에 사용자 코드에서 명시적으로 clear() 메서드를 실행하여 null로 설정해야 메모리 회수가 진행된다.\n</p>\n<p>이와 같이, PhantomReference를 사용하면 어떤 객체가 파이널라이즈된 이후에 할당된 메모리가 회수되는 시점에 사용자 코드가 관여할 수 있게 된다. 파이널라이즈 이후에 처리해야 하는 리소스 정리 등의 작업이 있다면 유용하게 사용할 수 있다. 그러나 개인적으로는 PhantomReference를 사용하는 코드를 거의 본 적이 없으며, 그 효용성에 대해서는 의문이 있다.\n</p>\n<h2>마치며\n</h2><p>Java의 Reference는 그 선후 관계와 용어가 복잡해서 글로 쉽게 풀어쓰기가 어려워 본문이 꽤 장황해졌다. 본문의 내용을 간단히 요약하면 다음과 같다.\n</p>\n<ul><li>Java GC는 GC 대상 객체를 찾고, 대상 객체를 처리(finalization)하고, 할당된 메모리를 회수하는 작업으로 구성된다.\n</li><li>애플리케이션은 사용자 코드에서 객체의 reachability를 조절하여 Java GC에 일부 관여할 수 있다.\n</li><li>객체의 reachability를 조절하기 위해서 java.lang.ref 패키지의 SoftReference, WeakReference, PhantomReference, ReferenceQueue 등을 사용한다.\n</li></ul><p>개인적으로는 내부 캐시 등을 구현하고자 하는 대부분의 애플리케이션에서는 WeakReference 혹은 이를 이용한 WeakHashMap만으로도 충분하다고 생각한다. 다른 애플리케이션에서는 가끔 SoftReference를 사용하는 경우도 있지만, PhantomReference는 거의 예제가 없으며 그만큼 불필요할 것이다. 이들 Java Reference들과 관련된 GC 동작을 잘 이해하면 Java의 heap 메모리 문제에서 더욱 유연한 애플리케이션 작성에 크게 도움이 될 것이다.\n</p>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 웹플랫폼개발랩 박세훈\n&#9;&#9;영화 &lt;코드명 J&gt;의 원작 소설 이 발표된 것은 1981년이다. 저자인 윌리엄 깁슨은 대량의 데이터를 전달하려면 사람의 두뇌를 써야 할 것이라고 생각했다. 30년이 지나 사람은 두뇌를 사용하는 대신 손톱보다 작고 훨씬 대용량인 메모리카드를 만들어냈다. IT 기술이 이렇게 빠르게 발전하고 그만큼 데이터양도 늘어나고 있지만 메모리카드와 비교도 안 되게 좁은 필자의 두뇌에는 아직도 채워야 할 내용이 많은 것 같다. 그래서 언제나 무언가를 채우기 위해 돌아다니고 두리번거리고 있다.\n&#9;&#9;\n</div></div>"},{"name":"안전한 패스워드 저장","published":1364197068,"description":"<div><p>NHN Business Platform 회원플랫폼개발랩 김종수\n&#9;</p>\n<p>&#34;보안 시스템은 가장 약한 연결 고리만큼만 강하다.&#34;\n</p>\n<p>보안 시스템은 여러 부분으로 이뤄집니다. 공격자(attacker)는 이 중에서 가장 취약한 부분을 공격할 것이라고 가정해야 합니다. 보안 시스템이라는 사슬에서 가장 약한 고리가 끊어지면 다른 고리가 얼마나 강한지는 문제가 되지 않습니다. 즉, 보안 시스템의 안정성은 &#39;강한 부분이 얼마나 강한가&#39;보다는 &#39;약한 부분이 얼마나 약한가&#39;에 따라서 좌우됩니다.\n</p>\n<p>지난해 6월 세계 최대 비즈니스 전문 소셜 네트워크 서비스(SNS) LinkedIn은 사용자 데이터 해킹 사고로 650만 명의 아이디와 패스워드 정보가 유출된 후 집단 소송을 당했습니다. 취약한 암호화 알고리즘인 SHA-1을 사용했다는 것이 그 이유였습니다. 이제 보안 시스템의 한 부분인 암호화 알고리즘으로 어떤 알고리즘을 선택했는지도 보안의 책임을 다했는지 판단할 때 중요한 요소입니다.</p>\n<p>이 글에서는 보안 시스템의 여러 부분 중, 패스워드를 저장할 때 사용되는 해시 함수(hash function)의 개념을 설명하고 대부분의 웹 사이트에서 사용하고 있는 암호화 알고리즘의 안정성을 검토하겠습니다. 그리고 어떤 암호화 알고리즘을 사용해야 안전한지 설명하겠습니다.\n</p>\n<h2>단방향 해시 함수\n</h2><p>보통 프로그래머는 아래의 두 가지 중 한 가지로 사용자의 패스워드를 저장한다.\n</p>\n<ul><li>단순 텍스트(plain text)\n</li><li>단방향 해시 함수(one-way hash function)의 다이제스트(digest)\n</li></ul><p>단순 텍스트로 패스워드를 저장하는 것은 범죄를 저지르는 것이나 다름없다. 아직도 이런 방법을 사용하고 있다면 지금 당장 변경해야 한다.\n</p>\n<p>단방향 해시 함수는 수학적인 연산을 통해 원본 메시지를 변환하여 암호화된 메시지인 다이제스트를 생성한다. 원본 메시지를 알면 암호화된 메시지를 구하기는 쉽지만 암호화된 메시지로는 원본 메시지를 구할 수 없어야 하며 이를 &#39;단방향성&#39;이라고 한다.\n</p>\n<p>예를 들어 사용자의 패스워드가 &#34;hunter2&#34;라면 이 문자열을 흔히 사용하는 해시 알고리즘인 SHA-256으로 인코딩하여 아래와 같은 값을 얻을 수 있다.\n</p>\n<p></p>\n<code>f52fbd32b2b3b86ff88ef6c490628285f482af15ddcb29541f94bcf526a3f6c7\n</code><p></p>\n<p>위의 값을 저장하면 사용자의 패스워드를 직접 저장하는 위험을 피할 수 있다. 그리고 사용자가 로그인할 때 패스워드를 입력하면, 이를 해시한 값을 저장된 값과 비교하여 일치 여부를 확인할 수 있다.\n</p>\n<p>대부분의 해시 함수는 입력 값의 일부가 변경되었을 때 다이제스트가 완전히 달라지도록 설계되어 있다. &#34;hunter3&#34;라는 값의 SHA-256 다이제스트는 아래와 같으며 위의 &#34;hunter2&#34;와는 완전히 달라진 것을 확인할 수 있다.\n</p>\n<p></p>\n<code>fb8c2e2b85ca81eb4350199faddd983cb26af3064614e737ea9f479621cfa57a\n</code><p></p>\n<p>이 특징을 avalanche 효과라고 하며, 사용자의 원본 패스워드를 추론하기 어렵게 만드는 중요한 요소이다. 그러나 이것만으로는 패스워드 보안이 충분히 안전하다고 말할 수 없다.\n</p>\n<h2>단방향 해시 함수의 문제점\n</h2><p>대부분의 웹 사이트에서는 SHA-256과 같은 해시 함수를 사용해 패스워드를 암호화해 저장하고 값을 비교하는 것만으로 충분한 암호화 메커니즘을 적용했다고 생각하지만, 실제로는 다음과 같은 두 가지 문제점이 있다.\n</p>\n<h3>인식 가능성(recognizability)\n</h3><p>동일한 메시지가 언제나 동일한 다이제스트를 갖는다면, 공격자가 전처리(pre-computing)된 다이제스트를 가능한 한 많이 확보한 다음 이를 탈취한 다이제스트와 비교해 원본 메시지를 찾아내거나 동일한 효과의 메시지를 찾을 수 있다. 이와 같은 다이제스트 목록을 레인보우 테이블(rainbow table)이라 하고, 이와 같은 공격 방식을 레인보우 공격(rainbow attack)이라 한다. 게다가 다른 사용자의 패스워드가 같으면 다이제스트도 같으므로 한꺼번에 모두 정보가 탈취될 수 있다.\n</p>\n<h3>속도(speed)\n</h3><p>해시 함수는 암호학에서 널리 사용되지만 원래 패스워드를 저장하기 위해서 설계된 것이 아니라 짧은 시간에 데이터를 검색하기 위해 설계된 것이다. 바로 여기에서 문제가 발생한다. 해시 함수의 빠른 처리 속도로 인해 공격자는 매우 빠른 속도로 임의의 문자열의 다이제스트와 해킹할 대상의 다이제스트를 비교할 수 있다(MD5를 사용한 경우 일반적인 장비를 이용하여 1초당 56억 개의 다이제스트를 대입할 수 있다).\n</p>\n<p>이런 방식으로 패스워드를 추측하면 패스워드가 충분히 길거나 복잡하지 않은 경우에는 그리 긴 시간이 걸리지 않는다. 그리고 대부분 사용자의 패스워드는 길거나 복잡하지 않을 뿐 아니라, 동일한 패스워드를 사용하는 경우도 많다.\n</p>\n<p>반면 사용자는 웹 사이트에서 패스워드를 인증하는 데 걸리는 시간에는 그리 민감하지 않다. 사용자가 로그인하기 위해 아이디와 패스워드를 입력하고 확인 버튼을 누르는 과정에 10초가 걸린다고 가정했을 때, 다이제스트를 생성하는 데 0.1초 대신 1초가 소요된다고 해서 크게 신경 쓰는 사람은 많지 않다. 즉, 해시 함수의 빠른 처리 속도는 사용자들보다 공격자들에게 더 큰 편의성을 제공하게 된다.\n</p>\n<h2>단방향 해시 함수 보완하기\n</h2><h3>솔팅(salting)\n</h3><p>솔트(salt)는 단방향 해시 함수에서 다이제스트를 생성할 때 추가되는 바이트 단위의 임의의 문자열이다. 그리고 이 원본 메시지에 문자열을 추가하여 다이제스를 생성하는 것을 솔팅(salting)이라 한다. 예를 들어 다음과 같이 &#34;redfl0wer&#34;에 솔트인 &#34;8zff4fgflgfd93fgdl4fgdgf4mlf45p1&#34;를 추가해 다이제스트를 생성할 수 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 패스워드 &#34;redfl0wer&#34;에 솔트를 추가해 다이제스트 생성\n</strong></p>\n<p>이 방법을 사용하면, 공격자가 &#34;redfl0wer&#34;의 다이제스트를 알아내더라도 솔팅된 다이제스트를 대상으로 패스워드 일치 여부를 확인하기 어렵다. 또한 사용자별로 다른 솔트를 사용한다면 동일한 패스워드를 사용하는 사용자의 다이제스트가 다르게 생성되어 인식 가능성 문제가 크게 개선된다.\n</p>\n<p>솔트와 패스워드의 다이제스트를 데이터베이스에 저장하고, 사용자가 로그인할 때 입력한 패스워드를 해시하여 일치 여부를 확인할 수 있다. 이 방법을 사용할 때에는 모든 패스워드가 고유의 솔트를 갖고 솔트의 길이는 32바이트 이상이어야 솔트와 다이제스트를 추측하기 어렵다.\n</p>\n<h3>키 스트레칭(key stretching)\n</h3><p>입력한 패스워드의 다이제스트를 생성하고, 생성된 다이제스트를 입력 값으로 하여 다이제스트를 생성하고, 또 이를 반복하는 방법으로 다이제스트를 생성할 수도 있다. 이렇게 하면 입력한 패스워드를 동일한 횟수만큼 해시해야만 입력한 패스워드의 일치 여부를 확인할 수 있다. 이것이 기본적인 키 스트레칭 과정이다.\n</p>\n<p>잘 설계된 패스워드 저장 시스템에서는 하나의 다이제스트를 생성할 때 어느 정도(일반적인 장비에서 0.2초 이상)의 시간이 소요되게 설정한다. 이는 억지 기법 공격(brute-force attack)으로 패스워드를 추측하는 데 많은 시간이 소요되도록 하기 위한 것이다.\n</p>\n<p>최근에는 일반적인 장비로 1초에 50억 개 이상의 다이제스트를 비교할 수 있지만, 키 스트레칭을 적용하여 동일한 장비에서 1초에 5번 정도만 비교할 수 있게 한다. GPU(Graphics Processing Unit)를 사용하더라도 수백에서 수천 번 정도만 비교할 수 있다. 50억 번과는 비교할 수도 없을 정도로 적은 횟수다. 앞으로 컴퓨터 성능이 더 향상되면 몇 번의 반복을 추가하여 보완할 수 있다.\n</p>\n<p>다음 그림은 솔트를 추가한 패스워드에 여러 단계의 해시 함수를 적용하여 다이제스트를 생성하는 과정을 나타낸 것이다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 솔팅과 키 스트레칭을 적용하여 다이제스트 생성\n</strong></p>\n<p>앞에서 설명한 바와 같이 솔팅과 키 스트레칭으로 구성된 암호화 시스템을 구현하려고 한다면 이미 검증된 암호화 시스템을 사용할 것을 권장한다. 널리 알려진 검증된 시스템을 사용하면, 암호화 시스템을 잘못 구현해서 발생하는 위험을 피할 수 있다.\n</p>\n<p>이에 비해 자신만의 암호화 시스템을 구현하는 것은 매우 위험하다. 이 경우 취약점을 확인하기 어렵고, 대부분의 경우 구현된 암호화 시스템을 점검하고 확인하는 사람은 암호화 시스템을 구현한 당사자 한 명이다. 만약 구현한 암호화 시스템에 취약점이 있다면, 많은 사람들이 사용할수록 그만큼 많은 사람들이 피해를 입게 된다. 이런 취약점이 내포된 시스템은 여러 차례 발견되었고, 이와 같은 시스템을 사용한 프로그램들이 여러 해 동안 BSD나 Linux에서 사용되어 왔다.\n</p>\n<p>다음 절에서는 위에서 설명한 사항들을 고려하여 선택할 수 있는 대안을 제시한다.\n</p>\n<h2>Adaptive Key Derivation Functions\n</h2><p>adaptive key derivation function은 다이제스트를 생성할 때 솔팅과 키 스트레칭을 반복하며 솔트와 패스워드 외에도 입력 값을 추가하여 공격자가 쉽게 다이제스트를 유추할 수 없도록 하고 보안의 강도를 선택할 수 있다.\n</p>\n<p>이 함수들은 GPU와 같은 장비를 이용한 병렬화를 어렵게 하는 기능을 제공한다. 이와 같은 기능은 프로그램이 언어에서 제공하는 라이브러리만으로는 구현하기 어렵다.\n</p>\n<p>adaptive key derivation function 중 주요한 key derivation function은 다음과 같다.\n</p>\n<h3>PBKDF2\n</h3><p>가장 많이 사용되는 key derivation function은 PBKDF2(Password-Based Key Derivation Function)이다. 해시 함수의 컨테이너인 PBKDF2는 솔트를 적용한 후 해시 함수의 반복 횟수를 임의로 선택할 수 있다. PBKDF2는 아주 가볍고 구현하기 쉬우며, SHA와 같이 검증된 해시 함수만을 사용한다.\n</p>\n<p>PBKDF2의 기본 파라미터는 다음과 같은 5개 파라미터다.\n</p>\n<p></p>\n<code>DIGEST &#61; PBKDF2(<strong>PRF</strong>, <strong>Password</strong>, <strong>Salt</strong>, <strong>c</strong>, <strong>DLen</strong>)\n</code><p></p>\n<ul><li>PRF: 난수(예: HMAC)\n</li><li>Password: 패스워드\n</li><li>Salt: 암호학 솔트\n</li><li>c: 원하는 iteration 반복 수\n</li><li>DLen: 원하는 다이제스트 길이\n</li></ul><p>PBKDF2는 NIST(National Institute of Standards and Technology, 미국표준기술연구소)에 의해서 승인된 알고리즘이고, 미국 정부 시스템에서도 사용자 패스워드의 암호화된 다이제스트를 생성할 때 사용한다.\n</p>\n<h3>bcrypt\n</h3><p>bcrypt는 애초부터 패스워드 저장을 목적으로 설계되었다. Niels Provos와 David Mazières가 1999년 발표했고 현재까지 사용되는 가장 강력한 해시 메커니즘 중 하나이다. bcrypt는 보안에 집착하기로 유명한 OpenBSD에서 기본 암호 인증 메커니즘으로 사용되고 있고 미래에 PBKDF2보다 더 경쟁력이 있다고 여겨진다. \n</p>\n<p>bcrypt에서 &#34;work factor&#34; 인자는 하나의 해시 다이제스트를 생성하는 데 얼마만큼의 처리 과정을 수행할지 결정한다. &#34;work factor&#34;를 조정하는 것만으로 간단하게 시스템의 보안성을 높일 수 있다.\n</p>\n<p>다만 PBKDF2나 scrypt와는 달리 bcrypt는 입력 값으로 72 bytes character를 사용해야 하는 제약이 있다.\n</p>\n<p></p>\n<code>// Sample code for jBCrypt is a Java<br>// gensalt is work factor and the default is 10<br>String hashed &#61; BCrypt.hashpw(password, BCrypt.gensalt(11));<br><br>// Check that an unencrypted password matches one that has<br>// previously been hashed<br>if (BCrypt.checkpw(candidate, hashed))<br>    System.out.println(&#34;It matches&#34;);<br>else<br>    System.out.println(&#34;It does not match&#34;);\n</code><p></p>\n<h3>scrypt\n</h3><p>scrypt는 PBKDF2와 유사한 adaptive key derivation function이며 Colin Percival이 2012년 9월 17일 설계했다. scrypt는 다이제스트를 생성할 때 메모리 오버헤드를 갖도록 설계되어, 억지 기법 공격(brute-force attack)을 시도할 때 병렬화 처리가 매우 어렵다. 따라서 PBKDF2보다 안전하다고 평가되며 미래에 bcrypt에 비해 더 경쟁력이 있다고 여겨진다. scrypt는 보안에 아주 민감한 사용자들을 위한 백업 솔루션을 제공하는 Tarsnap에서도 사용하고 있다. 또한 scrypt는 여러 프로그래밍 언어의 라이브러리로 제공받을 수 있다.\n</p>\n<p>scrypt의 파라미터는 다음과 같은 6개 파라미터다.\n</p>\n<p></p>\n<code>DIGEST &#61; scrypt(<strong>Password</strong>, <strong>Salt</strong>, <strong>N</strong>, <strong>r</strong>, <strong>p</strong>, <strong>DLen</strong>)\n</code><p></p>\n<ul><li>Password: 패스워드\n</li><li>Salt: 암호학 솔트\n</li><li>N: CPU 비용 \n</li><li>r: 메모리 비용\n</li><li>p: 병렬화(parallelization)\n</li><li>DLen: 원하는 다이제스트 길이\n</li></ul><h2>마치며\n</h2><p>MD5, SHA-1, SHA-256, SHA-512 등의 해시 함수는 메시지 인증과 무결성 체크를 위한 것이다. 이것을 패스워드 인증을 위해 사용하면 앞에서 말한 인식 가능성과 빠른 처리 속도에 기인하는 취약점이 존재한다.\n</p>\n<p>이를 해결하기 위해서는 위에서 언급한 key derivation function을 사용하는 것을 권장한다.\n</p>\n<p>ISO-27001의 보안 규정을 준수하고, 서드파티의 라이브러리에 의존하지 않으면서 사용자 패스워드의 다이제스트를 생성하려면 PBKDF2-HMAC-SHA-256/SHA-512을 사용하면 된다.\n</p>\n<p>매우 강력한 패스워드 다이제스트를 생성하는 시스템을 쉽게 구현하고 싶다면 bcrypt를 사용하는 것이 좋다. 대부분의 프로그래밍 언어에서 라이브러리를 사용할 수 있고, 검색 엔진에서 &#34;bcrypt &lt;프로그래밍 언어&gt;&#34;로 검색하면 쉽게 예제를 구할 수 있다.\n</p>\n<p>구현하려는 시스템이 매우 민감한 정보를 다루고, 보안 시스템을 구현하는 데 많은 비용을 투자할 수 있다면 scrypt를 사용하면 된다.\n</p>\n<p>이와 함께 패스워드 보안을 위해 더 쉽게 취할 수 있는 조치가 있다.\n</p>\n<p>패스워드 다이제스트의 강도는 결국 패스워드 자체의 길이와 유일성 같은 엔트로피에 의해서 결정된다. 따라서 사용자가 안전한 패스워드를 설정하도록 패스워드 정책을 설정하는 것이 매우 중요하다. 사용자가 모두 다른 패스워드를 사용하도록 강제하는 것이 최상이겠지만 현실적으로는 어렵기 때문에 최대한 긴 패스워드를 사용하도록 권장해야 한다.\n</p>\n<h2>참고자료\n</h2><ol><li>닐스 퍼거슨∙브루스 슈나이어∙타다요시 쿄노, 실용 암호학, 에이콘, 2011.\n</li><li>PBKDF2: <a href=\"http://en.wikipedia.org/wiki/PBKDF2\">http://en.wikipedia.org/wiki/PBKDF2</a>\n&#9;&#9;</li><li>bcrypt: <a href=\"http://en.wikipedia.org/wiki/Bcrypt\">http://en.wikipedia.org/wiki/Bcrypt</a>\n&#9;&#9;</li><li>scrypt: <a href=\"http://en.wikipedia.org/wiki/scrypt\">http://en.wikipedia.org/wiki/scrypt</a>\n&#9;&#9;</li><li>password security: <a href=\"http://throwingfire.com/storing-passwords-securely/\">http://throwingfire.com/storing-passwords-securely/</a>\n&#9;&#9;</li><li>Java crypt: <a href=\"http://www.mindrot.org/projects/jBCrypt/\">http://www.mindrot.org/projects/jBCrypt/</a>\n&#9;&#9;</li><li>Java scrypt: <a href=\"http://www.jarvana.com/jarvana/view/com/lambdaworks/scrypt/1.0/scrypt-1.0-sources.jar!/com/lambdaworks/crypto/SCrypt.java\">http://www.jarvana.com/jarvana/view/com/lambdaworks/scrypt/1.0/scrypt-1.0-sources.jar!/com/lambdaworks/crypto/SCrypt.java</a>\n&#9;&#9;</li><li>ighashgpu - SHA1, MD5 &amp; MD4 해시 크래커: <a href=\"http://kldp.org/node/109911\">http://kldp.org/node/109911</a>\n&#9;&#9;</li></ol>\n\n<div>\n&#9;<div>\n&#9;&#9;\n\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 회원플랫폼개발랩 김종수\n&#9;&#9;회원플랫폼개발랩에서 네이버 회원관리 업무를 담당하고 있다. 보안과 사용자 편의성이라는 두 마리의 토끼를 잡으려고 노력 중이고 새로운 것을 놓치지 않고자 두 눈 크게 뜨고 살아가려 한다.\n                <br>\n&#9;&#9;\n</div></div>"},{"name":"네트워크 트래픽 분석 기술, NetFlow 소개와 활용","published":1363330033,"description":"<div><p>NHN Business Platform 인프라솔루션개발랩 이동규\n&#9;</p>\n<p>NetFlow는 Cisco Systems가 개발한 네트워크 프로토콜로, 누가 언제 어디서 무엇을 어떻게 하는 데에 네트워크를 사용하는지에 관한 정보를 제공합니다. 이와 같은 정보를 분석하면 장애를 유발할 수 있는 네트워크 취약점을 파악하여 장애를 예방할 수 있으며 효율적으로 네트워크를 운영할 수 있습니다. 이는 곧 비용 절감과 수익 향상으로 이어집니다.\n</p>\n<p>10여 년 전에 발표된 이 기술이 요즘 더욱 각광을 받는 것은 최근 급변하는 IT 환경 때문입니다. 사용자는 모바일로 급속히 옮겨가고 서버에는 가상화와 클라우드가 도입되면서, 어떤 애플리케이션이 얼마만큼의 트래픽을 발생하는지 분석할 필요성이 생겼습니다. 또한 전통적인 데이터에 영상과 음성이 통합되면서 통신 품질을 보장하기 위해 더 높은 네트워크 효율에 대한 요구가 증가하고 있습니다.\n</p>\n<p>이 글에서는 네트워크가 어떻게 사용되고 있는지 보여 줄 수 있는 중요한 기술인 NetFlow를 소개합니다.\n</p>\n<h2>전통적인 SNMP 성능 모니터링\n</h2><p>전통적으로는 네트워크를 모니터링할 때 전적으로 SNMP(Simple Network Management Protocol)에 의존했다. SNMP를 이용하면 특정 구간의 트래픽이 얼마나 되는지, 특정 스위치의 트래픽이 얼마나 되는지에 대한 실시간 데이터를 &lt;그림 1&gt;과 같이 bps(bits per second) 단위로 볼 수 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 네트워크 모니터링 그래프\n</strong></p>\n<p>그런데 어디에서 이런 트래픽이 시작되는지, 어떤 애플리케이션이 사용하는지 또는 특정 소스에서 어느 정도의 대역폭을 사용하는지와 같은 정보를 알고 싶은 때가 있다. 이런 정보는 SNMP를 이용한 모니터링만으로 알 수 없다. 물론 모든 패킷을 분석하면 가능하지만, 10Gbps 이상의 트래픽을 실시간으로 분석하려면 리소스가 너무 많이 필요하다.\n</p>\n<p>그래서 흐름(flow)이라는 개념이 사용된다. RFC 3917에서는 흐름을 &#34;특정 시간 동안 네트워크상의 지정된 관찰 지점을 지나가는 패킷의 집합&#34;이라고 정의한다. 간단히 이야기하면 흐름이란 패킷의 출발지와 목적지 정보 등을 가진 데이터라고 할 수 있다.\n</p>\n<p>SNMP는 트래픽 정보를 실시간으로 제공할뿐 아니라 네트워크 장비의 CPU와 메모리 사용량도 제공한다(NetFlow는 IP 흐름의 시작 시간과 종료 시간을 제공하지만 SNMP와 같은 수준의 실시간 데이터를 제공하지는 못한다). 이처럼 SNMP의 장점도 있지만 트래픽의 특성을 파악하기에는 부족하다. 따라서 더 많은 정보를 갖고 있는 NetFlow를 사용하여 IP 흐름의 특성을 파악하는 것을 권장한다.\n</p>\n<h2>네트워크 상황 분석을 위한 NetFlow\n</h2><p>네트워크 흐름이 어디에서 어디로 어떻게 가는지를 이해하고 분석하는 것은 네트워크 성능에 매우 중요하다. 흐름을 분석하면 더 정확하게 네트워크 장비의 용량을 산정할 수 있으며, 목적에 따라 QoS(Quality of Service)를 적절히 적용하여 네트워크 리소스 사용을 최적화할 수 있다. 또한 네트워크 흐름을 분석한 정보는 보안적인 측면에서 DoS(Denial of Service)와 네트워크에서 생성되는 웜(worm) 등 여러 보안 위협을 탐지하는 데 중요한 역할을 한다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 NetFlow 구조(이미지 출처: <a href=\"http://en.wikipedia.org/wiki/Netflow\">http://en.wikipedia.org/wiki/Netflow</a>)\n</strong></p>\n<p>NetFlow는 IT 인프라에서 발생하는 여러 문제를 해결하는 데 다음과 같은 도움을 준다.\n</p>\n<ul><li>새로운 애플리케이션이 유발하는 네트워크 변화 분석<br>VoIP나 원격지의 상황 변화와 같은 새로운 네트워크 환경을 분석한다.\n</li><li>WAN 통신 사용량 최대값 감소<br>네트워크 사용량이 많은 애플리케이션을 분석하고, 애플리케이션 정책 변경에 따른 WAN 통신 영향을 측정한다.\n</li><li>네트워크 구성의 취약점 파악 및 문제 해결<br>네트워크 사용이 많은 지점(hog)이 있거나 네트워크 성능이 낮을 때 명령어 인터페이스(CLI, Command Line Interface)나 리포트 도구를 사용해서 원인을 진단한다.\n</li><li>권한 없는 WAN 통신 탐지<br>네트워크 폭주를 유발하는 애플리케이션을 구별함으로써 네트워크 효율성을 높여 비용을 절감한다.\n</li><li>비정상적인 활동 탐지 및 보안<br>비정상적인 활동 탐지와 웜 분석에 사용할 수 있다.\n</li><li>QoS 매개변수 유효성 검사<br>각 CoS(Class of Service)에 적절한 대역폭이 할당되어 있는지, 대역폭이 너무 크거나 작게 할당되는 경우는 없는지 확인한다.\n</li></ul><h2>NetFlow의 네트워크 흐름 분석\n</h2><p>스위치나 라우터를 통하는 패킷들은 IP 패킷 속성으로 구분할 수 있다. 이런 속성은 IP 패킷의 지문 또는 신분증과 같으며, 패킷이 새로운 것인지 아니면 다른 것과 비슷한 것인지를 구분한다.\n</p>\n<p>전통적으로 IP 흐름 분석은 IP 패킷 속성 중 5개에서 많게는 7개의 속성을 기반으로 한다. NetFlow가 사용하는 IP 패킷의 속성은 다음과 같다.\n</p>\n<ul><li>출발지 IP 주소\n</li><li>목적지 IP 주소\n</li><li>출발지 포트\n</li><li>목적지 포트\n</li><li>레이어 3 프로토콜\n</li><li>CoS(Class of Service)\n</li><li>라우터 또는 스위치 인터페이스\n</li></ul><p>출발지/도착지 IP 주소, 포트, 프로토콜 인터페이스, CoS가 같은 패킷은 하나의 흐름으로 묶인다. 그리고 하나로 묶은 흐름의 패킷과 바이트는 더한다. 이렇게 수집된 대용량의 네트워크 정보는 NetFlow 캐시라고 불리는 NetFlow 데이터베이스에 저장되므로 추후에 쉽게 확장 가능하다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 3 NetFlow 캐시에서 Flow 생성(이미지 출처: <a href=\"http://www.cisco.com/en/US/prod/collateral/iosswrel/ps6537/ps6555/ps6601/prod_white_paper0900aecd80406232.html\">http://www.cisco.com/en/US/prod/collateral/iosswrel/ps6537/ps6555/ps6601/prod_white_paper0900aecd80406232.html</a>)\n</strong></p>\n<p>이 흐름은 네트워크 현황을 이해하는 데 매우 유용하다.\n</p>\n<ul><li>누가 트래픽을 시작했는지 출발지 주소로 알 수 있다.\n</li><li>누가 트래픽을 받는지 목적지 주소로 알 수 있다.\n</li><li>어떤 애플리케이션이 트래픽을 얼마나 어떻게 사용하는지 포트 정보로 알 수 있다.\n</li><li>CoS로 트래픽의 우선순위를 확인하여 통신 품질을 보장할 수 있다.\n</li><li>네트워크 장비가 어떻게 트래픽을 사용하는지 인터페이스 정보로 알 수 있다.\n</li><li>누적된 패킷과 바이트 수로 트래픽의 양을 알 수 있다.\n</li></ul><h2>NetFlow의 데이터 접근 방법\n</h2><p>NetFlow의 데이터에 접근하는 방법은 기본적으로 크게 두 가지이다. 명령어 인터페이스와 리포트 도구이다. 즉각적으로 네트워크 현황을 파악해야 한다면 NetFlow CLI(Command Line Interface)를 사용하면 된다. CLI는 문제 해결에 매우 유용하다.\n</p>\n<p>또는 NetFlow 정보를 &#34;NetFlow collector&#34;라 불리는 원격 서버로 보낼 수 있다. NetFlow collector는 전송된 흐름 정보를 수집, 분석하고 종합하여 트래픽과 보안 정보를 분석한다. SNMP polling과는 달리, NetFlow export는 정기적으로 NetFlow collector에 정보를 푸시한다. 일반적으로 NetFlow 캐시는 지속적으로 흐름 정보를 저장하고, 스위치나 라우터는 NetFlow 캐시에서 종료되거나 소멸된 흐름 정보를 찾아서 NetFlow collector 서버로 보낸다. 네트워크 통신이 끝나면 TCP 통신에서는 TCP FIN 플래그를 받으면서 흐름이 종료된다.\n</p>\n<p>NetFlow 정보 리포트 기능을 구현하려면 다음 단계를 따른다.\n</p>\n<ol><li>NetFlow는 흐름을 캡처하여 NetFlow 캐시에 흐름 정보를 저장하도록 설정한다.\n</li><li>NetFlow export는 Collector로 흐름 정보를 보내도록 설정한다.\n</li><li>NetFlow export는 NetFlow 캐시에서 종료된 흐름 정보를 찾아서 NetFlow collector로 전송한다.\n</li><li>약 30에서 50개의 흐름 정보가 묶여서 UDP 형식으로 NetFlow collector 서버에 전송된다.\n</li><li>NetFlow collector 소프트웨어는 수집한 데이터로 실시간 또는 통계 리포트를 생성한다.\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 4 NetCache의 데이터 흐름(이미지 출처: <a href=\"http://www.cisco.com/en/US/prod/collateral/iosswrel/ps6537/ps6555/ps6601/prod_white_paper0900aecd80406232.html\">http://www.cisco.com/en/US/prod/collateral/iosswrel/ps6537/ps6555/ps6601/prod_white_paper0900aecd80406232.html</a>)\n</strong></p>\n<h2>흐름 정보 전송 시기 결정\n</h2><p>특정 시간 동안 새로운 패킷이 도착하지 않거나 흐름이 타이머보다 더 오래 지속되었을 때, 또는 TCP 플래그가 흐름 종료를 알려주었을 때(FIN, RST 플래그) 흐름 정보는 NetFlow collector로 전송될 준비가 된다. 흐름이 비활성 상태인지 또는 너무 오래 지속되었는지 측정하는 타이머가 있는데, 비활성 흐름 타이머의 초기값은 15초이고 활성 흐름 타이머의 초기값은 30분이다.\n</p>\n<p>NetFlow collector는 흐름을 합치고 트래픽을 모을 수 있다. 예를 들어, 활성 흐름 타이머보다 길게 지속되는 FTP 다운로드는 여러 개의 흐름으로 나뉘어 전송될 수 있으며, NetFlow collector는 해당 흐름을 모아서 특정 시간 동안의 FTP 통신 트래픽을 보여줄 수 있다. \n</p>\n<h2>흐름의 export 데이터 형식\n</h2><p>일반적으로 export version이라고 불리는 여러 종류의 export packet 형식이 있다. 이 export version에는 version 5, 7, 9 등이 있는데 가장 많이 사용하는 것은 NetFlow export version 5이다. version 9가 가장 최근의 형식이며, 보안, 트래픽 분석, 멀티캐스트 등에서 이점이 있다.\n</p>\n<h2>NetFlow의 발달\n</h2><p>NetFlow의 발달은 캐싱 기술의 발달과 함께했다. NetFlow를 사용하려는 많은 시도가 있었지만, 몇 해 전까지만 해도 NetFlow 설정 때문에 과도한 NetFlow 캐싱을 수행하여 스위칭 역할까지 제대로 수행하지 못하는 경우도 있었다. 최근에는 NetFlow 기술이 많이 안정화되었고, 트래픽 분석과 트래픽 통신을 아무런 문제없이 동시에 수행하는 많은 장비가 있다.\n</p>\n<p>Cisco Systems는 NetFlow의 업그레이드 버전인 Flexible NetFlow까지 선보여 더 정확한 분석을 가능하게 했다. 최근에는 많은 Network 장비 벤더에서 NetFlow와 유사한 기술인 SFlow, CFlow를 지원하는 장비를 판매하고 있다.\n</p>\n<h2>마치며\n</h2><p>인터넷 초창기에는 네트워크상에서 대역폭이 얼마나 사용되고 있는지만 알아도 충분했지만 요즘은 그것만으로 충분하지 않다. 왜냐하면 네트워크가 거의 항상 사용되고 있어 단순 대역폭 사용량만으로는 네트워크 현황이나 문제점을 분석할 수 없기 때문이다. 그래서 지금은 네트워크에서 애플리케이션들이 어떻게 동작하는지를 이해하고, 누가 대역폭을 얼마나 사용하고 무엇을 하며 네트워크 상황 변화가 어떤 영향을 미치는지를 파악할 수 있어야 한다.\n</p>\n<p>NetFlow는 네트워크가 어떻게 사용되고 있는지 보여줄 수 있는 매우 중요한 기술이다. 네트워크 상황을 명확하고 분명하게 분석하는 것이 지금처럼 중요한 적은 없었다. 현재 인프라솔루션개발랩에서는 NetFlow 기술을 이용한 모니터링 솔루션을 개발하고 있으며, 이는 전세계에서 사용하는 NHN 서비스를 더 상세히 모니터링하여 서비스의 안전성에 큰 기여를 할 수 있을 것이라 믿는다. 새로운 모니터링 솔루션이 서비스 개발자들에게 많은 도움이 되었으면 한다.\n</p>\n<h2>참고자료\n</h2><ol><li>Introduction to Cisco IOS NetFlow: <a href=\"http://www.cisco.com/en/US/prod/collateral/iosswrel/ps6537/ps6555/ps6601/prod_white_paper0900aecd80406232.html\">http://www.cisco.com/en/US/prod/collateral/iosswrel/ps6537/ps6555/ps6601/prod_white_paper0900aecd80406232.html</a>\n&#9;&#9;</li><li>Designing Cisco Network Service Architectures (ARCH) Foundation Learning Guide: (CCDP ARCH 642-874), Third Edition\n</li><li>NetFlow Application: <a href=\"http://netflow.caligare.com/applications.htm\">http://netflow.caligare.com/applications.htm</a>\n&#9;&#9;</li><li>NetFlow Analyzer: <a href=\"http://www.manageengine.com/products/netflow/\">http://www.manageengine.com/products/netflow/</a>\n&#9;&#9;</li><li>Wikipedia&#43;NetFlow: <a href=\"http://en.wikipedia.org/wiki/Netflow\">http://en.wikipedia.org/wiki/Netflow</a>\n&#9;&#9;</li></ol>\n<div>\n&#9;<div>\n&#9;&#9;\n\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 인프라솔루션개발랩 이동규\n&#9;&#9;NHN에 2008년 입사해서 시스템과 관련된 많은 경험들을 하고 있다. 인내심을 가지고 시스템들과 더 친해져서 서로를 더 깊이 알고 싶다.\n                <br>\n&#9;&#9;\n</div></div>"},{"name":"웹 사이트 성능 최적화 분석 자동화: YSlow와 CI 서버 연동","published":1362559266,"description":"<div><p>NHN 커뮤니티서비스개발랩 박경일\n&#9;</p>\n<p>2007년 Yahoo!에서 웹 사이트 성능 최적화를 위한 내부 노하우를 14개 법칙(현재는 35개 법칙, <a href=\"http://developer.yahoo.com/performance/rules.html\">http://developer.yahoo.com/performance/rules.html</a>)으로 정리해 일반 개발자에게 공개했습니다. 그리고 해당 법칙에 따라 성능 최적화를 분석하는 YSlow라는 도구도 함께 공개했습니다.\n</p>\n<p>초기에 YSlow는 Firefox의 확장 프로그램으로 공개됐으나 그 이후 Chrome, Opera, Safari 등 모든 브라우저의 확장 도구로 포팅됐습니다. 최근에는 Node.js나 PhantomJS를 이용해 브라우저 없이 명령어 입력으로 바로 실행할 수 있는 커맨드라인 버전까지 다양하게 제공하고 있어 원하는 방법을 선택해 사용할 수 있습니다.\n</p>\n<p>이 글에서는 YSlow 커맨드라인 버전과 CI(Continuous Integration, 지속적인 통합) 서버인 Jenkins를 연동해 빌드 때마다 자동으로 웹 사이트 성능 최적화 분석 결과를 리포팅하는 방법을 살펴보겠습니다.\n</p>\n<h2>웹 사이트 성능 최적화 분석 자동화\n</h2><p>먼저 웹 사이트 성능 최적화 법칙에 대해 간단히 살펴보고, 성능 최적화 분석 자동화에 필요한 도구에 무엇이 있는지 알아보겠다.\n</p>\n<h3>웹 사이트 성능 최적화 법칙\n</h3><p>인터넷 포털 사이트는 사용자들에게 인터넷의 첫 관문 역할을 하기 때문에 다양한 정보를 제공하면서도 웹 사이트의 속도가 빨라야 한다. Yahoo!는 자사의 포털 사이트가 점점 방대해지면서 페이지 로딩 속도도 느려지게 돼 성능 최적화를 고민하지 않을 수 없었다.\n</p>\n<p>당시에 웹 사이트의 성능 최적화는 주로 백엔드(back-end) 요소인 서버 프로그램이나 데이터베이스 등에 초점을 맞추고 있었다. 그 이유는 사용자 PC의 브라우저에 페이지가 로딩돼 화면에 나타나고 나면 성능 최적화는 개발자가 컨트롤할 수 있는 영역을 벗어난 브라우저의 몫이라고 생각했기 때문이다. 하지만 Yahoo!의 성능개선팀 매니저였던 스티브 사우더스(Steve Souders)는 연구, 조사를 통해 서버 프로그램 영역을 떠난 순간인 프런트엔드(front-end) 영역에서 일어나는 일이 웹 페이지 속도의 80~90%를 차지한다는 사실을 인지하고 프런트엔드 요소를 어떻게 하면 빠르게 할 수 있을지 고민하고 연구하여 최선의 방안들을 Yahoo! 포털에 하나씩 적용해 나갔다. 그 결과 Yahoo!는 많은 정보를 담고 있으면서도 빠른 속도로 첫 페이지를 사용자에게 제공할 수 있게 됐다.\n</p>\n<p>이러한 Yahoo! 성능개선팀의 우수 사례(best practice)가 모여 웹 사이트 성능 최적화 14개 법칙이 탄생했다. 현재는 다음과 같은 35개 법칙이 있다.\n</p>\n<ol><li><strong>Minimize HTTP Requests(HTTP요청을 최소화하라)\n</strong></li><li><strong>Use a Content Delivery Network(CDN을 이용하라)\n</strong></li><li><strong>Add an Expires or a Cache-Control Header(응답헤더에 Expires 혹은 Cache-Control을 추가하라)\n</strong></li><li><strong>Gzip Components(gzip으로 압축하라)\n</strong></li><li><strong>Put Stylesheets at the Top(스타일시트는 문서의 위쪽에 넣어라)\n</strong></li><li><strong>Put Scripts at the Bottom(스크립트는 문서의 아래쪽에 넣어라)\n</strong></li><li><strong>Avoid CSS Expressions(CSS Expression을 피하라)\n</strong></li><li><strong>Make JavaScript and CSS External(자바스크립트와 CSS는 외부 파일로 만들어라)\n</strong></li><li><strong>Reduce DNS Lookups(DNS 검색을 줄여라)\n</strong></li><li><strong>Minify JavaScript and CSS(자바스크립트와 CSS의 크기를 작게 하라)\n</strong></li><li><strong>Avoid Redirects(리다이렉션을 피하라)\n</strong></li><li><strong>Remove Duplicate Scripts(중복 스크립트를 제거하라)\n</strong></li><li><strong>Configure ETags(ETags를 설정하라)\n</strong></li><li><strong>Make Ajax Cacheable(AJAX도 캐싱할 수 있도록 만들어라)\n</strong></li><li>Flush the Buffer Early(버퍼를 빨리 비워라)\n</li><li><strong>Use GET for AJAX Requests(AJAX 요청 시 GET을 사용하라)\n</strong></li><li>Post-load Components (사후 구성 컴포넌트)\n</li><li>Preload Components(사전 구성 컴포넌트)\n</li><li><strong>Reduce the Number of DOM Elements(DOM 요소의 개수를 줄여라)\n</strong></li><li>Split Components Across Domains(컴포넌트를 도메인별로 분리하라)\n</li><li>Minimize the Number of iframes(IFrame의 개수를 최소화하라)\n</li><li><strong>No 404s(404 오류가 발생하지 않게 하라)\n</strong></li><li><strong>Reduce Cookie Size(쿠키의 크기를 줄여라)\n</strong></li><li><strong>Use Cookie-free Domains for Components(컴포넌트는 쿠키가 없는 도메인을 사용하라)\n</strong></li><li>Minimize DOM Access (DOM 접근을 최소화하라)\n</li><li>Develop Smart Event Handlers (이벤트 핸들러를 잘 개발하라)\n</li><li>Choose &lt;link&gt; over &#64;import(&#64;import보다는 &lt;link&gt; 태그를 써라)\n</li><li><strong>Avoid Filters(CSS 필터를 피하라)\n</strong></li><li>Optimize Images(이미지를 최적화하라)\n</li><li>Optimize CSS Sprites(CSS 스프라이트를 최적화하라)\n</li><li><strong>Don&#39;t Scale Images in HTML(HTML로 지정한 크기보다 큰 이미지를 사용하지 마라)\n</strong></li><li><strong>Make favicon.ico Small and Cacheable(favicon.ico 파일은 작게 만들고 캐싱되도록 만들어라)\n</strong></li><li>Keep Components under 25K(컴포넌트 크기를 25KB 이하로 유지하라)\n</li><li>Pack Components into a Multipart Document(컴포넌트를 멀티파트 문서로 묶어라)\n</li><li><strong>Avoid Empty Image src(이미지의 src 속성 값을 빈 채로 만들지 마라)\n</strong></li></ol><p>여기서는 이 법칙의 자세한 내용과 기법에 관해서 따로 설명하지 않겠다. 법칙에 관한 자세한 내용은 Yahoo! 개발자 페이지의 &#34;<a href=\"http://developer.yahoo.com/performance/rules.html\">Best Practices for Speeding Up Your Web Site</a>&#34; 문서에서 확인할 수 있다.\n</p>\n<h3>성능 최적화 분석 자동화 도구\n</h3><h4>YSlow\n</h4><p>YSlow는 앞에서 언급한 웹 사이트 성능 최적화 법칙을 웹 사이트가 얼마나 만족하고 있는지 측정하는 도구다. 다양한 브라우저 확장 프로그램 버전을 제공하고 있으며, <a href=\"http://yslow.org/\">http://yslow.org/</a>에서 다운로드할 수 있다.\n</p>\n<p>YSlow는 현재 35개 법칙 중 프로그램으로 측정할 수 있는 23개 법칙(앞에서 35개 법칙 중 굵은 글자로 표시해 두었다)을 분석해 자체 기준에 따라 A~F까지 등급을 분류해서 보고한다. 등급 및 점수는 참고 사항이므로 자신의 웹 사이트 상황과는 안 맞을 수 있다. 보고서 점수에 너무 연연하지 말고 보고서 내용을 참고하여 상황에 맞게 최적화하면 된다.\n</p>\n<p>자세한 등급과 점수는 &#34;YSlow Ruleset Matrix(<a href=\"http://yslow.org/ruleset-matrix\">http://yslow.org/ruleset-matrix</a>)&#34; 문서에서 확인할 수 있다.\n</p>\n<h4>PhantomJS(<a href=\"http://phantomjs.org/\">http://phantomjs.org/</a>)\n</h4><p>PhantomJS는 WebKit 엔진으로 브라우저를 에뮬레이팅해 커맨드라인에서 JavaScript를 실행시킬 수 있게 하는 도구다. JavaScript 테스트 자동화에 많이 사용하고 있으며 브라우저 화면 캡처와 네트워크 분석도 가능해서 다양하게 활용할 수 있다.\n</p>\n<h4>Jenkins\n</h4><p>Jenkins 서버는 소스코드가 변경됐을 때 빌드, 테스트, 분석, 리포팅이 자동으로 수행되도록 도와주는 CI 서버다. Jenkins 서버는 프로젝트의 소스가 변경되면 자동으로 빌드하고 단위 테스트를 수행해 그 결과를 리포팅하기 때문에 프로그램 변경 시에 발생할 수 있는 문제를 사전에 찾아 해결할 수 있다. 그래서 프로젝트를 더 안정적이고 성공적으로 유지 보수할 수 있다.\n</p>\n<p>각 프로젝트마다 소스 저장소, 빌드 환경, 단위 테스트 환경 등이 서로 다르기 때문에 Jenkins 서버는 다양한 환경을 수용할 수 있도록 잘 구조화된 플러그인 확장 환경을 제공한다. 좀 더 자세한 내용은 홈페이지(<a href=\"http://jenkins-ci.org/\">http://jenkins-ci.org/</a>)를 참고하길 바란다.\n</p>\n<blockquote><p><strong>참고</strong><br>Jenkins의 원래 이름은 Hudson이었으나 Oracle사와의 상표 권리 문제로 2011년 1월부터 Hudson(Oracle)과 Jenkins(오픈소스)로 나뉘게 됐다.\n</p>\n</blockquote><h2>YSlow for PhantomJS\n</h2><h3>PhantomJS 설치하기\n</h3><p>YSlow가 브라우저 없이 실행될 수 있도록 먼저 PhantomJS를 설치한다.\n</p>\n<ol><li><a href=\"http://phantomjs.org/download.html\">http://phantomjs.org/download.html</a>에서 자신의 운영체제에 맞는 PhantomJS 버전을 다운로드한다.\n</li><li>다운로드한 파일의 압축을 해제하면 PhantomJS 실행 파일을 확인할 수 있다.\n</li><li>먼저 버전 확인 명령으로 이상이 없는지 확인한다. 아무런 의존성이 없기 때문에 다음과 같이 바로 명령어를 실행하면 된다.<br>\n&#9;&#9;</li><li><a href=\"http://yslow.org/phantomjs/\">http://yslow.org/phantomjs/</a>에서 YSlow for PhantomJS를 다운로드한 다음 압축을 해제한다.\n</li><li>다음과 같이 <strong>phantomjs</strong> 명령어로 <strong>yslow.js</strong>를 실행시켜서 본다.<br>\n&#9;&#9;</li></ol><p>PhantomJS와 YSlow만으로도 커맨드 라인을 통해 YSlow로 웹 사이트 성능을 분석할 수 있다.\n</p>\n<h3>사용법\n</h3><p><strong>phantomjs yslow.js --help</strong> 명령을 실행시키면 다음과 같은 사용법을 확인할 수 있다. 편의를 위해 각 옵션 설명을 번역해 놓았다.\n</p>\n<p></p>\n<code>Usage: phantomjs [phantomjs options] yslow.js [yslow options] [url ...]<br><br>PhantomJS Options:<br><br>  http://y.ahoo.it/phantomjs/options<br><br>YSlow Options:<br><br>  -h, --help               사용법을 출력한다<br>  -V, --version            버전 출력<br>  -i, --info &lt;info&gt;        로그 출력정보를 지정 (basic|grade|stats|comps|all) [all]<br>  -f, --format &lt;format&gt;    결과물 출력 형식을 지정한다 (json|xml|plain|tap|junit) [json]<br>  -r, --ruleset &lt;ruleset&gt;  적용할 YSlow 성능 법칙세트을 지정한다 (ydefault|yslow1|yblog) [ydefault]<br>  -b, --beacon &lt;url&gt;       결과를 로그할 URL을 지정한다<br>  -d, --dict               결과 항목 사전을 포함한다<br>  -v, --verbose            beacon 응답 정보를 출력한다<br>  -t, --threshold &lt;score&gt;  합격/불합격여부를 위한 한계 최저점수를 지정한다 ([0-100]|[A-F]|{JSON}) [80]<br>                           e.g.: -t B or -t 75 or -t &#39;{&#34;overall&#34;: &#34;B&#34;, &#34;ycdn&#34;: &#34;F&#34;, &#34;yexpires&#34;: 85}&#39;<br>  -u, --ua &#34;&lt;user agent&gt;&#34;  페이지가 리소스를 요청할 때 서버로 전송할 user agent 문자열을 지정한다<br>  -vp, --viewport &lt;WxH&gt;    페이지의 뷰포트 사이즈를 WxY로 지정한다, W &#61; 너비, H &#61; 높이 [400x300]<br>  -ch, --headers &lt;JSON&gt;    커스텀 요청 헤더를 지정한다, e.g.: -ch &#39;{&#34;Cookie&#34;: &#34;foo&#61;bar&#34;}&#39;<br>  -c, --console &lt;level&gt;    페이지 console 메시지를 출력한다 (0: none, 1: message, 2: message &#43; line &#43; source) [0]<br><br>Examples:<br>phantomjs yslow.js http://yslow.org<br>phantomjs yslow.js -i grade -f xml www.yahoo.com www.cnn.com www.nytimes.com<br>phantomjs yslow.js -info all --format plain --ua &#34;MSIE 9.0&#34; http://yslow.org<br>phantomjs yslow.js -i basic --rulseset yslow1 -d http://yslow.org<br>phantomjs yslow.js -i grade -b http://www.showslow.com/beacon/yslow/ -v yslow.org<br>phantomjs --load-plugins&#61;yes yslow.js -vp 800x600 http://www.yahoo.com<br>phantomjs yslow.js -i grade -f tap -t 85 http://yslow.org\n</code><p></p>\n<p>실행 예제 설명은 <a href=\"http://yslow.org/phantomjs/\">YSlow for Phantom 사용법 페이지</a>를 참고하도록 한다. 예제를 실행해 보면 알겠지만 문자열로 주르륵 떨어지는 출력 결과에 당혹하지 않을 수 없다. 이제 Jenkins를 이용해 보기 좋게 보고서를 출력하고 자동화해 보자\n</p>\n<h2>Jenkins 서버에 YSlow연동하기\n</h2><h3>Jenkins 서버 준비하기\n</h3><p>이미 Hudson이나 Jenkins 서버가 구축돼 있다면 구축된 서버를 활용하도록 하자. 시험 삼아 로컬 PC의 Windows 환경에서 확인해 보고 싶다면 다음과 같이 Jenkins 서버를 다운로드해 실행하도록 한다.\n</p>\n<ol><li>먼저 <a href=\"http://java.com/download\">http://java.com/download</a>에서 Java를 다운로드해 설치한다.\n</li><li>jenkins.war를 <a href=\"http://jenkins-ci.org/\">http://jenkins-ci.org/</a>에서 다운로드한다.\n</li><li>Windows의 명령 프롬프트에서 다음과 같이 Jenkins 서버를 실행한다.<br>\n&#9;&#9;</li><li>브라우저에서 <a href=\"http://localhost:8080\">http://localhost:8080</a>으로 접속해 서버가 정상적으로 실행되는지 확인한다. 다음과 같은 화면을 볼 수 있으면 정상적으로 실행된 것이다.<br>\n&#9;&#9;</li></ol><p>YSlow for PhantomJS는 TAP(Test Anything Protocol) 타입과 JUnit 타입의 출력 포맷을 제공하고 있기 때문에 Jenkins의 TAP 플러그인이나 JUnit 플러그인으로 분석 결과를 보기 좋게 만들어낼 수 있다. Jenkins 서버에 해당 플러그인이 있는지 확인하고, 없다면 다음과 같이 플러그인을 설치한다.\n</p>\n<ol><li><strong>Jenkins 관리 &gt; 플러그인 관리</strong> 항목을 클릭한다.<br>\n&#9;&#9;</li><li><strong>설치된 플러그인</strong> 탭에서 플러그인 설치 여부를 확인한다.\n</li><li>플러그인이 없다면 <strong>설치 가능</strong> 탭에서 해당 플러그인을 찾아서 설치한다(JUnit 플러그인은 기본으로 설치돼 있어 별도로 설치하지 않아도 된다).<br>\n&#9;&#9;</li><li>플러그인 다운로드 및 설치가 완료되면 자동으로 다시 시작한다. Windows에서는 자동으로 다시 시작하지 않으므로 서버가 실행되고 있는 명령 창에서 <strong>Ctrl&#43;C</strong> 키를 눌러 중단했다가 다시 실행하면 된다.\n</li></ol><p>이제 모든 준비가 완료됐다. Jenkins에서 YSlow를 실행하고 보고서가 출력되도록 연동해 보자.\n</p>\n<h3>Jenkins 서버에 YSlow 연동하기\n</h3><h4>TAP 보고서로 출력하기\n</h4><p>Jenkins에 프로젝트를 추가하고 다음과 같이 설정한다.\n</p>\n<ol><li><strong>새로운 Job</strong>을 클릭해 프로젝트를 추가한다.<br>\n&#9;&#9;</li><li><strong>OK</strong>를 클릭하면 설정 화면이 나온다.\n</li><li><div><strong>Build</strong> 항목에서 <strong>Add build step &gt; Execute shell</strong>을 선택하고 커맨드라인 명령을 입력한다(Windows에서는 <strong>Execute Windows batch command</strong>를 이용한다).<br>\n&#9;&#9;&#9;</div><blockquote><p><strong>참고: 커맨드라인 명령 입력 값<br></strong></p>\n<code>phantomjs yslow.js -i grade -threshold &#34;B&#34; -f tap http://www.naver.com &gt; yslow.tap</code><br>-i grade : 모든 법칙이 테스트되도록 지정<br>-threshold &#34;B&#34; : 모든 법칙의 수용 가능한 최저 점수를 지정<br>-f tap : 결과를 TAP 형식으로 출력하도록 지정<br>http://www.naver.com : 테스트할 페이지 URL<br>yslow.tap : 저장할 TAP 결과 파일 이름\n<p></p>\n</blockquote></li><li><strong>Post-build Actions</strong> 항목에서 <strong>Add build step &gt; Publish TAP Results</strong>를 선택하고 <strong>Test results</strong>에 <strong>yslow.tap</strong>을 입력한다.<br>\n&#9;&#9;</li><li>설정한 내용을 저장한다.\n</li><li>왼쪽 메뉴에서 <strong>Build Now</strong>를 클릭해서 실행한다.\n</li><li>빌드가 완료되면 왼쪽 메뉴에서 <strong>TAP</strong>을 클릭해 최근 빌드의 결과를 확인할 수 있다.<br>\n&#9;&#9;</li><li><strong>TAP Test Result</strong>를 클릭하면 검사 항목별 내용을 확인할 수 있다.<br>\n&#9;&#9;</li></ol><h4>JUnit 보고서로 출력하기\n</h4><p>JUnit 보고서를 출력하려면 다음과 같이 설정하고 실행하면 된다.\n</p>\n<ol><li><div><strong>Build</strong> 항목에서 <strong>Add build step &gt; Execute shell</strong>을 추가하고 커맨드라인 명령을 입력한다.<br>\n&#9;&#9;&#9;</div><blockquote><p><strong>참고: 커맨드라인 명령 입력 값<br></strong></p>\n<code>phantomjs yslow.js -i grade -threshold &#34;B&#34; -f junit http://www.naver.com &gt; yslow.xml<br></code>-i grade : 모든 법칙이 테스트되도록 지정<br>-threshold &#34;B&#34; : 모든 법칙의 수용 가능한 최저 점수를 지정<br>-f junit : 결과를 JUnit 형식으로 출력하도록 지정<br>http://www.naver.com : 테스트할 페이지 URL<br>yslow.tap : 저장할 JUnit 결과파일 이름\n<p></p>\n</blockquote></li><li><strong>Post-build Actions</strong> 항목에서 <strong>Add build step &gt; Publish JUnit test result report</strong>를 선택하고 <strong>Test report XMLs</strong>에 <strong>yslow.xml</strong>을 입력한다.<br>\n&#9;&#9;</li><li>설정 내용을 저장하고 빌드를 수행하면 결과를 확인할 수 있다.<br>\n&#9;&#9;</li><li><strong>Test Result</strong>를 클릭하면 상세 결과를 확인할 수 있다.<br>\n&#9;&#9;</li></ol><p>여기까지는 Jenkins 서버에 적용하는 방법을 쉽게 보여주기 위해 단독 프로젝트를 생성하고 빌드했지만, 기존에 Jenkins 서버를 사용하고 있었다면 Build와 Post-build Actions 설정을 추가한다. 자신의 Yslow로 검사할 URL은 프로젝트의 최종 URL을 적용하면 된다.\n</p>\n<h2>마치며\n</h2><p>웹 페이지의 성능 문제로 골머리를 앓았던 웹 개발자라면 한 번쯤 Firefox나 Chrome의 YSlow 플러그인을 설치해서 사용해 봤을 것이다.\n</p>\n<p>일반적으로 프런트엔드 성능 최적화는 프로젝트 막바지 혹은 운영 중 심각하게 성능 이슈가 있을 때 일회성으로 조치하고 이후에는 잘 신경 쓰지 않는다. 하지만 웹 페이지를 유지 보수하다 보면 이것저것 새로운 기능과 변경 사항으로 인해 조금씩 느려지다 언젠가 다시 성능 이슈가 발생할 수도 있다.\n</p>\n<p>CI 서버에 YSlow를 설정하면 유지 보수 시에 변경이 발생할 때마다 문제가 발생할 여지가 있는 부분을 손쉽게 모니터링하고 추적할 수 있을 것이다. 또한 이렇게 개발자가 사전에 성능 문제를 인지할 수 있다면, 기능이 추가되고 변경되더라도 사용자에게 항상 쾌적한 속도의 웹 페이지 접속 환경을 보장한다는 가치도 만들어 낼 수 있다.\n</p>\n<p>이런 점에서 Yslow와 CI 연동을 이용한 웹사이트 성능 최적화는 시도해 볼만하다.\n</p>\n<div>\n&#9;<div>\n&#9;&#9;\n\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NHN 커뮤니티서비스개발랩 박경일\n&#9;&#9;현재 NHN 커뮤니티서비스개발랩에서 스마트에디터 개발 업무를 담당하고 있습니다. \n                자바스크립트 UI 개발이 주 업무이긴 하지만 서버나 앱 개발에도 관심이 많고 개발하는 일이라면 이것 저것 가리지 않고 좋아합니다.\n                백발의 개발자를 꿈꾸며...\n&#9;&#9;\n</div></div>"},{"name":"ZooKeeper를 활용한 Redis Cluster 관리","published":1361863454,"description":"<div><p>NHN Business Platform 클라우드플랫폼개발랩 임영완, 배상용\n&#9;</p>\n<p>지속적으로 늘어나는 푸시 사용자를 MySQL 샤딩으로만 감당하기에는 버거웠습니다. 그래서 다양하게 검토한 끝에 MySQL을 대체할 데이타베이스로 Redis를 선택하게 되었고, 클러스터를 구성하기 위해서 ZooKeeper라는 도구를 사용했습니다. 이 글에서는 Redis와 ZooKeeper의 조합으로 Redis Cluster를 구성하는 방법을 알아보겠습니다.\n</p>\n<h2>Redis를 메시지 데이터베이스로 사용하게 된 배경\n</h2><p>NNI(NHN Notication Infrastructure)는 Android 운영체제 기반의 스마트폰 애플리케이션에 푸시 알림을 제공하는 NHN의 플랫폼이다. NNI는 푸시 알림을 저장하는 저장소로 MySQL을 사용하고 있었다. NNI 시스템 구조상 서비스의 사용량이 많아 데이터베이스를 증설할 경우, 다수의 MySQL 연관 장비를 투입해야 함과 동시에 데이터베이스 세트가 추가될 때마다 애플리케이션 서버의 샤딩(sharding) 로직을 수정해 서버를 다시 배포해야 하는 문제가 있었다.\n</p>\n<p>이러한 문제점을 개선하기 위해 푸시 알림 메시지 형태의 자료를 저장하기에 적합한 구조를 지원하고, 횡적 확장이 용이하며, 알림 메시지의 저장 및 검색 성능과 관련한 기능에서는 MySQL보다 뛰어난 솔루션에 대해 검토를 진행하게 되었다.\n</p>\n<p>여러 가지 솔루션을 검토한 후 NHN의 서비스에서는 대용량의 데이터를 저장하기보다 높은 트래픽을 처리하는 것이 가장 중요한 포인트라고 생각했고, RDBMS보다 MemoryDB를 선택하게 되었다. 그리고 1년이 넘는 시간 동안 운영하면서 단 한 차례도 장애를 일으키지 않은 Redis를 신뢰해 MySQL 대용으로 사용하기로 했다.\n</p>\n<p>그러나 Redis 선택 시 몇 가지 생각해야 될 문제가 있다. 첫 번째로 가장 불편한 사항은 샤딩을 지원하지 않는다는 점이다. 확장성(scalability)을 확보하려면 수동으로 샤드(shard)를 구성한 후 애플리케이션 서버에서 해싱(hashing) 로직에 의해 샤딩을 지원해야 하고 클러스터 관리 도구도 직접 만들어야 한다.\n</p>\n<p>두 번째로 클러스터 구성에서 중요한 Failover 기능이 없다는 점이다. Master-Slave Replication 구성 시 Master가 장애가 날 때 자동으로 처리하지 않아 일일이 수동으로 복구해야 한다.\n</p>\n<h2>Redis Cluster 구성을 위한 ZooKeeper 도입 배경\n</h2><p>Redis로 클러스터를 구성해서 사용하려면 앞에서 언급한 문제점을 해결해야 한다. 분산 서버 환경에서 ZooKeeper가 필수라고 많이 이야기하고, 사내에서 Line과 Arcus 등의 서비스에서 이미 안정성이 검증됐기 때문에 크게 의심하지 않고 ZooKeeper를 선택했다.\n</p>\n<p>분산 처리 환경에서 필수로 언급되는 ZooKeeper란 무엇일까? 한 마디로 정의하면 &#34;분산 처리 환경에서 사용 가능한 데이터 저장소&#34;라고 말할 수 있겠다. 기능은 매우 단순하지만 분산 서버 환경에서는 활용 분야가 넓다. 예를 들어 분산 서버 간의 정보 공유, 서버 투입/제거 시 이벤트 처리, 서버 모니터링, 시스템 관리, 분산 락 처리, 장애 상황 판단 등 다양한 분야에서 활용할 수 있다.\n</p>\n<p>&#39;어떻게 다양한 활용이 가능할까?&#39;라는 의문을 해결하기 위해서 기능에 대해서 한 마디로 설명하면 다음과 같이 설명할 수 있다.\n</p>\n<p>ZooKeeper는 데이터를 디렉터리 구조로 저장하고, 데이터가 변경되면 클라이언트에게 어떤 노드가 변경됐는지 콜백을 통해서 알려준다. 데이터를 저장할 때 해당 세션이 유효한 동안 데이터가 저장되는 Ephemeral Node라는 것이 존재하고, 데이터를 저장하는 순서에 따라 자동으로 일련번호(sequence number)가 붙는 Sequence Node라는 것도 존재한다. 조금 과장하면 이러한 기능이 ZooKeeper 기능의 전부다. 이런 심플한 기능을 가지고 자신의 입맛에 맞게 확장해서 사용하면 된다.\n</p>\n<p>기능을 하나씩 자세히 살펴보자. 우선 ZooKeeper가 데이터를 저장하는 방식인 데이타 모델에 대해서 살펴보자.\n</p>\n<p>ZooKeeper는 &lt;그림 1&gt;과 같은 디렉터리 구조로 데이터를 저장한다. 특징을 살펴보면 Persistent를 유지하기 위해서 트랜잭션 로그와 스냅샷 파일이 디스크에 저장되어 시스템을 재시작해도 데이터가 유지된다. 각각의 디렉터리 노드를 znode라고 명명하며, 한 번 설정한 이름은 변경할 수 없고 스페이스를 포함할 수도 없다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 ZooKeeper의 데이터 모델(이미지 출처: <a href=\"http://zookeeper.apache.org/doc/trunk/zookeeperOver.html\">http://zookeeper.apache.org/doc/trunk/zookeeperOver.html</a>)\n</strong></p>\n<p>데이터를 저장하는 기본 단위인 노드에는 Persistent Node와 Ephemeral Node, Sequence Node, 3가지가 있다.\n</p>\n<p>첫 번째로 Persistent Node는 한 번 저장되고 나면 세션이 종료되어도 삭제되지 않고 유지되는 노드다. 즉, 명시적으로 삭제하지 않는 한 해당 데이터는 삭제 및 변경되지 않는다.\n</p>\n<p>두 번째로 Ephemeral Node는 특정 노드를 생성한 세션이 유효한 동안 그 노드의 데이터가 유효한 노드다. 좀 더 자세히 설명하면 ZooKeeper Server에 접속한 클라이언트가 특정 노드를 Ephermeral Node로 생성했다면 그 클라이언트와 서버 간의 세션이 끊어지면, 즉 클라이언트와 서버 간의 Ping을 제대로 처리하지 못한다면 해당 노드는 자동으로 삭제된다. 이 기능을 통해 클라이언트가 동작하는지 여부를 쉽게 판단할 수 있다.\n</p>\n<p>세 번째로 Sequence Node는 노드 생성 시 sequence number가 자동으로 붙는 노드다. 이 기능을 활용해 분산 락 등을 구현할 수 있다.\n</p>\n<p>다음으로 ZooKeeper 서버 구성도를 살펴보자.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 ZooKeeper의 서버 구성도(이미지 출처: <a href=\"http://zookeeper.apache.org/doc/trunk/zookeeperOver.html\">http://zookeeper.apache.org/doc/trunk/zookeeperOver.html</a>)\n</strong></p>\n<p>ZooKeeper 서버는 일반적으로 3대 이상을 사용하며 서버 수는 주로 홀수로 구성한다. 서버 간의 데이터 불일치가 발생하면 데이터 보정이 필요한데 이때 과반수의 룰을 적용하기 때문에 서버를 홀수로 구성하는 것이 데이터 정합성 측면에서 유리하다. 그리고 ZooKeeper 서버는 Leader와 Follower로 구성되어 있다. 서버들끼리 자동으로 Leader를 선정하며 모든 데이터 저장을 주도한다.\n</p>\n<p>클라이언트에서 Server(Follower)로 데이터 저장을 시도할 때 Server(Follower) -&gt; Server(Leader) -&gt; 나머지 Server(Follower)로 데이터를 전달하는 구조이고, 모든 서버에 동일한 데이터가 저장된 후 클라이언트에게 성공/실패 여부를 알려주는 동기 방식으로 작동한다. 즉, 모든 서버는 동일한 데이터를 각각 가지고 있고, 클라이언트가 어떤 서버에 연결되어 데이터를 가져가더라도 동일한 데이터를 가져가게 된다.\n</p>\n<p>사용/운영 시 몇 가지 주의 사항이 있다. 개발에 급급한 나머지 ZooKeeper를 캐시 용도로 사용해 서비스를 오픈했다가 장애가 발생한 사례도 종종 있다고 한다. 데이터의 변경이 자주 발생하는 서비스에서 ZooKeeper를 데이터 저장소로 사용하는 것은 추천하지 않는다. ZooKeeper에서 추천하는 Read : Write 비율은 10 : 1 이상이다.\n</p>\n<p>그리고 ZooKeeper 서버가 제대로 실행되지 않을 때가 있는데, 대부분 서버간의 데이터 불일치로 인한 데이터 동기화 실패가 그 원인이다. 주로 베타 테스트 후 운영 직전에 ZooKeeper 서버를 증설해서 사용하는데, 이럴 때 기존에 테스트했던 서버와 신규로 투입한 서버의 데이터 차이로 인해 이런 현상이 종종 발생한다. 이때는 데이터를 초기화한 후 서버를 실행하면 된다. \n</p>\n<p>그리고 마지막으로, zoo.cfg라는 설정(configuration) 파일의 ZooKeeper 서버 목록을 꼼꼼히 확인해야 한다. 서버 목록이 정확히 맞지 않아도 서버가 실행되긴 하지만, 로그 파일을 확인하면 ZooKeeper 서버가 지속적으로 재시작할 때도 있고 데이터를 엉뚱한 곳에 저장하기도 한다.\n</p>\n<h2>아키텍처의 변화\n</h2><p>ZooKeeper와 Redis를 이용해 Redis Cluster를 구성하기로 결정했고 아키텍처(architecture)에 대해서 수많은 아이디어를 검토했다. 크게 2가지 구성도를 검토했다.\n</p>\n<p>&lt;그림 3&gt;은 1차 아키텍처 구성도다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 3 1차 아키텍처 구성도\n</strong></p>\n<p>ZooKeeper에 저장되어 있는 Redis 서버 정보가 변경되면 애플리케이션 서버에 콜백으로 알려주고, 애플리케이션 서버는 해당 정보를 통해 Redis에 접속하는 구조다. Redis 서버에 문제가 발생하면 ZooKeeper가 감지하고(Ephemeral Node의 기능을 활용해 세션이 종료되면 ZooKeeper의 데이터가 자동으로 삭제되어서 감지함) 애플리케이션 서버에 콜백으로 알려준다. 이 구조의 장점은 ZooKeeper의 많은 기능을 활용할 수 있다는 것이다. 단점은 ZooKeeper가 단순히 Redis 서버의 네트워크 단절만을 확인한다는 것과 Redis의 Master/Slave를 관리하기 위해서는 애플리케이션 서버에서 직접 처리해야 한다는 것이다.\n</p>\n<p>이러한 단점을 보안해 2차 아키텍처를 구성했다. 2차 아키텍처 구성은 &lt;그림 4&gt;와 같다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 4 2차 아키텍처 구성도\n</strong></p>\n<p>2차 아키텍처에서는 ZooKeeper의 노드 변경 여부를 클라이언트에게 알려주는 Watcher 기능만을 사용했다. 1차 아키텍처 구성도에서 사용했던 Ephemeral Node는 사용하지 않고 Redis Cluster Manager에서 ZooKeeper의 Ephemeral Node 기능까지 직접 구현해 사용했다. 1차 아키텍처 구성도보다 애플리케이션 서버의 로직을 간소화할 수 있고, Redis Cluster Manager만 제대로 구현한다면 애플리케이션 서버와 Redis 서버 데몬 등에 새로운 로직을 구현할 필요가 없다.\n</p>\n<h2>Redis Cluster Manager의 요구 사항\n</h2><p>Redis Cluster Manager를 개발하기 위한 요구 사항은 다음과 같다.\n</p>\n<ul><li>NPUSH-NNI의 메시지 데이터베이스 외에 여러 서비스에서 사용하는 Redis Cluster를 관리할 수 있어야 한다(예: NNI 단말 토큰용 Redis Cluster, NPUSH-GW의 Registration DB Cluster 등).\n</li><li>한 클러스터는 다수의 샤드로 구성될 수 있다.\n</li><li>한 개의 샤드는 다수의 Redis 서버로 구성될 수 있고 1개의 Master와 다수의 Slave로 구성된다.\n</li><li>위의 기능을 지원하기 위해 ZooKeeper 디렉터리를 제어할 수 있는 RPC API를 제공한다.\n</li><li>등록된 서버의 Health check를 주기적으로 수행하고 각 샤드의 Master 서버가 동작하지 않으면 Slave 서버를 자동으로 Master로 promotion하는 기능을 구현한다.\n</li><li><div>NCS 서버에게는 Redis의 상태 및 샤딩 정보를 알 필요 없는 캡슐화된 ShardedRedisClient 라이브러리를 제공한다.\n</div><ul><li>Pushevent 메서드와 PusheventRes 메서드, Subscribe 메서드만 호출한다.\n</li><li>샤딩 규칙(sharding rule) 변경에 따른 Old Hashed Data 및 New Hashed Data 모두 장애 없이 처리돼야 한다. 캐시 용도가 아니기 때문에 Consistent Hashing 로직 적용은 고려하지 않는다.\n</li></ul></li></ul><h2>ZooKeeper 디렉터리 구조\n</h2><p>위의 요구 사항을 만족시키기 위해 ZooKeeper의 분산 저장소 기능을 사용해 디렉터리 구조를 설계했다.\n</p>\n<p><strong>예제 1 ZooKeeper 디렉터리 구조\n</strong></p>\n<p></p>\n<code>/status<br>    - NHN-DB :<br>        - shard-1 :<br>            - &#34;10.102.29.187:6380&#34; : &#34;normal&#34;<br>            - &#34;10.102.30.220:6380&#34; : &#34;normal&#34;<br>            - &#34;10.102.40.47:6380&#34; : &#34;normal&#34;<br>        - shard-2 :<br>            - &#34;10.102.43.60:6380&#34; : &#34;normal&#34;<br>            - &#34;10.102.41.46:6380&#34; : &#34;normal&#34;<br>            - &#34;10.102.43.199:6380&#34; : &#34;normal&#34;<br>/clusters<br>    - NHN-DB : NNI Message DB<br>        - shard-1 : auto_recovery<br>            - &#34;10.102.29.187:6380&#34; : &#34;master&#34;<br>            - &#34;10.102.30.220:6380&#34; : &#34;slave&#34;<br>            - &#34;10.102.40.47:6380&#34; : &#34;standby&#34;<br>        - shard-2 : auto_recovery<br>            - &#34;10.102.43.60:6380&#34; : &#34;master&#34;<br>            - &#34;10.102.41.46:6380&#34; : &#34;slave&#34;<br>            - &#34;10.102.43.199:6380&#34; : &#34;backup&#34;<br>/shard-rules<br>    - NHN-DB : NNI Message DB<br>        - status : plan-1<br>        - plan-1 : &#34;10.102.29.187:6380&#34;<br>        - plan-2 : &#34;10.102.29.187:6380&#34;, &#34;10.102.43.60:6380&#34;\n</code><p></p>\n<p>디렉터리 구조를 간단히 설명하면 <strong>/status</strong> 디렉터리는 Redis 서버의 상태를 기록하는 용도로 사용하고 <strong>/clusters</strong> 디렉터리는 해당 Redis 서버의 role을 기록하는 용도로 사용한다.\n</p>\n<p><strong>/shard-rules</strong> 디렉터리는 클러스터에 샤드가 추가될 때 기존 샤드 정보 및 신규 샤드 정보를 기록해 애플리케이션 서버에 제공되는 ShardedRedisClient에서 활용할 수 있도록 샤드 룰(shard rule) 정보를 제공한다.\n</p>\n<p>이제 Redis Cluster Manager의 주요 컴포넌트에서 활용하는 ZooKeeper의 Watch 기능을 이용해 분산 디렉터리 정보를 어떻게 관리하고 애플리케이션 서버에서 어떻게 해당 디렉터리 정보를 이용할 수 있는지 알아보겠다.\n</p>\n<h2>Redis Cluster Manager의 시스템 구성\n</h2><p>Redis Cluster Manager는 BLOC Container에서 수행되는 BLOC 모듈로 구현돼 있다. ZooKeeper 및 Redis 서버를 제어하기 위해 전용 클라이언트를 사용하는 BO(Business Object)/DAO(Data Access Object)를 구현했고, 구현한 BO 중 외부 API 형태로 노출해야 할 BO 메서드는 BLOC Resouce 형태로 작성해 노출시켜 주었다.\n</p>\n<blockquote><p><strong>참고</strong><br>BLOC(Business Logic Container)은 BO를 제공하는 NHN의 서비스 컨테이너다.\n</p>\n</blockquote><p>또한 Redis 서버의 Health check, Server failover, Sharding rule 관리를 담당하는 별도의 컴포넌트로 구성되어 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 5 Redis Cluster Manager의 주요 컴포넌트\n</strong></p>\n<h2>Redis Cluster Manager의 주요 컴포넌트\n</h2><h3>BLOC BO API\n</h3><p>Redis Cluster Manager 시스템 구성 섹션에서 ZooKeeper 디렉터리 및 Redis 서버를 관리하기 위해 BLOC Resource를 이용한다고 했다. 노출된 BLOC API 호출을 통해 Cluster, Shard, Node, Shardrule 정보를 업데이트할 수 있고 이를 통해 ZooKeeper의 분산 디렉터리 설정 및 Redis 서버의 role을 설정할 수 있는 기능을 수행한다.\n</p>\n<h3>Healthcheck Manager\n</h3><p>Healthcheck Manager는 ZooKeeper 서버에 생성된 /status 디렉터리의 하위 디렉터리에 기록된 Redis 서버의 리스트를 읽어 주기적으로 해당 서버들로 redis ping command를 호출한다. Ping에 대한 응답 유/무에 따라 해당 서버의 정보가 기록된 노드의 데이터를 변경한다(normal &lt;-&gt; abnormal).\n</p>\n<p>또한 /status 디렉터리의 하위 디렉터리에 대해 Watch 설정을 적용해서 Redis 서버가 추가/삭제 또는 상태가 변경되었을 경우 Ping Check를 위한 Healthcheck Thread를 초기화하는 기능을 수행한다.\n</p>\n<p>다음은 Healthcheck Manager의 주요 기능이다.\n</p>\n<h4>Initialize\n</h4><ol><li>/status 하위 디렉터리에 모두 Watch 설정을 적용해서 노드 관련 이벤트가 발생하는지 감시한다(노드의 추가, 수정, 삭제가 발생하는지 감시).\n</li><li>현재의 /status 디렉터리 아래의 노드 리스트(Redis 서버)를 읽어 주기적(2초)으로 Redis Java Client인 Jedis를 이용해 redis ping command를 실행한다.\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 6 Healthcheck Manager의 초기화 시나리오\n</strong></p>\n<h4>Monitoring\n</h4><ol><li>ping response time이 10초가 넘을 경우 바로 서버의 상태를 abnormal로 변경한다.\n</li><li>connection 오류가 발생할 경우 3번 retry를 시도한다. retry 간격은 지수로 증가한다.\n</li><li>retry를 시도해도 오류가 발생할 경우 서버 상태를 abnormal로 변경한다.\n</li><li>최대 Ping 주기 &#43; retry 시도 시간 안에 서버 상태 변경이 발생한다(약 9초).\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 7 Healthcheck Manager의 모니터링 시나리오 \n</strong></p>\n<h4>Watching\n</h4><ol><li>/status의 하위 디렉터리가 변경되는지 항상 확인한다(노드 추가, 노드 삭제, 데이터 변경).\n</li><li>노드가 추가되거나 데이터가 변경된다면 ZooKeeper 서버로부터 Watch Event를 받는다.\n</li><li>Watch Event를 받으면 현재 ScheduledThreadPoolExecutor에 의해 수행되고 있는 Health Check Thread를 종료함과 동시에 새로 Health Check Thread를 생성한다.\n</li><li>Watch Event는 한번 발생하면 다시 Watch 설정을 할 때까지 발생하지 않으므로 다시 /status 하위 디렉터리에 대한 Watch 설정을 한다.\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 8 Healthcheck Manager의 Watching 시나리오\n</strong></p>\n<h3>Cluster Manager\n</h3><p>Cluster Manager 또한 ZooKeeper 서버에 생성된 /status 디렉터리의 하위 디렉터리에 Watch 설정을 적용하고 Redis 서버들의 상태 변화가 있을 경우 전달된 Watch Event를 받아 Redis 서버의 Failover, Standby 서버 전환 등을 통해 Redis 서버 클러스터를 관리하는 기능을 수행한다.\n</p>\n<p>다음은 Cluster Manager의 주요 기능이다.\n</p>\n<h4>Initialize\n</h4><ul><li>/status 디렉터리의 하위 디렉터리에 모두 Watch 설정을 적용해서 노드 관련 이벤트가 발생하는지 감시한다.\n</li></ul><p>\n&#9;</p>\n<p><strong>그림 9 Cluster Manager의 초기화 시나리오\n</strong></p>\n<h4>Watching\n</h4><ol><li>노드가 추가되거나 데이터가 변경된다면 ZooKeeper 서버로부터 Watch Event를 받는다.\n</li><li>Watch Event를 받으면 상태가 변경된 서버 중에 /clusters 디렉터리 아래 동일 서버를 확인하고 Master 서버의 상태가 변경되었는지 확인한다.\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 10 Cluster Manager의 Watching 시나리오\n</strong></p>\n<h4>Failover\n</h4><ol><li><div>Master 서버가 abnormal 상태로 변경되면 다음과 같은 작업을 수행한다.\n</div><ol><li>이전 Master 서버는 standby 상태로 변경한다.\n</li><li>Slave 서버 중에 1개를 Master 상태로 변경한다.\n</li><li>변경할 Slave 서버가 없다면 백업 서버를 Slave 서버와 같은 절차로 Master로 변경한다.\n</li></ol><blockquote><p><strong>참고<br></strong>Master와 Slave 서버는 같은 IDC 내 다른 access switch에 구성했고, 백업 서버는 다른 IDC에 구성했다.\n</p>\n</blockquote></li><li>ZooKeeper 디렉터리 정보를 모두 업데이트했으면, Redis Java Client인 Jedis로 slaveofNoOne 명령을 실행시켜 신규 Master가 될 Redis 서버를 Master role로 변경한다.\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 11 Cluster Manager의 Failover 시나리오\n</strong></p>\n<h4>설정 팁\n</h4><p>참고로 위와 같이 Cluster Manager의 Failover 기능을 정상적으로 이용하기 위해 NNI에서 사용하는 Redis 메시지 데이터베이스 서버는 다음과 같은 설정을 이용해 실행된다.\n</p>\n<ul><li>Master, Slave는 dump file off, Backup 서버는 dump on 설정을 한다. 아래 내용이 redis.conf 파일에 포함되어 있다면 dump on 설정이다. 아래 내용에 대해서 좀 더 자세히 살펴보면 900초 동안 1건의 데이터 변경이 발생하거나 300초 동안 10건의 데이터가 변경되거나 60초 동안 10000건의 데이터가 변경될 경우 디스크 저장을 시도하라는 옵션이다.\n</li></ul><p></p>\n<code>Save 900 1<br>Save 300 10<br>Save 60 10000\n</code><p></p>\n<ul><li>장비 성능이 좋지 않은 경우 Loglevel을 verbose에서 notice로 변경할 필요가 있다. Verbose로 로그 레벨을 설정하면, 로그를 남기다가 Redis operation 성능 저하로 1~2초 정도 멈추는 현상이 발생할 수 있다. \n</li></ul><p></p>\n<code>Loglevel notice\n</code><p></p>\n<h3>Shardrule Manager\n</h3><p>Shardrule Manager는 ZooKeeper 서버에 생성된 /clusters 하위 디렉터리를 Watch 설정을 통해 감시하고 있다가 클러스터 내 Master Redis 서버 정보가 변경되었을 경우 해당 Event를 받아 /shard-rules의 plan-1, plan-2 노드를 업데이트하는 기능을 수행한다.\n</p>\n<p>plan-1 및 plan-2 노드의 데이터는 Shard별 Master IP를 콤마 구분자로 구분하는 데이터이며 애플리케이션 서버에 제공된 ShardedRedisClient에서 해당 정보를 이용해 서버 Hashing을 하는 정보로 활용되고 있다.\n</p>\n<p>애플리케이션 서버(NPUSH-NNI의 NCS 서버)는 /shard-rules 하위 디렉터리를 Watching하고 있다가 Master 서버의 IP가 변경될 경우 신규 Master 서버로 접속하게 된다.\n</p>\n<p>다음은 Shardrule Manager의 주요 기능이다.\n</p>\n<h4>Initialize\n</h4><ul><li>/clusters 디렉터리의 하위 디렉터리에 모두 Watch 설정을 적용해 노드 관련 이벤트가 발생하는지 감시한다.\n</li></ul><p>\n&#9;</p>\n<p><strong>그림 12 Shardrule Manager의 초기화 시나리오\n</strong></p>\n<h4>Watching\n</h4><ol><li>/clusters 디렉터리 아래 노드가 추가되거나 데이터가 변경된다면 ZooKeeper 서버로부터 Watch Event를 받는다.\n</li><li>/clusters 디렉터리 아래의 Master 노드 정보와 shard-rules 노드 아래 plan-1, plan-2 노드의 데이터로 있는 Master IP 정보를 비교해 plan-1, plan-2의 데이터가 Master IP와 일치하는지 확인한다.\n</li><li>만일 일치하지 않는다면 shard-rules 노드 아래 plan-1, plan-2 노드의 데이터를 신규 Master IP 정보로 업데이트한다.\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 13 Shardrule Manager의 Watching 시나리오\n</strong></p>\n<h2>마치며\n</h2><p>Redis 데이터베이스를 클러스터 형태로 관리하는 것은 위에서 설명한 Redis Cluster Manager를 통한 방법 외에도 다양한 방법으로 구현할 수 있다.\n</p>\n<p>하지만 현재 시점에서 Redis 데이터베이스를 사용하거나 운영하는 사례가 많아진다면 우리와 같은 이슈에 대해서 고민하는 사람들이 많아질 것으로 예상한다. 따라서 우리가 개발한 사례를 좀 더 자세히 공유해 Redis 데이터베이스를 운영할 때 참조할 수 있는 자료로 활용할 수 있을 것이다.\n</p>\n<p>Redis 데이터베이스는 RDBMS와는 달리 팀에서 자체적으로 필요에 따라 적용해 설치, 서비스 반영, 운영 등을 시작하고 있는 단계이다. 이러한 상황에서 더 전문적이고 체계적인 운영 기술 및 노하우가 취합되고 공유되었으면 하는 바람이다.\n</p>\n<h2>참고 자료\n</h2><ul><li>Redis: <a href=\"http://redis.io/\">http://redis.io/</a>\n&#9;&#9;</li><li>ZooKeeper: <a href=\"http://zookeeper.apache.org/\">http://zookeeper.apache.org/</a>\n&#9;&#9;</li><li>Line Architecture: <a href=\"http://tech.naver.jp/blog/?p&#61;1420\">http://tech.naver.jp/blog/?p&#61;1420</a>\n&#9;&#9;</li></ul>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 클라우드플랫폼개발랩 임영완\n&#9;&#9;개발에 연관된 일은 모두 좋아하고, 사랑하는 개발자입니다.  어제보다 나은 코드를 뽑아내기 위해 항상 노력하고, 지금은 후학양성을 위해 현재 5살 아이에게 Python을 가르치고 있습니다.\n&#9;&#9;<br>\n&#9;&#9;\n</div>\n\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 클라우드플랫폼개발랩 배상용\n&#9;&#9;2009년부터 NHN의 SMS, 안드로이드 푸시메시지 인프라 개발 및 운영을 담당하고 있습니다. 인프라라는 것은 개발뿐만 아니라 운영도 중요하구나 라는 것을 많이 느끼고 있고, 운영을 잘하기 위해서라도 다양한 플랫폼에 대한 지식과 개발 노하우를 쌓기 위해 노력하고 있습니다.\n&#9;&#9;\n</div></div>"},{"name":"L4/L7 스위치의 대안, 오픈 소스 로드 밸런서 HAProxy","published":1360831093,"description":"<div><p>NHN Business Platform 클라우드플랫폼개발랩 박영희</p>\n<p>Ncloud에서 하드웨어로 구성된 기존의 로드 밸런서(load balancer)를 대체할 수 있는 솔루션을 찾던 중 소프트웨어 로드 밸런서인 HAProxy를 검토하게 됐습니다. HAProxy를 검토하면서 정리한 자료와 사내 개발용 Ncloud(ncloud.nhncorp.com) 서비스에 HAProxy를 적용한 사례를 공유하려 합니다.\n</p>\n<p>HAProxy를 이해하기 위해서 우선 로드 밸런서의 기본 개념을 이해하고 HAProxy의 동작 방식을 알아보겠습니다. 그리고 HAProxy로 설계 가능한 구조를 알아보겠습니다.\n</p>\n<h2>오픈 소스 로드 밸런서 HAProxy\n</h2><p>HAProxy는 기존의 하드웨어 스위치를 대체하는 소프트웨어 로드 밸런서로, 네트워크 스위치에서 제공하는 L4, L7 기능 및 로드 밸런서 기능을 제공한다. HAProxy는 설치가 쉽고 또한 환경 설정도 어렵지 않으므로 서비스 이중화를 빠르게 구성하고 싶다면 HAProxy를 추천한다.\n</p>\n<h3>로드 밸런싱이란?\n</h3><p>로드 밸런싱이란 부하 분산을 위해서 가상(virtual) IP를 통해 여러 서버에 접속하도록 분배하는 기능을 말한다. 로드 밸런싱에서 사용하는 주요 기술은 다음과 같다.\n</p>\n<ul><li>NAT(Network Address Translation): 사설 IP 주소를 공인 IP 주소로 바꾸는 데 사용하는 통신망의 주소 변조기이다.\n</li><li>DSR(Dynamic Source Routing protocol): 로드 밸런서 사용 시 서버에서 클라이언트로 되돌아가는 경우 목적지 주소를 스위치의 IP 주소가 아닌 클라이언트의 IP 주소로 전달해서 네트워크 스위치를 거치지 않고 바로 클라이언트를 찾아가는 개념이다.\n</li><li>Tunneling: 인터넷상에서 눈에 보이지 않는 통로를 만들어 통신할 수 있게 하는 개념으로, 데이터를 캡슐화해서 연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화를 해제할 수 있다.\n</li></ul><h3>로드 밸런서 동작 방식\n</h3><p>이제 일반적인 로드 밸런서의 동작 방식을 설명하고 HAProxy를 설명하겠다.\n</p>\n<p>로드 밸런서의 동작을 간단하게 설명하면, 네트워크에서 IP 주소와 MAC 주소를 이용해 목적지(destination) IP 주소를 찾아가고 출발지로 되돌아오는 구조이다. 이 글에서는 4가지의 로드 밸런서 동작 방식을 설명하겠다. 일반적인 로드 밸런서의 동작을 참조하기 위한 것이므로 정확하게 이해하지 못해도 상관없다.\n</p>\n<p></p>\n<h4>Bridge/Transparent Mode\n</h4><p></p>\n<p>사용자가 서비스를 요청하면 L4로 전달된 목적지 IP 주소를 real server IP 주소로 변조하고 MAC 주소를 변조해서 목적지를 찾아가는 방식이다.\n</p>\n<ol><li>요청 전달 시 변조<br>- 사용자 &gt; L4 &gt; NAT(IP/MAC 주소 변조) &gt; real server<br>- 사용자가 L4를 호출하면 중간에 NAT가 목적지 IP 주소를 real server IP 주소로 변조하고 MAC 주소도 변조한다.\n</li><li>응답 전달 시 변조<br>- real server &gt; NAT &gt; L4 &gt; 사용자<br>- real server에서 L4를 거치면서 출발지(source) IP 주소를 L4 가상 IP 주소로 변조한다. 동일 네트워크 대역이므로 MAC 주소는 변조하지 않는다.\n</li></ol><p></p>\n<h4>Router Mode\n</h4><p></p>\n<p>Bridge/Transparent Mode와 유사하지만 출발지(source) MAC 주소도 변조된다.\n</p>\n<p></p>\n<h4>One Arm Mode\n</h4><p></p>\n<p>사용자가 real server에 접근할 때 목적지 IP는 L4 스위치 IP를 바라본다. L4에 도달하면 L4가 클라이언트에게 받은 목적지 IP 주소를 L4 IP 주소에서 real server IP와 real server MAC 주소로 변조한다. 되돌아가는 IP는 L4의 IP pool의 IP 주소로 변조한다.\n</p>\n<p></p>\n<h4>DSR (Direct Server Return) Mode\n</h4><p></p>\n<p>사용자가 real server에 접근할 때 출발지와 목적지의 IP 주소를 변조하지 않고, L4에서 관리하는 real server의 MAC 주소 테이블을 확인해서 MAC 주소만 변조한다.\n</p>\n<h3>HAProxy 동작 방식\n</h3><p>HAProxy는 기본적으로 reverse proxy 형태로 동작한다. 우리가 브라우저에서 사용하는 proxy는 클라이언트 앞에서 처리하는 기능으로, forward proxy라 한다. reverse proxy의 역할을 간단히 설명하면, 실제 서버 요청에 대해서 서버 앞 단에 존재하면서, 서버로 들어오는 요청을 대신 받아서 서버에 전달하고 요청한 곳에 그 결과를 다시 전달하는 것이다.\n</p>\n<p>HAProxy의 동작 방식을 알아보고 HAProxy를 이용해서 어떤 구조로 확장할 수 있는지 알아보겠다.\n</p>\n<p>HAProxy의 동작 흐름은 다음과 같다.\n</p>\n<ol><li>최초 접근 시 서버에 요청 전달\n</li><li>응답 시 쿠키(cookie)에 서버 정보 추가 후 반환\n</li><li>재요청 시 proxy에서 쿠키 정보 확인 &gt; 최초 요청 서버로 전달\n</li><li>다시 접근 시 쿠키 추가 없이 전달 &gt; 클라이언트에 쿠키 정보가 계속 존재함(쿠키 재사용)\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 1 HAProxy 동작 방식\n</strong></p>\n<h3>HAProxy HA(High availability) 구성\n</h3><p>HAProxy는 기본적으로 VRRP(Virtual Router Redundancy Protocol)를 지원한다. HAProxy의 성능상 초당 8만 건 정도의 연결을 처리해도 크게 무리가 없지만, 소프트웨어 기반의 솔루션이기 때문에 HAProxy가 설치된 서버에서 문제가 발생하면 하드웨어 L4보다는 불안정할 수 있다. 따라서 HA 구성으로 master HAProxy에 문제가 생기는 경우에도 slave HAProxy에서 서비스가 원활하게 제공될 수 있는 구성을 알아보겠다.\n</p>\n<p>다음 그림과 같은 구성에서는 가상 IP 주소를 공유하는 active HAProxy 서버와 standby HAProxy 서버가 heartbeat를 주고 받으면서 서로 정상적으로 동작하는지 여부를 확인한다. active 상태의 서버에 문제가 발생하면 standby HAProxy가 active 상태로 변경되면서 기존 active HAProxy의 가상 IP 주소를 가져오면서 서비스가 무정지 상태를 유지한다. 다만 1초 정도의 순단 현상은 발생할 수 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 HAProxy 무정지 구성\n</strong></p>\n<p>HA로 설정된 HAProxy의 동작 흐름이 단일 HAProxy와 다른 점은 최초 접근 시 쿠키에 바로 서버 정보를 입력하지 않고 서버에서 jsessionid가 전달될 때 서버 정보를 합쳐서 전달한다는 것이다.\n</p>\n<ol><li>쿠키에 정보 추가 없고 X-Forwarded-For에 정보 추가\n</li><li>쿠키에 추가 없음\n</li><li>Jsessionid 추가\n</li><li>서버 정보 &#43; jsessionid를 쿠키에 추가\n</li><li>쿠키에서 서버 판별 후 jsessionid만 전달\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 3 HA 구성 시 동작 방식\n</strong></p>\n<h3>L4 &#43; HAProxy HA 구성 및 Global 환경에서 구성\n</h3><p>HAProxy와 기존 하드웨어 스위치를 이용해서 더 확장된 형태의 고가용성 구조를 설계할 수가 있다. 다음과 같은 형태의 구성도 가능하다.\n</p>\n<p></p>\n<h4>하드웨어 L4 &#43; HAProxy\n</h4><p></p>\n<p>클라이언트에서 연결되는 부분은 가상 IP 주소 &#43; L4의 구성으로 하드웨어 이중화를 구축하고, L4에서 서버 앞 단에 HAProxy를 구축해서 HAProxy를 더 확장할 수 있는 구조로 설계할 수 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 4 L4 &#43; HAProxy 구성\n</strong></p>\n<p></p>\n<h4>GSLB(Global Service Load Balancing) &#43; HAProxy\n</h4><p></p>\n<p>global 서비스가 증가되면서 IDC 간 이중화 및 global 환경에서의 무정지 서비스를 위한 DR(Disaster Recovery, 재해 복구) 시스템 구축이 필수 요구사항이 되었다. GSLB &#43; HAProxy를 이용하면 global한 무정지 서비스 구축이 가능하다.\n</p>\n<p>GSLB 구축에 L4 스위치를 사용할 수도 있지만 GSLB 구성용 L4는 고가의 장비이다. 따라서 L4를 이용한 GSLB 대신 DNS(BIND)를 이용한 구축 형태는 다음과 같다.\n</p>\n<ol><li>클라이언트에서 DNS로 도메인 조회\n</li><li>근거리 IDC 정보 전달\n</li></ol><p>\n&#9;</p>\n<p><strong>그림 5 Global 환경에서 GSLB&#43;HAProxy 구성\n</strong></p>\n<p>이상 로드 밸런서의 동작 원리와 HAProxy를 이용한 다양한 구축 방법에 대해서 알아보았다. 이제 실제 HAProxy를 설치하기 위한 옵션 및 설치 방법에 대해서 알아보겠다.\n</p>\n<h2>HAProxy Ncloud 적용 사례\n</h2><p>사내 개발자용 Ncloud 시스템은 DNS에서 RR(Round Robin) 기능을 통해 이중화된 서비스로 운영하고 있었다. 그런데 DNS의 경우 팀에서 관리하는 시스템도 아니고 서버 증설 또는 제거를 위해서 매번 관리 시스템을 통해서 작업하는 것이 번거로웠다. 또한 HAProxy의 실제 적용을 테스트하기 위해서 우리가 관리하는 시스템에 적용했는데, 이 적용 및 운영 사례를 살펴보겠다.\n</p>\n<h3>사내 Ncloud 시스템의 DNS RR을 HAProxy로 교체\n</h3><p>사내 Ncloud 시스템의 DNS RR을 HAProxy로 교체하여 &lt;그림 6&gt;과 같이 앞에서 설명한 HA 구성과 동일한 형태로 구성했다. 그 결과 기존 DNS로 구성할 때보다 서버 증설 및 삭제에 있어 유연성이 증가했으며 HA 구성으로 서비스 안정성도 높아졌다.\n</p>\n<p>그런데 서버 반영 후 애플리케이션 서버에서 클라이언트 IP 주소를 찾아서 처리하는 로직에 문제가 발생했다. 확인 결과 사용자의 요청이 HAProxy를 거치면서 클라이언트 IP 주소 정보가 HAProxy의 정보로 변조되어 보이는 상황이었다.\n</p>\n<p>이 문제가 발생하지 않도록 하기 위해서 HAProxy에서 제공하는 X-Forwarded-For 옵션을 적용하고 Apache 서에는 mod_rpaf 모듈을 설치해서 애플리케이션 서버가 HTTP 헤더에서 클라이언트 IP 주소를 조회하면 실제 클라이언트 IP 주소가 반환되도록 보완했다. \n</p>\n<p>\n&#9;</p>\n<p><strong>그림 6 HAProxy 적용 구조\n</strong></p>\n<p>실제 적용 후 서버 L7 check가 잘 되고 있는지 HAProxy가 제공하는 어드민 페이지에서 확인했고, 클라이언트 IP 주소 문제 외에 별다른 이슈는 발생하지 않았다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 7 HAProxy 어드민 페이지\n</strong></p>\n<h3>HAProxy 성능\n</h3><p>Ncloud는 동시 접속자가 많은 시스템이 아니라 성능에 대해 크게 문제될 부분이 없었지만 HAProxy가 설치되는 서버의 사양에 따라 어느 정도 성능이 제공되는지 확인하기 위해 성능을 측정했다. 여기에서는 nGrinder(<a href=\"http://www.nhnopensource.org/ngrinder/\">http://www.nhnopensource.org/ngrinder/</a>) 테스트 결과와 해외 사례를 공유한다.\n</p>\n<p></p>\n<h4>1. 해외 운영 사례\n</h4><p></p>\n<ul><li>서버 사양(저사양): Dell PowerEdge 2850, Intel PCI3 4x Gigabit Fiber card (CPU 1.6GHz dual core x 1)\n</li><li>제공 서비스: 영화 다운로드 서비스\n</li><li>결과: 일별 2.47TB 전송 &#43; 81일 동안 운영\n</li></ul><p></p>\n<h4>2. nGrinder 테스트\n</h4><p></p>\n<ul><li>환경: HAProxy (1core), apache 서버 2대\n</li><li>결과: 6,603 TPS\n</li></ul><p>\n&#9;</p>\n<p><strong>그림 8 nGrinder 테스트 결과\n</strong></p>\n<p></p>\n<h4>3. 해외 성능 사례\n</h4><p></p>\n<ul><li>듀얼 CPU 환경에서 초당 2만 세션까지 연결 가능<br>-&gt; CPU 성능이 높아지면 연결 가능 세션 수 증가\n</li><li>초당 1만 건 세션 연결 시 응답에 100밀리초(ms) 소요 <br>-&gt; 최대 연결 개수는 하드웨어의 RAM과 file descriptor에 의해 결정됨<br>-&gt; 세션당 16KB 사용 시 6만 세션당 1G RAM 필요\n</li></ul><p>\n&#9;</p>\n<p><strong>그림 9 해외 성능 테스트 사례(이미지 출처: <a href=\"http://haproxy.1wt.eu/\">http://haproxy.1wt.eu/#perf</a>)\n</strong></p>\n<h2>HAProxy 설치 및 옵션\n</h2><p>HAProxy의 중요 옵션과 단점에 대해서 간단하게 알아보겠다. 자세한 설치 방법 및 서비스에 사용되는 설정은 마지막에 설명해 놓았으니 실제 설치가 필요한 경우에 참고하기 바란다.\n</p>\n<h3>HAProxy 운영 시 필요한 옵션\n</h3><p>HAProxy의 경우 튜닝 옵션을 비롯하여 매우 많은 옵션을 지원하므로 여기에서는 실제 구축 시 필요한 옵션만 간략하게 알아보겠다.\n</p>\n<p>옵션을 변경하려면 haproxy.cfg 파일을 수정한다. 실제 수정 방법은 설치 방법에서 설명한다. 더 자세한 설명이 필요하면 다음 웹 페이지에서 확인하기 바란다.\n</p>\n<ul><li>HAProxy 설정 매뉴얼: <a href=\"http://cbonte.github.com/haproxy-dconv/configuration-1.4.html\">http://cbonte.github.com/haproxy-dconv/configuration-1.4.html</a>\n&#9;&#9;</li></ul><h3>HAProxy 옵션\n</h3><p>다음은 전역 옵션(global) 섹션과 기본 옵션(defaults) 섹션, 프록시 옵션 섹션(listen)의 주요 옵션에 관한 설명이다.\n</p>\n<ul><li><div>global # 전역 옵션 섹션\n</div><ul><li>daemon: 백그라운드 모드(background mode)로 실행\n</li><li>log: syslog 설정\n</li><li>log-send-hostname: hostname 설정\n</li><li>uid: 프로세스의 userid를 number로 변경\n</li><li>user: 프로세스의 userid를 name으로 변경\n</li><li>node: 두 개 이상의 프로세스나 서버가 같은 IP 주소를 공유할 때 name 설정(HA 설정)\n</li><li>maxconn: 프로세스당 최대 연결 개수\n</li></ul></li><li><div>Defaults # 기본 옵션 섹션\n</div><ul><li>log: syslog 설정\n</li><li>maxconn: 프로세스당 최대 연결 개수\n</li></ul></li><li><div>listen webfarm 10.101.22.76:80 : haproxy name ip:port\n</div><ul><li>mode http: 연결 프로토콜\n</li><li>option httpchk: health check\n</li><li>option log-health-checks: health 로그 남김 여부\n</li><li>option forwardfor: 클라이언트 정보 전달\n</li><li>option httpclose: keep-alive 문제 발생 시 off 옵션\n</li><li>cookie SERVERID rewrite: 쿠키로 서버 구별 시 사용 여부\n</li><li>cookie JSESSIONID prefix: HA 구성 시 prefix 이후에 서버 정보 주입 여부\n</li><li>balance roundrobin: 순환 분배 방식\n</li><li>stats enable: 서버 상태 보기 가능 여부\n</li><li>stats uri /admin: 서버 상태 보기 uri\n</li><li>server xvadm01.ncli 10.101.22.18:80 cookie admin_portal_1 check inter 1000 rise 2 fall 5: real server 정보(server [host명] [ip]:[port] cookie [서버쿠키명] check inter [주기(m/s)] rise [서버구동여부점검횟수], fall [서비스중단여부점검횟수])\n</li></ul></li></ul><h3>balance 옵션\n</h3><p>로드 밸런싱의 경우 round robin 방식을 일반적으로 사용하지만 다른 여러 방식이 있다. 옵션에 적용할 수 있는 로드 밸런싱 알고리즘은 다음과 같다.\n</p>\n<ul><li>roundrobin: 순차적으로 분배(최대 연결 가능 서버 4128개)\n</li><li>static-rr: 서버에 부여된 가중치에 따라서 분배\n</li><li>leastconn: 접속 수가 가장 적은 서버로 분배\n</li><li>source: 운영 중인 서버의 가중치를 나눠서 접속자 IP를 해싱(hashing)해서 분배\n</li><li>uri: 접속하는 URI를 해싱해서 운영 중인 서버의 가중치를 나눠서 분배(URI의 길이 또는 depth로 해싱)\n</li><li>url_param: HTTP GET 요청에 대해서 특정 패턴이 있는지 여부 확인 후 조건에 맞는 서버로 분배(조건 없는 경우 round robin으로 처리)\n</li><li>hdr: HTTP 헤더 에서 <strong>hdr(&lt;name&gt;)</strong>으로 지정된 조건이 있는 경우에 대해서만 분배(조건 없는 경우 round robin으로 처리)\n</li><li>rdp-cookie:  TCP 요청에 대한 RDP 쿠키에 따른 분배\n</li></ul><h3>HAProxy 1.4.22 단점 - SSL 미지원\n</h3><p>1.4.22 안정화 버전에서는 기본 기능으로 SSL을 지원하지 않고 있다. 1.4.22 버전에서 HTTP와 HTTPS를 같이 지원하려면 Apache &#43; mod_ssl &#43; HAProxy를 구성해서 Apache를 reverse-proxy-cache로 사용한다. only HTTPS 모드이면 stunnel을 설정하고 사용할 수 있다.\n</p>\n<p>현재 개발 중인 1.5_dev 버전은 에서는 정식으로 SSL을 지원할 예정이다.\n</p>\n<h3>HAProxy 설치 및 config 수정\n</h3><p>HAProxy 설치를 위한 소스 파일 다운로드와 설치 절차는 다음과 같다.\n</p>\n<p><strong>예제 1 HAProxy 소스 다운로드 및 설치 절차\n</strong></p>\n<p></p>\n<code>$ wget http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.22.tar.gz<br>$ tar xvfz haproxy-1.4.22.tar.gz<br>$ cd harproxy-1.4.22<br>$ make TARGET&#61;linux26 ARCH&#61;x86_64<br>$ make install<br>$ cd examples<br>$ cp haproxy.init /etc/rc.d/init.d/haproxy<br>$ chmod 755 /etc/rc.d/init.d/haproxy<br>$ mkdir -p /etc/haproxy/<br>$ cp /생성위치/haproxy-1.4.22/examples/haproxy.cfg /etc/haproxy/<br>$ mkdir -p /etc/haproxy/errors/<br>$ cp /생성위치/haproxy-1.4.22/examples/errorfiles/* /etc/haproxy/errors/<br>$ cd /usr/sbin<br>$ ln -s /usr/local/haproxy/sbin/haproxy haproxy<br>$ vi /etc/haproxy/haproxy.cfg\n</code><p></p>\n<p>haproxy.cfg 파일은 다음 설정 예제를 참고해서 수정하면 된다.\n</p>\n<p><strong>예제 2 HAProxy 환경 설정 예제\n</strong></p>\n<p></p>\n<code>#서버 정보<br>#LB ip         10.101.22.33<br>#server-1 10.101.27.49<br>#server-2 10.101.26.50<br><br>global<br>        log 127.0.0.1   local0<br>        log 127.0.0.1   local1 notice<br>        maxconn 4096<br>        uid 99<br>        gid 99<br>        daemon<br>        log-send-hostname<br>        #debug<br>        #quiet<br><br>defaults<br>        log     global<br><br>listen  webfarm 10.101.22.33:80<br>        mode http<br>        option httpchk GET /l7check.html HTTP/1.0<br>        option log-health-checks<br>        option forwardfor<br>        option httpclose<br>        cookie SERVERID rewrite<br>        cookie JSESSIONID prefix<br>        balance roundrobin<br>        stats enable<br>        stats uri /admin<br>        server  xvadm01.ncli 10.101.27.49:80 cookie admin_portal_1 check inter 1000 rise 2 fall 5<br>        server  xvadm02.ncli 10.101.26.50:80 cookie admin_portal_2 check inter 1000 rise 2 fall 5<br>$ /etc/init.d/haproxy start\n</code><p></p>\n<h2>마치며\n</h2><p>HAProxy는 네트워크 담당자가 아닌 개발자들에게는 관심 없는 분야의 기술일 수 있다. 그렇지만 모바일 환경이 발달하면서 빠르고 유연한 확장성은 필수 요소로 생각해야 한다. 최초 서비스 구축 시 확장성을 고려해서 L4/L7 스위치 분산까지는 고려할 수 있겠지만 지역간 분산(GSLB 구성)을 고려해서 설계하는 것은 일부 업체를 제외하고는 비용 및 경험 부재로 쉽지 않은 것이 사실이다. 하지만 &#39;DNS &#43; HAProxy &#43; 클라우드 서비스&#39;로 조합하면 적은 비용으로도 동일한 수준으로 구축할수 있다. 그래서 HAProxy의 개념과 서비스 구축 방안 정도는 미리미리 습득하기를 권장한다.\n</p>\n<h2>참고 자료\n</h2><ul><li>HAProxy Configuration Manual  1.4.22-9: <a href=\"http://cbonte.github.com/haproxy-dconv/configuration-1.4.html\">http://cbonte.github.com/haproxy-dconv/configuration-1.4.html</a>\n&#9;&#9;</li><li>HAProxy 1.5-dev12 support SSL : <a href=\"http://blog.exceliance.fr/2012/09/04/howto-ssl-native-in-haproxy/\">http://blog.exceliance.fr/2012/09/04/howto-ssl-native-in-haproxy/</a>\n&#9;&#9;</li><li>HAProxy Performance : <a href=\"http://haproxy.1wt.eu/\">http://haproxy.1wt.eu/#perf</a>\n&#9;&#9;</li><li>Load Balancer : <a href=\"http://blog.loadbalancer.org/?a&#61;1\">http://blog.loadbalancer.org/?a&#61;1</a>\n&#9;&#9;</li><li>KeepAlived : <a href=\"http://keepalived.org/\">http://keepalived.org/</a>\n&#9;&#9;</li><li>Stunnel : <a href=\"https://www.stunnel.org/index.html\">https://www.stunnel.org/index.html</a>\n&#9;&#9;</li><li>Openssl : <a href=\"http://www.openssl.org/\">http://www.openssl.org/</a>\n&#9;&#9;</li></ul>\n&#9;&#9;\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 클라우드플랫폼개발랩 박영희\n&#9;&#9;주로 java로 개발을 하고 있고 또한 UI 측면의 javascript, css, html5과 테스트 자동화 및 애자일 개발 방법론 습득 및 전파를 좋아합니다. 최근 클라우드에 적용가능한 오픈소스 솔루션을 연구하고 적용하고 있습니다\n&#9;&#9;<br>\n&#9;&#9;\n</div></div>"},{"name":"2차 인증 소개","published":1360230162,"description":"<div><p>NHN Business Platform 회원플랫폼개발랩 나윤재</p>\n<p>로그인 과정에서 주로 사용하는 인증 방식은 아이디와 비밀번호를 입력하여 시스템 사용 권한을 확인하고 접근 권한을 부여하는 것입니다. 하지만 이런 방식은 스니핑(sniffing) 또는 키 로깅 등을 이용한 공격 방법에 의해 인증 정보가 쉽게 노출될 수 있다는 취약점이 있습니다. 이미 노출된 아이디, 비밀번호로 인해 개인 정보 유출이나 아이디 도용 등의 피해를 입기도 합니다.\n</p>\n<p>이런 피해를 줄이기 위해 주요 온라인 사이트에서는 지식 기반(아이디, 비밀번호) 인증에 소유 기반(보안카드, OTP 등) 인증을 추가한 2차 인증을 도입하고 있습니다. 소유 기반 인증은 사용자가 인증 요소를 소유하고 있어야 인증이 가능한 방식으로 보안카드, 하드웨어 방식의 OTP(One Time Password), 공인인증서 등이 주로 사용됩니다. 최근에는 스마트폰 사용자가 증가하면서 USIM(Universal Subscriber Identity Module) 기반 또는 VM(Virtual Machine) 기반의 모바일 OTP를 이용한 인증 서비스가 사용되고 있습니다.\n</p>\n<p>이 글에서는 OTP의 생성 방식 및 2차 인증 적용 사례를 소개하겠습니다.\n</p>\n<h2>다양한 OTP 생성 방식\n</h2><p>OTP 생성 방식은 시도 응답(challenge-response) 방식, 시간 동기화(time-synchronous) 방식, 이벤트 동기화(event-synchronous) 방식, 시간-이벤트 동기화(time-event synchronous) 방식으로 나눌 수 있다. 각 방식의 장단점을 살펴보자.\n</p>\n<h3>시도 응답 방식\n</h3><p>서버가 제시하는 시도 값을 사용자가 알고리즘에 입력해 출력되는 값을 얻고 이를 응답 값으로 서버에 전송하여 자신을 인증하는 방식이다. 온라인 이체 시 사용하는 보안카드 숫자 입력이 시도 응답 방식의 대표적 예다. 즉, 서버가 임의의 난수를 생성하여 사용자에게 전송하면 사용자는 해당 시도 값을 OTP 토큰에 입력해 그 결과로 얻은 OTP를 다시 입력하는 방식이다.\n</p>\n<p>시도 응답 방식은 입력 값이 매번 임의의 값이 된다는 측면에서는 안전성을 갖추고 있으나, 네트워크 모니터링에 의해 전송되는 값이 노출될 수 있다는 단점이 있다. 또 서버와 클라이언트 사이의 통신 횟수도 비교적 많이 요구된다.\n</p>\n<p>다음은 시도 응답 방식의 인증 과정을 나타낸 것이다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1</strong>\n&#9;&#9;<strong>시도 응답 방식\n</strong></p>\n<ol><li>시도 값 생성\n</li><li>생성된 시도 값 전달\n</li><li>시도 값을 이용해서 OTP 생성\n</li><li>생성된 OTP 입력\n</li><li>OTP 인증 서버로 검증 요청\n</li><li>시도 값을 이용해서 OTP 생성 및 검증\n</li><li>OTP 검증 결과 전송\n</li></ol><h3>시간 동기화 방식\n</h3><p>시도 응답 방식은 사용자의 입력 값이 많다는 단점이 있다. 시간 동기화 방식은 이 문제를 개선하기 위해 임의의 난수 대신에 시간 값을 입력 값으로 사용해 OTP를 생성한다.\n</p>\n<p>서버와 OTP 토큰 간에 동기화된 시간을 기준으로 특정 시간 간격마다 변하는 OTP를 생성한다. 하지만 특정 시간 간격마다 OTP가 변하기 때문에 OTP를 입력하는 도중에 다른 값이 생성되어 OTP가 변경되는 단점이 있다. 이러한 단점 때문에 시간 간격을 길게 설정하면 공격자가 중간에 OTP를 알아채 사용할 가능성이 커지게 되는 또 다른 문제점도 생길 수 있다. 시간 동기가 어긋나면 인증이 실패할 수 있으므로 추가적으로 OTP 토큰과 서버 간의 시간 동기를 맞추는 알고리즘도 필요하다.\n</p>\n<p>시간 동기화 방식은 OTP가 노출되더라도 사용 시간을 제약하거나 동일 OTP값을 사용하지 못 하도록 제약할 수 있다. 하지만 특정 시간 동안 값을 입력하지 못하면 중간에 OTP값이 변경되어 다시 입력해야 한다.\n</p>\n<p>다음은 시간 동기화 방식의 인증 과정을 나타낸 것이다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 시간 동기화 방식\n</strong></p>\n<ol><li>OTP 토큰 내부의 자체 시간 정보를 이용해서 OTP 생성\n</li><li>생성된 OTP값 입력\n</li><li>OTP 검증 서버로 검증요청\n</li><li>서버의 자체 시간 정보를 이용해서 OTP 생성 및 검증\n</li><li>OTP 검증 결과를 전송\n</li></ol><h3>이벤트 동기화 방식\n</h3><p>이벤트 동기화 방식은 서버와 OTP 토큰이 동기화된 시간 대신에 동일한 카운트 값을 기준으로 비밀번호를 생성한다. 사용자가 OTP를 생성할 때 카운트 값을 OTP 알고리즘의 입력 값으로 사용하여 OTP를 생성하고, OTP를 생성한 후에는 카운트 값을 증가시켜서 저장해 두었다가 다음 번에 사용한다.\n</p>\n<p>이 방식은 인증 실패 시 재시도를 위해 특정 시간을 기다릴 필요가 없지만, OTP 토큰에서 OTP만 여러 번 생성하고 해당 OTP를 서버에 입력하지 않으면 OTP 토큰과 서버 간의 카운트 값이 달라져 OTP 토큰을 다시 초기화해야 하는 단점이 있다.\n</p>\n<p>다음은 이벤트 동기화 방식의 인증 과정을 나타낸 것이다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 3 이벤트 동기화 방식\n</strong></p>\n<ol><li>토큰 내부의 이벤트 정보를 이용해서 OTP 생성\n</li><li>생성된 OTP값 입력\n</li><li>OTP 인증 서버로 검증요청\n</li><li>서버의 자체 이벤트 정보를 이용해서 OTP 생성 및 검증\n</li><li>OTP 검증 결과를 전송\n</li></ol><h3>시간-이벤트 동기화 방식\n</h3><p>시간 동기화와 이벤트 동기화 방식의 단점을 보완하기 위해서 두 가지 방식을 조합한 OTP 생성 방식이다. 시간-이벤트 동기화 방식은 OTP 생성 입력 값으로 시간 값과 카운터 값을 모두 사용한다.\n</p>\n<p>시간 동기화와 같이 특정 시간 간격마다 비밀번호를 새로 생성하며, 같은 시간 내에 OTP 생성 요청이 여러 번 발생하면 카운트 값을 증가시켜 새로운 OTP를 생성한다. 동일한 시간 간격 내에서도 새로운 OTP를 생성할 수 있으므로 OTP의 일회성을 높여 안전성이 뛰어나다.\n</p>\n<p>다음은 시간-이벤트 동기화 방식의 인증 과정을 나타낸 것이다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 4 시간-이벤트 동기화 방식\n</strong></p>\n<ol><li>OTP 토큰 내부의 자체 시간 정보와 이벤트 정보를 이용해서 OTP 생성\n</li><li>생성된 OTP값 입력\n</li><li>OTP 인증 서버로 검증 요청\n</li><li>서버의 자체의 시간 정보와 이벤트 정보를 이용해서 OTP 생성 및 검증\n</li><li>OTP 검증 결과를 전송\n</li></ol><h2>2차 인증 적용 사례\n</h2><p>OTP 방식의 2차 인증을 제공하고 있는 주요 온라인 사이트의 사례는 다음과 같다.\n</p>\n<h3>Google의 2차 인증\n</h3><p>Google은 휴대폰 SMS(Short Message Service)와 음성 통화로 인증 코드를 제공하는 방법으로 2차 인증을 제공한다. 로그인 후 <strong>계정 &gt; 보안 &gt; 2단계 인증</strong>에서 신청할 수 있다. 로그인할 때마다 2차 인증을 물어 보는 불편함을 줄이려면 <strong>이 컴퓨터를 신뢰함</strong>을 선택하여 동일 브라우저에서 로그인 시 2차 인증을 생략할 수 있다.\n</p>\n<p>휴대전화를 사용할 수 없는 경우를 대비해 미리 백업 인증 코드 10개를 제공하며, 각 코드는 한 번씩만 사용할 수 있다. 백업 인증 코드가 부족하면 새 백업 코드를 생성한다. 브라우저 외부에서 작동하는 일부 애플리케이션에서 2차 인증이 지원되지 않아 인증 코드를 요청할 수 없을 때는 애플리케이션 비밀번호를 생성하여 사용해야 한다.\n</p>\n<h3>Facebook의 2차 인증\n</h3><p>Facebook은 SMS로 보안 코드를 전달받아 로그인하는 형태의 2차 인증을 제공한다. 로그인 후 <strong>계정 설정 &gt; 보안 &gt; 로그인 승인</strong>에서 신청할 수 있다. Google과 마찬가지로 &#39;인증된 기기&#39;를 등록하면 동일 브라우저에서 로그인 시 2차 인증을 생략할 수 있다. <strong>로그인 승인</strong> 기능을 활성화할 때는 기기 등록이 필수이다.\n</p>\n<p>Facebook은 앱에서 &#39;코드 생성기&#39;를 제공하므로 SMS를 받을 수 없거나 인터넷을 이용할 수 없을 때에도 인증 코드를 제공받아 로그인할 수 있다. Facebook 앱의 코드 생성기를 사용하려면 Facebook 앱에 로그인된 상태여야 한다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 5 Facebook의 코드 생성기\n</strong></p>\n<p>Facebook의 인증은 SMS의 보안 코드나 코드 생성기의 인증 코드 중 하나를 선택해 로그인할 수 있다는 점에서 Google과 다르다. 일부 Facebook 앱, Jabber, 스카이프, Xbox에서는 계정 비밀번호 대신 앱 비밀번호를 사용해 로그인한다.\n</p>\n<h3>네이버의 2차 인증\n</h3><p>네이버도 2012년부터 네이버 OTP를 이용한 2차 인증을 제공하고 있다. 로그인 후 <strong>내정보 &gt; 내정보보호 &gt; OTP</strong>에서 신청할 수 있다.\n</p>\n<p>네이버 OTP는 스마트폰(Android, iPhone)에 설치된 네이버앱의 <strong>설정 &gt; 네이버 OTP</strong>에서 확인할 수 있다. 일련번호가 생성되는 시점에 인증 서버와 키 교환이 필요하기 때문에 반드시 인터넷에 접속되어 있어야 하지만, 일련번호를 발급 받은 후에는 인터넷 접속 없이도 OTP 인증 번호를 확인할 수 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 6 네이버의 OTP\n</strong></p>\n<p>네이버 OTP는 시간-이벤트 동기화 방식으로 구현되어 있다. 특정 시간 동안 인증 번호가 유효하며, 뒤로 가기 후 다시 OTP 메뉴로 재진입하는 이벤트를 통해 새로운 인증 번호를 사용할 수도 있다.\n</p>\n<p>네이버 OTP는 Facebook의 코드 생성기와는 달리 별도의 OTP 일련번호가 존재하여 여러 아이디에 사용할 수 있으며, 타 서비스에도 적용할 수 있게 되어 있다.\n</p>\n<p>Google, Facebook과 마찬가지로 로그인 시에 OTP 상태유지와 애플리케이션 비밀번호를 제공하고 있다.\n</p>\n<p>Google, Facebook과 마찬가지로 로그인 시에 OTP 인증 유지를 선택하면 동일 브라우저에서 로그인 시 2차 인증을 생략할 수 있다. 아웃룩, 스마트TV 등 네이버 OTP 인증번호를 입력할 수 없는 환경을 위해서 애플리케이션 비밀번호를 제공하고 있다.\n</p>\n<p>네이버는 OTP의 불편함을 느끼는 사용자를 위해 일회용 로그인 번호를 이용한 인증을 추가로 제공하고 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 7 네이버의 일회용 로그인 번호\n</strong></p>\n<p>네이버 앱에서 로그인된 아이디의 일회용 로그인 번호를 생성하고, 이를 통해 아이디, 비밀번호를 입력하지 않고도 로그인할 수 있다. 이 방식은 일회용 로그인 번호를 입력해 로그인하므로 공격자에게 아이디, 비밀번호가 노출되지 않고 안전하게 로그인할 수 있다는 장점이 있다.\n</p>\n<h2>마치며\n</h2><p>2012년 초, ZDNet에 Google의 QR코드 로그인에 관한 기사가 실린 적이 있다. 이 방법은 사용자가 브라우저에 특정 URL을 입력하여 QR코드를 생성하고, 로그인된 스마트폰의 QR코드 리더를 통해 이를 인식하여 해당 브라우저에 로그인하는 기능이다. 아직까지 실 서비스에 적용되지 않았지만, 빠르고 쉽게 로그인할 수 있다는 점에선 좋은 시도였다. 앞서 소개한 네이버의 일회용 로그인 번호도 아이디, 비밀번호와 같은 인증 정보를 직접 입력하지 않고 로그인할 수 있다는 점에선 QR코드 로그인과 유사하다고 할 수 있다.\n</p>\n<p>현재까지 2차 인증은 OTP 기반으로 제공되고 있지만, 앞으로의 2차 인증은 본인이 신뢰할 수 있는 기기에서만 로그인하고 그 인증 정보를 활용하여 다른 기기에서 로그인하는 방식으로 발전해 갈 것으로 예상된다.\n</p>\n<h2>참고 자료\n</h2><ul><li>Two-factor Authentication: <a href=\"http://en.wikipedia.org/wiki/Two-factor_authentication\">http://en.wikipedia.org/wiki/Two-factor_authentication</a>\n&#9;&#9;</li><li>Google&#39;s QR code login experiment concluded: <a href=\"http://www.zdnet.com/blog/igeneration/googles-qr-code-log-in-experiment-concluded/14679\">http://www.zdnet.com/blog/igeneration/googles-qr-code-log-in-experiment-concluded/14679</a>\n&#9;&#9;</li><li>국내외 OTP 표준화 동향: <a href=\"http://academic.naver.com/openUrl.nhn?doc_id&#61;54642187&amp;linkType&#61;doclink\">http://academic.naver.com/openUrl.nhn?doc_id&#61;54642187&amp;linkType&#61;doclink</a>\n&#9;&#9;</li><li>김태형, &#34;피싱방지 및 가용성개선을 위한 PKI기반의 모바일OTP 메커니즘 연구&#34;, 고려대학교 석사논문, 2010.12.\n</li></ul>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 회원플랫폼개발랩 나윤재\n&#9;&#9;회원플랫폼개발랩에서 네이버회원 업무를 담당하고 있다. 주로 BPM(Business Process Management), MIS(Management Information System), ETL(Extract, Transform, Load)등의 업무를 경험했고, 현재는 신규 아이디 시스템(NEOID)을 개발, 적용하고 있다.\n&#9;&#9;\n</div></div>"},{"name":"elasticsearch로 로그 검색 시스템 만들기","published":1359688385,"description":"<div><p>NHN Business Platform 글로벌플래폼개발랩 이재익</p>\n<p>elasticsearch는 Shay Banon이 Lucene을 바탕으로 개발한 분산 검색엔진입니다. 설치와 서버 확장이 매우 편리하기 때문에 개발하고 있는 시스템에 검색 기능이 필요하다면 elasticsearch를 적용하는 것을 권장하고 싶습니다. 분산 시스템이기 때문에 검색 대상 용량이 증가했을 때 대응하기가 무척 수월하다는 것이 장점입니다.\n</p>\n<p>이 글에서는 참고 자료의 내용을 바탕으로 기본적인 elasticsearch의 설치와 사용법을 설명하고, 실제 서비스에 적용할 때 고려해야 할 사항을 정리했습니다.\n</p>\n<h2>elasticsearch의 특징\n</h2><p>우선 관계형 데이터베이스에 익숙한 사람들을 위해 관계형 데이터베이스와 elasticsearch의 용어를 비교한 표를 참고 자료에서 인용했다.\n</p>\n<p><strong>표 1 관계형 데이터베이스와 elasticsearch 용어 비교\n</strong></p>\n<div><table><tbody><tr><td><p><strong>관계형 데이터베이스</strong></p>\n</td><td><p><strong>elasticsearch</strong></p>\n</td></tr><tr><td><p>Database</p>\n</td><td><p>Index</p>\n</td></tr><tr><td><p>Table</p>\n</td><td><p>Type</p>\n</td></tr><tr><td><p>Row</p>\n</td><td><p>Document</p>\n</td></tr><tr><td><p>Column</p>\n</td><td><p>Field</p>\n</td></tr><tr><td><p>Schema</p>\n</td><td><p>Mapping</p>\n</td></tr><tr><td><p>Index</p>\n</td><td><p>Everything is indexed</p>\n</td></tr><tr><td><p>SQL</p>\n</td><td><p>Query DSL</p>\n</td></tr></tbody></table></div><h3>JSON 기반의 스키마 없는 저장소\n</h3><p>elasticsearch는 검색엔진이지만, NoSQL처럼 사용할 수 있다. 데이터 모델을 JSON으로 사용하고 있어서, 요청과 응답을 모두 JSON 문서로 주고받고 소스 저장도 JSON 형태로 저장한다. 스키마를 미리 정의하지 않아도, JSON 문서를 넘겨주면 자동으로 인덱싱한다. 숫자나 날짜 등의 타입은 자동으로 매핑한다.\n</p>\n<h3>Multi-tenancy\n</h3><p>elasticsearch는 multit-enancy를 지원한다. 하나의 elasticsearch 서버에 여러 인덱스를 저장하고, 여러 인덱스의 데이터를 하나의 쿼리로 검색할 수 있다. &lt;예제 1&gt;의 경우 날짜별로 인덱스를 분리해 로그를 저장하고 있고, 검색 시에는 검색 범위에 있는 날짜의 인덱스를 하나의 쿼리로 요청하고 있다.\n</p>\n<p><strong>예제 1 Multi-tenency 예제 쿼리\n</strong></p>\n<p></p>\n<code># log-2012-12-26 인덱스에 로그 저장<br>curl -XPUT http://localhost:9200/log-2012-12-26/hadoop/1 -d &#39;{<br>    &#34;projectName&#34; : &#34;hadoop&#34;,<br>    &#34;logType&#34;: &#34;hadoop-log&#34;,<br>    &#34;logSource&#34;: &#34;namenode&#34;,<br>    &#34;logTime&#34;:&#34;2012-12-26T14:12:12&#34;,<br>    &#34;host&#34;: host1&#34;,<br>    &#34;body&#34;: &#34;org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile&#34;<br>}&#39;<br><br># log-2012-12-27 인덱스에 로그 저장<br>curl -XPUT http://localhost:9200/log-2012-12-27/hadoop/1 -d &#39;{<br>    &#34;projectName&#34; : &#34;hadoop&#34;,<br>    &#34;logType&#34;: &#34;hadoop-log&#34;,<br>    &#34;logSource&#34;: &#34;namenode&#34;,<br>    &#34;logTime&#34;:&#34;2012-12-27T02:02:02&#34;,<br>    &#34;host&#34;: &#34;host2&#34;,<br>    &#34;body&#34;: &#34;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&#34;<br>}&#39;<br><br># log-2012-12-26, log-2012-12-27 인덱스에 한번에 검색 요청<br>curl -XGET http://localhost:9200/ log-2012-12-26, log-2012-12-27/_search\n</code><p></p>\n<h2>확장성과 유연성\n</h2><p>elasticsearch는 확장성과 유연성이 매우 뛰어나다. 플러그인을 이용해 기능을 확장할 수 있다. 예를 들어 Thrift 플러그인이나 Jetty 플러그인을 사용하면 전송 프로토콜을 변경할 수 있다. 필수 플러그인이라고 할 수 있는 BigDesk나 Head를 설치하면 elasticsearh 모니터링 기능을 사용할 수 있게 된다. &lt;예제 2&gt;에서 보는 것처럼 동적으로 복제본 개수를 조정할 수도 있다. 다만 샤드 수는 인덱스별로 고정돼 있어 수정이 불가능하므로 노드 수와 향후 서버 확장을 고려해 초기에 적절한 수를 할당해야 한다.\n</p>\n<p><strong>예제 2 설정 변경 쿼리\n</strong></p>\n<p></p>\n<code>$ curl -XPUT http://localhost:9200/log-2012-12-27/ -d &#39;{<br>    &#34;settings&#34; : {<br>        &#34;number_of_shards&#34; : 10,<br>        &#34;number_of_replicas&#34; : 1<br>    }<br>}&#39;\n</code><p></p>\n<h2>분산 저장소\n</h2><p>elasticsearch는 분산 검색엔진이다. 키에 따라 여러 샤드가 구성되는 방식으로 데이터를 분산한다. 인덱스는 각각의 샤드마다 구성된다. 각각의 샤드는 0개 이상의 복제본을 가진다. elasticsearch는 클러스터링을 지원하며 클러스터가 가동될 때 여러 노드 중 하나가 메타데이터 관리를 위한 마스터 노드로 선출된다. 마스터 노드가 다운되면 자동으로 클러스터 내의 다른 노드가 마스터가 된다. 노드 추가 또한 매우 간단하다. 같은 네트워크에 노드를 추가하는 경우 추가된 노드가 멀티캐스트를 이용해 자동으로 클러스터를 찾아 자신을 추가한다. 같은 네트워크를 이용하지 않을 경우 유니캐스트로 마스터 노드의 주소를 명시해 주어야 한다(참고 영상:<a href=\"http://youtu.be/l4ReamjCxHo\">http://youtu.be/l4ReamjCxHo</a>).\n</p>\n<h2>설치하기\n</h2><h3>Quick Start\n</h3><p>elasticsearch는 무설정 설치가 가능하다. &lt;예제 3&gt;에서 볼 수 있는 것 처럼 공식 홈페이지에서 파일을 내려 받아 압축을 해제하기만 하면 바로 실행해 볼 수 있다.\n</p>\n<ol><li>다운로드\n</li></ol><p></p>\n<code>$ wget http://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-0.20.4.tar.gz<br>$ tar xvzf elasticsearch-0.20.4.tar.gz\n</code><p></p>\n<ol><li>서버 실행\n</li></ol><p><strong>예제 3 설치 및 실행 명령\n</strong></p>\n<p></p>\n<code>$ bin/elasticsearch -f\n</code><p></p>\n<h3>플러그인 설치\n</h3><p>elasticsearch는 플러그인을 통해 쉽게 기능을 확장할 수 있다. 관리 기능을 추가하거나 Lucene의 Analyzer를 변경하고 기본 전송 모듈을 Netty에서 Jetty로 변경하는 것도 가능하다. &lt;예제 4&gt;는 플러그인을 설치하기 위한 명령어다. &lt;예제 4&gt;의 첫 번째와 두 번째 줄에서 보이는 &#39;head&#39;와 &#39;bigdesk&#39;는 elasticsearch 모니터링을 위한 필수 플러그인이므로 꼭 설치해서 기능을 확인해 보도록 하자. 설치 후 http://localhost:9200/_plugin/head/와 http://localhost:9200/_plugin/bigdesk/로 접속하면 웹 브라우저를 이용해 상태를 확인해 볼 수 있다.\n</p>\n<p><strong>예제 4 플러그인 설치\n</strong></p>\n<p></p>\n<code>bin/plugin -install Aconex/elasticsearch-head<br>bin/plugin -install lukas-vlcek/bigdesk<br>bin/plugin -install elasticsearch/elasticsearch-transport-thrift/1.4.0<br>bin/plugin -url https://oss-es-plugins.s3.amazonaws.com/elasticsearch-jetty/elasticsearch-jetty-0.20.1.zip -install elasticsearch-jetty-0.20.1\n</code><p></p>\n<h3>주요 설정\n</h3><p>간단한 기능 테스트에는 설정 변경이 필요 없으나, 성능 테스트를 하거나 실서비스에 적용할 때에는 기본 설정에 대한 몇 가지 변경이 필요하다. &lt;예제 5&gt;를 참고하면 초기 설정 파일(elasticsearch.yml)에서 변경해야 할 설정 내용이 무엇인지 알 수 있다.\n</p>\n<p><strong>예제 5 주요 설정(config/elasticsearch.yml)\n</strong></p>\n<p></p>\n<code># 클러스터를 식별하기 위한 이름이므로 유일성과 의미를 가진 이름을 사용하자<br>cluster.name: es-cluster<br><br># 노드 이름은 자동으로 생성되지만 호스트명과 같이 클러스터 내에서 식별 가능한 이름을 활용하는 것이 좋다.<br>node.name: &#34;es-node1&#34;<br><br># 기본값은 아래 두 값이 모두 true다. node.master는 노드가 마스터가 될 수 있지에 대한 설정이고, node.data는 데이터를 저장하는 노드인지에 대한 설정이다. 보통은 두 값을 true로 설정하면 되고, 클러스터의 규모가 큰 경우에는 3가지 종류의 노드를 구성하기 위해 이 값을 노드별로 조정해 설정한다. 자세한 사항은 토폴로지(topology) 설정에서 다시 설명하겠다.<br>node.master: true<br>node.data: true<br><br># 샤드와 리플리카 수를 변경하는 설정이다. 아래 값은 기본값이다. <br>index.number_of_shards: 5<br>index.number_of_replicas: 1<br><br><br><br>#JVM의 스왑을 방지하려면 아래 설정 값을 true로 한다.<br>bootstrap.mlockall: true<br><br># 클러스터 내의 각 노드의 상태 체크를 위한 타임아웃 값으로, 너무 작게 하면 노드가 클러스터에서 자주 이탈하는 문제가 발생할 수 있어 적절한 값을 설정한다. 기본값은 3초다.<br>discovery.zen.ping.timeout: 10s<br><br># 기본값은 멀티캐스트를 사용하지만, 실환경에서는 다른 클러스터와 노드가 섞이는 위험이 발생할 수 있으므로 유니캐스트를 사용하고 두 번째 설정 값에 마스터가 될 수 있는 서버들의 목록을 나열하는 것이 좋다.<br>discovery.zen.ping.multicast.enabled: false<br>discovery.zen.ping.unicast.hosts: [&#34;host1&#34;, &#34;host2:port&#34;, &#34;host3[portX-portY]&#34;]\n</code><p></p>\n<h2>REST API 사용하기\n</h2><p>elasticsearch는 &lt;예제 6&gt;과 같은 형식의 REST API를 제공한다. 인덱스 생성과 삭제, 매핑 생성과 삭제, 검색, 설정 변경 등 대부분의 기능을 REST API를 통해 제공한다. REST API 이외에도 Java, Python, Ruby 등의 언어별 클라이언트도 제공하고 있다.\n</p>\n<p><strong>예제 6 REST API 형식\n</strong></p>\n<p></p>\n<code>http://host:port/(index)/(type)/(action|id)\n</code><p></p>\n<p>&lt;예제 7&gt;의 경우 날짜별로 인덱스를 분리하고, 프로젝트별로 타입을 나누어 관리하고 있다. 2012년 12월 27일에 hadoop이라는 프로젝트로 들어온 로그를 문서 단위로 생성하는 과정을 REST API를 사용해 수행하는 예다.\n</p>\n<p><strong>예제 7 REST API 사용 예\n</strong></p>\n<p></p>\n<code>#문서 생성<br>curl -XPUT http://localhost:9200/log-2012-12-27/hadoop/1<br>curl -XGET http://localhost:9200/log-2012-12-27/hadoop/1<br>curl -XDELETE http://localhost:9200/log-2012-12-27/hadoop/1<br><br>#검색<br>curl -XGET http://localhost:9200/log-2012-12-27/hadoop/_search<br>curl -XGET http://localhost:9200/log-2012-12-27/_search<br>curl -XGET http://localhost:9200/_search<br><br>#인덱스 상태 보기<br>curl -XGET http://localhost:9200/log-2012-12-27/_status\n</code><p></p>\n<h3>문서와 인덱스 생성\n</h3><p>&lt;예제 8&gt;에서처럼 요청을 보내면 인덱스와 타입이 정의돼 있지 않더라도 elasticsearch는 자동으로 log-2012-12-27 인덱스와 hadoop 타입을 생성한다. 자동으로 생성하지 않고 명시적으로 생성하려면 설정 파일에서 action.auto_create_index와 index.mapper.dynamic의 설정 값을 false로 명시해야 한다.\n</p>\n<p><strong>예제 8 문서 생성\n</strong></p>\n<p></p>\n<code># 요청<br>curl -XPUT http://localhost:9200/log-2012-12-27/hadoop/1 -d &#39;{<br>    &#34;projectName&#34; : &#34;hadoop&#34;,<br>    &#34;logType&#34;: &#34;hadoop-log&#34;,<br>    &#34;logSource&#34;: &#34;namenode&#34;,<br>    &#34;logTime&#34;:&#34;2012-12-27T02:02:02&#34;,<br>    &#34;host&#34;: &#34;host2 &#34;,<br>    &#34;body&#34;: &#34;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&#34;<br>}&#39;<br><br># 결과<br>{<br>    &#34;ok&#34; : true,<br>    &#34;_index&#34; : &#34;log-2012-12-27&#34;,<br>    &#34;_type&#34; : &#34;hadoop&#34;,<br>    &#34;_id&#34; : &#34;1&#34;,<br>    &#34;_version&#34; : 1<br>}\n</code><p></p>\n<p>&lt;예제 9&gt;에서 보는 것처럼 타입을 문서에 포함해 요청할 수 있다.\n</p>\n<p><strong>예제 9 타입을 포함한 쿼리\n</strong></p>\n<p></p>\n<code>curl -XPUT http://localhost:9200/log-2012-12-27/hadoop/1 -d &#39;{<br>    &#34;hadoop&#34; : {<br>        &#34;projectName&#34; : &#34;hadoop&#34;,<br>        &#34;logType&#34;: &#34;hadoop-log&#34;,<br>        &#34;logSource&#34;: &#34;namenode&#34;,<br>        &#34;logTime&#34;:&#34;2012-12-27T02:02:02&#34;,<br>        &#34;host&#34;: &#34;host2 &#34;,<br>        &#34;body&#34;: &#34;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&#34;<br>    }<br>}&#39;\n</code><p></p>\n<p>&lt;예제 10&gt;과 같이 ID 값을 생략하면 자동으로 ID를 생성하고 문서를 만든다. 요청 시 PUT 대신 POST 방식을 사용한 것에 주의하자.\n</p>\n<p><strong>예제 10 ID 없는 문서 생성 쿼리\n</strong></p>\n<p></p>\n<code># 요청<br>curl -XPOST http://localhost:9200/log-2012-12-27/hadoop/ -d &#39;{<br>    &#34;projectName&#34; : &#34;hadoop&#34;,<br>    &#34;logType&#34;: &#34;hadoop-log&#34;,<br>    &#34;logSource&#34;: &#34;namenode&#34;,<br>    &#34;logTime&#34;:&#34;2012-12-27T02:02:02&#34;,<br>    &#34;host&#34;: &#34;host2 &#34;,<br>    &#34;body&#34;: &#34;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&#34;<br>}&#39;<br><br># 결과<br>{<br>    &#34;ok&#34; : true,<br>    &#34;_index&#34; : &#34;log-2012-12-27&#34;,<br>    &#34;_type&#34; : &#34;hadoop&#34;,<br>    &#34;_id&#34; : &#34;kgfrarduRk2bKhzrtR-zhQ&#34;,<br>    &#34;_version&#34; : 1<br>}\n</code><p></p>\n<h3>문서 삭제\n</h3><p>&lt;예제 11&gt;은 문서를 삭제하는 방법을 보여 주고 있다. DELETE 메서드를 사용해 log-2012-12-27 인덱스에서 타입이 hadoop이고 ID가 1인 문서를 삭제한다.\n</p>\n<p><strong>예제 11 문서 삭제 쿼리\n</strong></p>\n<p></p>\n<code># 요청<br>$ curl -XDELETE &#39;http://localhost:9200/log-2012-12-27/hadoop/1&#39;<br><br># 결과<br>{<br>    &#34;ok&#34; : true,<br>    &#34;_index&#34; : &#34;log-2012-12-27&#34;,<br>    &#34;_type&#34; : &#34;hadoop&#34;,<br>    &#34;_id&#34; : &#34;1&#34;,<br>    &#34;found&#34; : true<br>}\n</code><p></p>\n<h3>문서 가져오기\n</h3><p>&lt;예제 12&gt;와 같이 GET 메서드를 사용하면 log-2012-12-27 인덱스에서 타입이 hadoop이고 ID가 1인 문서를 가져올 수 있다.\n</p>\n<p><strong>예제 12 문서를 가져오기 위한 쿼리\n</strong></p>\n<p></p>\n<code>#요청<br>curl -XGET &#39;http://localhost:9200/log-2012-12-27/hadoop/1&#39;<br><br># 결과<br>{<br>    &#34;_index&#34; : &#34;log-2012-12-27&#34;,<br>    &#34;_type&#34; : &#34;hadoop&#34;,<br>    &#34;_id&#34; : &#34;1&#34;, <br>    &#34;_source&#34; : {<br>        &#34;projectName&#34; : &#34;hadoop&#34;,<br>        &#34;logType&#34;: &#34;hadoop-log&#34;,<br>        &#34;logSource&#34;: &#34;namenode&#34;,<br>        &#34;logTime&#34;:&#34;2012-12-27T02:02:02&#34;,<br>        &#34;host&#34;: &#34;host2 &#34;,<br>        &#34;body&#34;: &#34;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&#34;<br>    }<br>}\n</code><p></p>\n<h3>검색\n</h3><p>검색 API를 호출하면 elasticsearch는 검색 API를 실행한 후 질의 내용과 일치하는 검색 결과를 반환한다. &lt;예제 13&gt;에서 검색 API를 사용하는 예제를 볼 수 있다.\n</p>\n<p><strong>예제 13 검색 API 사용 예제 쿼리\n</strong></p>\n<p></p>\n<code># 특정 인덱스의 모든 타입<br>$ curl -XGET &#39;http://localhost:9200/log-2012-12-27/_search?q&#61;host:host2&#39;<br><br># 특정 인덱스의 특정 타입<br>$ curl -XGET &#39;http://localhost:9200/log-2012-12-27/hadoop,apache/_search?q&#61;host:host2&#39;<br><br># 모든 인덱스의 특정 타입<br>$ $ curl - XGET &#39;http://localhost:9200/_all/hadoop/_search?q&#61;host:host2&#39;<br><br># 모든 인덱스와 타입<br>$ curl -XGET &#39;http://localhost:9200/_search?q&#61;host:host2&#39;\n</code><p></p>\n<h3>URI 요청을 사용한 검색 API\n</h3><p>URI를 사용하면 &lt;표 2&gt;의 파라미터와 쿼리 스트링(Query String)으로 간단하게 검색할 수 있다. 모든 검색 옵션을 제공하지는 않으므로 주로 테스트 용도로 간편하게 사용할 때 유용하다.\n</p>\n<p><strong>표 2 주요 파라미터들\n</strong></p>\n<div><table><tbody><tr><td><p><strong>이름</strong></p>\n</td><td><p><strong>설명</strong></p>\n</td></tr><tr><td><p>q</p>\n</td><td><p>쿼리 스트링</p>\n</td></tr><tr><td><p>default_operator</p>\n</td><td><p>기본으로 사용할 연산자(AND 혹은 OR). 기본값은 OR.</p>\n</td></tr><tr><td><p>fields</p>\n</td><td><p>결과로 가져올 필드. 기본값은 &#39;_source&#39; 필드.</p>\n</td></tr><tr><td><p>sort</p>\n</td><td><p>정렬 방법(예: fieldName:asc/fieldName:desc)</p>\n</td></tr><tr><td><p>timeout</p>\n</td><td><p>검색 수행 타임아웃 값. 기본값은 무제한.</p>\n</td></tr><tr><td><p>size</p>\n</td><td><p>결과 값의 개수. 기본값은 10.</p>\n</td></tr></tbody></table></div><p><strong>예제 14 URI 요청을 사용한 검색 쿼리\n</strong></p>\n<p></p>\n<code># 요청<br>$ curl -XGET &#39;http://localhost:9200/log-2012-12-27/hadoop/_search?q&#61;host:host2&#39;<br><br># 결과<br>{<br>    &#34;_shards&#34;:{<br>        &#34;total&#34; : 5,<br>        &#34;successful&#34; : 5,<br>        &#34;failed&#34; : 0<br>    },<br>    &#34;hits&#34;:{<br>        &#34;total&#34; : 1,<br>        &#34;hits&#34; : [<br>            {<br>                &#34;_index&#34; : &#34;log-2012-12-27&#34;,<br>                &#34;_type&#34; : &#34;hadoop&#34;,<br>                &#34;_id&#34; : &#34;1&#34;, <br>                &#34;_source&#34; : {<br>                    &#34;projectName&#34; : &#34;hadoop&#34;,<br>                    &#34;logType&#34;: &#34;hadoop-log&#34;,<br>                    &#34;logSource&#34;: &#34;namenode&#34;,<br>                    &#34;logTime&#34;:&#34;2012-12-27T02:02:02&#34;,<br>                    &#34;host&#34;: &#34;host2&#34;,<br>                    &#34;body&#34;: &#34;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&#34;<br>                }<br>            }<br>        ]<br>    }<br>}\n</code><p></p>\n<h3>요청 바디(Request Body)를 사용한 검색 API\n</h3><p>HTTP 바디를 사용할 경우 Query DSL을 사용해서 검색한다. Query DSL은 내용이 방대하므로 공식 사이트의 가이드 문서(<a href=\"http://www.elasticsearch.org/guide/reference/query-dsl/\">http://www.elasticsearch.org/guide/reference/query-dsl/</a>)를 참고하도록 하자.\n</p>\n<p><strong>예제 15 Query DSL을 사용한 검색\n</strong></p>\n<p></p>\n<code># 요청<br>$ curl -XPOST &#39;http://localhost:9200/log-2012-12-27/hadoop/_search&#39; -d &#39;{<br>    &#34;query&#34; : {<br>        &#34;term&#34; : { &#34;host&#34; : &#34;host2&#34; }<br>    }<br>}<br>&#39;<br><br># 결과<br>{<br>    &#34;_shards&#34;:{<br>        &#34;total&#34; : 5,<br>        &#34;successful&#34; : 5,<br>        &#34;failed&#34; : 0<br>    },<br>    &#34;hits&#34;:{<br>        &#34;total&#34; : 1,<br>        &#34;hits&#34; : [<br>            {<br>                &#34;_index&#34; : &#34;log-2012-12-27&#34;,<br>                &#34;_type&#34; : &#34;hadoop&#34;,<br>                &#34;_id&#34; : &#34;1&#34;,<br>                &#34;_source&#34; : {<br>                    &#34;projectName&#34; : &#34;hadoop&#34;,<br>                    &#34;logType&#34;: &#34;hadoop-log&#34;,<br>                    &#34;logSource&#34;: &#34;namenode&#34;,<br>                    &#34;logTime&#34;:&#34;2012-12-27T02:02:02&#34;,<br>                    &#34;host&#34;: &#34;host2&#34;,<br>                    &#34;body&#34;: &#34;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&#34;<br>                }<br>            }<br>        ]<br>    }<br>}\n</code><p></p>\n<h2>Mapping\n</h2><h3>Put Mapping API\n</h3><p>특정 타입에 매핑을 추가하려면 &lt;예제 16&gt;과 같은 형태로 정의할 수 있다.\n</p>\n<p><strong>예제 16 매핑을 등록하기 위한 쿼리\n</strong></p>\n<p></p>\n<code>$ curl -XPUT &#39;http://localhost:9200/log-2012-12-27/hadoop/_mapping&#39; -d &#39;<br>{<br>    &#34;hadoop&#34; : {<br>        &#34;properties&#34; : {<br>            &#34;projectName&#34; : {&#34;type&#34; : &#34;string&#34;, &#34;index&#34; : &#34;not_analyzed&#34;},<br>            &#34;logType&#34; : {&#34;type&#34; : &#34;string&#34;, &#34;index&#34; : &#34;not_analyzed&#34;},<br>            &#34;logSource&#34; : {&#34;type&#34; : &#34;string&#34;, &#34;index&#34; : &#34;not_analyzed&#34;},<br>            &#34;logTime&#34; : {&#34;type&#34; : &#34;date&#34;},<br>            &#34;host&#34; : {&#34;type&#34; : &#34;string&#34;, &#34;index&#34; : &#34;not_analyzed&#34;},<br>            &#34;body&#34; : {&#34;type&#34; : &#34;string&#34;},<br>        }<br>    }<br>}<br>&#39;\n</code><p></p>\n<h3>Get Mapping API\n</h3><p>정의한 매핑 정보를 얻기 위해서 &lt;예제 17&gt;과 같은 형태의 쿼리를 사용할 수 있다.\n</p>\n<p><strong>예제 17 매핑을 얻어오기 위한 쿼리\n</strong></p>\n<p></p>\n<code>$ curl -XGET &#39;http://localhost:9200/log-2012-12-27/hadoop/_mapping&#39;\n</code><p></p>\n<h3>Delete Mapping API\n</h3><p>&lt;예제 18&gt;은 정의한 매핑을 삭제하는 예다.\n</p>\n<p><strong>예제 18 매핑을 삭제하기 위한 쿼리\n</strong></p>\n<p></p>\n<code>$ curl -XDELETE &#39;http://localhost:9200/log-2012-12-27/hadoop&#39;\n</code><p></p>\n<h2>성능 최적화 팁\n</h2><h3>메모리와 오픈 파일 수\n</h3><p>검색할 데이터가 많아질수록 많은 메모리가 필요하다. elasticsearch를 운영하다 보면 메모리 사용으로 인한 문제를 많이 겪게 된다. elasticsearch 커뮤니티에서 권장하는 운영 방법에 따르면, elasticsearch 전용 서버를 운영할 때는 메모리 용량의 절반만 elasticsearch에 할당하고, 나머지 메모리 용량은 운영체제가 시스템 캐시 목적으로 사용할 수 있도록 하는 것이 좋다. 메모리 크기는 ES_HEAP_SIZE 환경 변수를 설정하거나 JVM의 -Xms와 -Xmx 값을 사용해서 설정할 수 있다.\n</p>\n<p><strong>예제 19 힙 크기를 지정해 실행\n</strong></p>\n<p></p>\n<code>bin/ElasticSearch -Xmx&#61;2G -Xms&#61;2G\n</code><p></p>\n<p>elasticsearch를 사용할 때는 OOME(Out Of Memory Error)가 발생하는 경우가 많다. 필드 캐시가 최대 힙 크기를 넘어서면서 발생하는데, index.cache.field.type 설정을 기본값인 resident 대신 soft로 설정하면 soft 레퍼런스를 활용하므로 캐시 영역에 대해 우선 가비지 컬렉션(Garbage Collection)을 실행해 문제를 해결할 수 있다.\n</p>\n<p><strong>예제 20 필드 캐시 타입 설정\n</strong></p>\n<p></p>\n<code>index.cache.field.type: soft\n</code><p></p>\n<p>데이터가 많아지면 인덱스 파일 개수 또한 증가하게 된다. elasticsearch가 사용하고 있는 Lucene에서 인덱스를 세그먼트 단위로 관리하기 때문이다. 경우에 따라 MAX_OPEN 파일 개수를 넘어서는 일도 발생한다. ulimit 명령으로 최대 오픈 파일 제한을 변경해야 한다. 권장되는 값은 32000~64000이지만, 시스템 규모나 데이터의 양에 따라 더 큰 값으로 설정해야 할 수도 있다.\n</p>\n<h3>인덱스 최적화\n</h3><p>날짜별로 인덱스를 관리하면 &lt;예제 21&gt;에서 보는 것처럼 관리가 필요 없는 오래된 로그를 쉽고 빠르게 삭제할 수 있어서, 문서별로 TTL 값을 설정해 삭제하는 것 보다 시스템에 주는 오버헤드가 적다.\n</p>\n<p><strong>예제 21 인덱스 삭제\n</strong></p>\n<p></p>\n<code>$ curl -XDELETE &#39;http://localhost:9200/log-2012-10-01/&#39;\n</code><p></p>\n<p>인덱스 최적화(Index Optimization)를 수행하면 세그먼트를 병합시킨다. 이러한 방식으로 검색 성능을 향상시킬 수 있다. 다만 시스템에 부담을 주므로 시스템 사용이 적은 시간대에 작업하도록 해야 한다.\n</p>\n<p><strong>예제 22 인덱스 최적화\n</strong></p>\n<p></p>\n<code>$ curl -XPOST &#39;http://localhost:9200/log-2012-10-01/_optimize&#39;\n</code><p></p>\n<h3>샤드와 복제본\n</h3><p>샤드 개수는 초기에 설정한 다음에는 변경이 불가능하므로 현재 시스템의 노드 수와 추후 발생할 수 있는 노드 증가를 고려해 정해야 한다. 예를 들어 현재 5개의 노드가 있고 향후 10개까지 노드를 증가시킬 계획이라면, 초기부터 샤드 수를 10개로 지정하는 것이 좋다. 초기에 5개로 지정하면 이후 노드를 10개로 증가시켜도 샤드는 5개이므로 5개의 노드는 활용할 수 없게 된다. 물론 복제본 수를 1로 지정했다면 추가한 5개 노드를 복제 전용 노드로 활용할 수 있다.\n</p>\n<p>샤드 수를 늘리면 질의가 샤드 개수만큼 분산되므로 많은 데이터 처리에 유리하게 되지만, 너무 크게 설정하면 오히려 트래픽이 증가해 성능이 떨어질 수 있으니 적절하게 설정해야 한다.\n</p>\n<h3>클러스터 토폴로지 구성\n</h3><p>elasticsearch의 설정 파일에는 &lt;예제 23&gt;과 같은 내용을 볼 수 있다. &lt;예제 23&gt;을 보면 세 가지 종류의 노드(데이터 노드, 마스터 노드, 검색 밸런서 노드)가 있음을 알 수 있다.\n</p>\n<ul><li>데이터 노드: 마스터 역할을 수행하지 않고, 데이터만 저장한다. 클라이언트로부터의 요청이 왔을 때 샤드에서 데이터를 검색하거나 인덱스를 생성한다.\n</li><li>마스터 노드: 클러스터를 유지하기 위한 역할을 하고 인덱싱이나 검색 요청을 데이터 노드들에 요청한다.\n</li><li>검색 로드 밸런서 노드: 검색 요청이 오면 노드들에 데이터를 요청 후 취합해 결과를 전달한다. \n</li></ul><p>하나의 노드가 마스터와 데이터 노드 역할을 다 하도록 운영할 수도 있으나, 세 가지 형태의 노드를 각각 사용하면 데이터 노드의 부담을 줄일 수 있다. 또한 마스터 노드를 별도로 구성하면 클러스터의 안정성을 높일 수 있다. 게다가 마스터 노드와 검색 노드는 저사양의 서버 장비를 활용할 수 있도록 해 운영 비용 또한 줄일 수 있다.\n</p>\n<p><strong>예제 23 토폴로지 관련 설정 내용\n</strong></p>\n<p></p>\n<code># You can exploit these settings to design advanced cluster topologies.<br>#<br># 1. You want this node to never become a master node, only to hold data.<br>#    This will be the &#34;workhorse&#34; of your cluster.<br>#<br># node.master: false<br># node.data: true<br>#<br># 2. You want this node to only serve as a master: to not store any data and<br>#    to have free resources. This will be the &#34;coordinator&#34; of your cluster.<br>#<br># node.master: true<br># node.data: false<br>#<br># 3. You want this node to be neither master nor data node, but<br>#    to act as a &#34;search load balancer&#34; (fetching data from nodes,<br>#    aggregating results, etc.)<br>#<br># node.master: false<br># node.data: false\n</code><p></p>\n<h3>라우팅 설정\n</h3><p>인덱싱할 데이터가 많으면 샤드의 수를 늘리는 것이 전체적인 성능을 증가시킬 수 있지만, 샤드의 개수를 증가시키는 만큼 노드 간의 트래픽이 증가한다는 문제점이 있다. 예를 들어 샤드가 100개면 하나의 검색 요청이 왔을 때 100개의 샤드에 모두 요청을 보내 데이터를 취합하는 형식이기 때문에 전체 클러스터에 부담이 된다. 라우팅을 사용하면 특정 샤드에만 데이터가 저장되어 샤드 수가 아무리 커져도 1개의 샤드에만 요청을 보내게 되므로 트래픽을 극적으로 줄일 수 있다. &lt;그림 2&gt;와 &lt;그림 3&gt;, &lt;그림 4&gt;는 Rafal Kuc이 Berlin Buzzwords 2012에서 발표한 자료에서 인용한 것이다. 라우팅을 사용하지 않으면 &lt;그림 2&gt;와 같이 전체 샤드에 모두 요청을 보내지만 라우팅을 사용하면 &lt;그림 3&gt;과 같이 특정 샤드에만 요청을 보내는 것을 볼 수 있다. &lt;그림 4&gt;에서 인용한 자료에 따르면 200개의 샤드에서 라우팅 사용 전과 후의 성능을 비교 했을 때 반응 시간이 10배 이상 차이 나는 것을 볼 수 있다. 라우팅을 적용하면 적용하지 않은 경우외 비교해 스레드 개수가 10~20배 증가하지만 CPU 사용률은 훨씬 적은 것을 볼 수 있다. 하지만 경우에 따라 라우팅을 적용하지 않은 것이 성능이 더 좋을 때도 있다. 여러 샤드로부터 결과가 취합되어야 하는 검색 질의에 대해서는 여러 샤드에 요청이 전달되는 것이 성능상 유리할 수 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 라우팅 사용 전\n</strong></p>\n<p>\n&#9;</p>\n<p><strong>그림 3 라우팅 사용 후\n</strong></p>\n<p>\n&#9;</p>\n<p><strong>그림 4 라우팅 사용 전/후의 성능 비교\n</strong></p>\n<h2>마무리\n</h2><p>elasticsearch는 유용한 기능뿐만 아니라 간단한 설치와 높은 확장성때문에 사용자를 빠르게 늘려가고 있다. 버전 숫자로만 본다면 최근(2013년 1월 기준)에 0.20.4 버전이 나온 정도지만 커뮤니티가 활발하기 때문에 빠르게 기능이 개선되고 있다. 또한 점점 더 많은 회사에서 elasticsearch를 자사의 서비스에 사용하고 있다. 최근에는 개발자인 Shay Banon을 포함한 커미터들이 모여 <a href=\"http://www.elasticsearch.com/\">Elasticsearch.com</a>을 만들어 컨설팅과 교육을 제공하고 있다. 이번 글에서는 기본적인 설치와 사용 방법, 성능 튜닝을 위한 내용을 정리했다. 많은 개발자들에게 도움이 되길 바란다.\n</p>\n<h2>참고 자료\n</h2><ul><li>공식 가이드: <a href=\"http://www.elasticsearch.org/guide/\">http://www.elasticsearch.org/guide/</a>\n&#9;&#9;</li><li>elasticsearch 소개 및 관계형 데이터베이스와 용어 비교: <a href=\"http://www.slideshare.net/clintongormley/cool-bonsai-cool-an-introduction-to-ElasticSearch\">http://www.slideshare.net/clintongormley/cool-bonsai-cool-an-introduction-to-ElasticSearch</a>\n&#9;&#9;</li><li>elasticsearch 소개: <a href=\"http://www.slideshare.net/dadoonet/elasticsearch-devoxx-france-2012-english-version\">http://www.slideshare.net/dadoonet/ElasticSearch-devoxx-france-2012-english-version</a>\n&#9;&#9;</li><li>Shay Banon의 발표 자료: <a href=\"http://2011.berlinbuzzwords.de/sites/2011.berlinbuzzwords.de/files/elasticsearch-bbuzz2011.pdf\">http://2011.berlinbuzzwords.de/sites/2011.berlinbuzzwords.de/files/elasticsearch-bbuzz2011.pdf</a>\n&#9;&#9;</li><li>Using Elasticsearch for logs: <a href=\"http://www.elasticsearch.org/tutorials/2012/05/19/elasticsearch-for-logging.html\">http://www.elasticsearch.org/tutorials/2012/05/19/elasticsearch-for-logging.html</a>\n&#9;&#9;</li><li>Multi-tenancy의 개념: <a href=\"http://en.wikipedia.org/wiki/Multitenancy\">http://en.wikipedia.org/wiki/Multitenancy</a>\n&#9;&#9;</li><li>Shay Banon의 Elasticsearch 최적화: <a href=\"https://github.com/logstash/logstash/wiki/ElasticSearch-Storage-Optimization\">https://github.com/logstash/logstash/wiki/ElasticSearch-Storage-Optimization</a>\n&#9;&#9;</li><li>Rafal Kuc의 성능 튜닝 관련된 Berlin Buzzwords 2012 발표 자료: <a href=\"http://www.elasticsearch.org/videos/2012/06/05/scaling-massive-elasticsearch-clusters.html\">http://www.elasticsearch.org/videos/2012/06/05/scaling-massive-elasticsearch-clusters.html</a>\n&#9;&#9;</li></ul>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 글로벌플래폼개발랩 이재익\n&#9;&#9;글로벌플랫폼개발랩에서 중국개발자들과 로그시스템을 개발하고 있다. 최근 elasticsearch, node.js, iOS 개발에 관심을 가지고 업무에 활용하고 있으며, 여가시간에는 무지함에서 벗어나기위해 독서를 하거나 여행을 하려고 노력 중이다. \n&#9;&#9;<br>\n&#9;&#9;\n</div></div>"},{"name":"[당첨자 발표] hello world 1주년 기념 이벤트","published":1359534541,"description":"<div><p>NHN 개발자 블로그 hello world 1주년  기념 이벤트 당첨자를 발표합니다.</p>\n\n<p> </p>\n\n<p>hello world의 1주년을 기념하는 이벤트에 보내주신 관심과 사랑 감사합니다.</p>\n\n<p>많은 추천 댓글 중에서 가장 뜨거운 열정과 애정을 보여주신 10분을 아래와 같이 선정하였습니다.</p>\n\n<p>당첨되신 분들 모두 축하드립니다.</p>\n\n<p> </p>\n\n<p>- 리얼포스키보드(1): Adrian Jung (facebook)</p>\n\n<p>- 로지텍 트리플파이 이어폰(1): 박종일 (facebook)</p>\n\n<p>- 삼성 SSD 128GB(2):  Won Hur (facebook), Hyuntak Joo (facebook)</p>\n\n<p>- 벨킨백팩(2): Hong SeungGi (facebook), Eunmi  Huh (facebook)</p>\n\n<p>- 레고 테크닉 9393: 도영주 (facebook), HyungSeokPark (twitter)</p>\n\n<p>- 폴프랭크 노트북 파우치: Changyeon Moon (facebook), aliceetw (twitter)</p>\n\n<p> </p>\n\n<p>2013년에도 좋은 컨텐츠를 보여드릴 수 있도록 노력하는 hello world가 되겠습니다.  </p>\n\n<p> </p>\n\n<p><strong>※ 당첨되신 분은 확인해주세요!</strong>  </p>\n\n<p>    ① 당첨되신 분들께서는 2013년 2월 8일 (금)까지</p>\n\n<p>    ② <a href=\"https://event.naver.com/prize_addr/accept1.php\">아래 URL</a>에서 경품수령을 위한 정보제공에 동의하신 후<br>        (<a href=\"https://event.naver.com/prize_addr/accept1.php\">https://event.naver.com/prize_addr/accept1.php</a>) </p>\n\n<p>    ③  본인 확인을 위해 응모하신 SNS 계정으로</p>\n\n<p>    ④ hello world 공식SNS(<a href=\"http://me2day.net/helloworld_nhn\">미투데이</a>, <a href=\"https://twitter.com/#!/helloworld_nhn\">트위터</a>, <a href=\"https://www.facebook.com/pages/Helloworld_nhn/235817773158003\">페이스북</a>)에  네이버 아이디를 쪽지로 남겨주세요.</p>\n<p>        </p></div>"},{"name":"TimingWheel을 이용한 타이머 구현","published":1359106540,"description":"<div><p>NHN Business Platform 웹플랫폼개발랩 최동순</p>\n<p>애플리케이션을 개발할 때 타이머를 사용해야 하는 일이 자주 있습니다. 특히 세션에 대한 타임아웃 처리를 하는 것과 같은 작업에서 말이지요. 일반적인 타이머의 구현은 타임아웃 작업의 등록이나 만료(expire) 여부의 검사 및 처리 시에 시간 복잡도 O(n)을 가집니다. 하지만, 이 글에서 설명할 TimingWheel 자료구조를 사용하면 타임아웃 작업의 만료 여부에 대한 검사가 필요 없는 등록과 실행의 두 작업만을 모두 O(1)의 시간 복잡도로 처리할 수 있는 타이머를 구현할 수 있습니다.\n</p>\n<h2>더 효율적인 타이머에 대한 고민\n</h2><p>애플리케이션을 개발할 때 타이머를 사용해야 하는 경우는 흔하게 발생한다. Java로 개발할 때는 JDK에서 제공하는 java.util.Timer 클래스를 사용해 쉽게 타이머를 구현할 수 있다. 그러나 타이머를 매우 빈번하게 사용해야 한다면 java.util.Timer 클래스로는 좋은 성능을 낼 수 없는 경우가 많다. TimerTask 객체를 추가하고 제거할 때 동기화가 발생하기 때문이다.\n</p>\n<p>2010년에 Comet 기반의 통신 서버 개발 프로젝트를 진행하면서 TimingWheel이라는 자료구조를 적용한 적이 있다. 이 TimingWheel은 타이머 구현 방법의 하나로, 경우에 따라 java.util.Timer 클래스보다 훨씬 더 좋은 성능을 낼 수 있다. 하지만 모든 타이머 요구사항에 TimingWheel을 사용할 수 있는 것은 아니다. 이 글에서는 TimingWheel의 제약 사항에 대해서도 간략하게 언급할 것이다.\n</p>\n<p>TimingWheel은 본래 네트워크 프로토콜 레벨에서 데이터 재전송과 프로토콜 리커버리 등을 처리할 때 필요한 타이머를 구현하기 위한 자료구조지만, 응용하기에 따라 다양한 목적으로 사용할 수도 있다.\n</p>\n<p>TimingWheel의 사용을 고려하게 된 계기는, Comet 기반의 통신 서버를 개발하면서 각 세션(커넥션)마다 ping/pong이나 타임아웃처럼 일정한 시간 간격을 두고 실행돼야 하는 작업을 효율적으로 처리하는 방식에 대한 고민이었다. 당시 요구사항에 따르면, 생성할 수 있는 최대 세션의 개수는 1만 개였는데 각 세션에 대하여 ping/pong, 재연결, 세션 만료 등 다양한 종류의 타임아웃을 지체 없이 처리해야 했기 때문에, java.util.Timer 클래스나 Quartz 등으로는 요구사항을 만족할 수 없었다.\n</p>\n<p>그래서 더 나은 타임아웃 처리를 위해 TimingWheel을 적용했다. TimingWheel은 타이머 처리를 O(1) 시간 복잡도로 처리할 수 있는 자료구조다.\n</p>\n<h2>TimingWheel의 기본 구조와 용어\n</h2><p>TimingWheel의 기본 구조는 &lt;그림 1&gt;에서 보는 것처럼 고정된 크기의 순환 배열(circular array)이다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 TimingWheel 기본 구조(참조한 이미지 출처: <a href=\"http://www.transitmagazine.com/lib0071.html\">http://www.transitmagazine.com/lib0071.html</a>)\n</strong></p>\n<p>배열의 각 버킷을 타임슬롯(time slot)이라고 부르는데, 타임아웃이 발생할 때 처리해야 할 작업에 대한 리스트를 담고 있다. TimingWheel의 기본적인 동작 과정은 슬롯 시간 간격(slot interval)마다 타임슬롯을 순회하면서, 해당 타임슬롯에 담긴 내용을 처리하는 방식으로 이뤄진다.\n</p>\n<p>&lt;그림 2&gt;는 슬롯 시간 간격이 50ms인 상황에서 현재로부터 200ms 이후에 발생할 타임아웃 작업(timeout job)이 등록되는 상황을 설명한 그림이다(time interval이 200ms인 타입아웃 작업 등록).\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 타임아웃 작업 등록 과정(참조한 이미지 출처: <a href=\"http://www.transitmagazine.com/lib0071.html\">http://www.transitmagazine.com/lib0071.html</a>)\n</strong></p>\n<p>슬롯 간격 시간이 50ms이기 때문에, 200ms 이후에 발생할 타이머에 대해서는 현재 커서 위치에서 4칸 이후의 슬롯에 타임아웃 작업을 저장하기만 하면 된다. 저장 시에 별도로 정렬(sorting) 등의 작업이 필요하지 않기 때문에 O(1)으로 처리할 수 있다.\n</p>\n<p>다음으로 등록된 타이머가 만료되어 타임아웃 작업이 처리되는 과정을 살펴보자.\n</p>\n<p>TimingWheel은 50ms마다 슬롯을 순회하기 때문에, 현재 시각 기준으로 200ms 이후에 커서는 자연스럽게 네 칸 뒤의 타임슬롯으로 이동하게 된다. 커서가 이동한 타임슬롯에 저장되어 있는 타임아웃 작업들은 각 작업의 시간 간격(time interval)은 다를지 모르지만 모두 지금 만료되는 작업들이 된다. 즉, 타임슬롯이 가지고 있는 리스트의 타임아웃 작업을 처리하는 로직에서는 타이머 만료 여부에 대한 추가적인 검사 없이 단순히 타임아웃 작업들을 실행시키면 되기 때문에 타임아웃 작업을 저장할 때와 마찬가지로 O(1)이라는 시간 복잡도 안에 처리할 수 있다. 단순한 아이디어지만 타임아웃 작업의 등록 및 실행 시에 만료 여부를 확인하는 로직이 필요 없기 때문에 O(1)이라는 시간 복잡도로 처리할 수 있는 것이다.\n</p>\n<p>타임아웃 작업을 저장할 타임슬롯(targetSlot)은 &lt;예제 1&gt;과 같은 계산 방식으로 얻을 수 있다. 순환 배열이기 때문에 모듈러(%) 연산자가 사용되었고 &lt;그림 2&gt;처럼 최대 타이머 시간(max interval)의 제약 사항이 생기게 된다. TimingWheel을 적용한 프로젝트를 진행할 때도 &lt;예제 1&gt;과 같은 방식으로 TimingWheel을 구현했다.\n</p>\n<p><strong>예제 1 targetSlot 계산 방식\n</strong></p>\n<p></p>\n<code>targetSlot &#61; ( currentSlot &#43; (timeInterval / slotInterval)) % timeSlotCount\n</code><p></p>\n<p>&lt;그림 3&gt;은 순환 배열을 좀더 직관적으로 표현한 것이다. 실제 프로젝트에서 TimingWheel을 구현할 때는 타임아웃 작업 처리에 소요되는 시간이 TimingWheel의 커서(cursor) 동작에 끼치는 영향을 최소화하기 위해 타임아웃 작업을 처리하는 스레드는 별도의 스레드 풀에서 동작할 수 있도록 했다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 3 Simple TimingWheel의 동작 방식\n</strong></p>\n<p>하지만 타이머가 필요한 모든 경우에 TimingWheel을 사용할 수 있는 것은 아니다. &lt;그림 2&gt;에서 보는 것처럼 TimingWheel에는 최대 타이머 시간에 대한 제한이 있다. &lt;그림 2&gt; 처럼 타임슬롯의 개수가 7개고, 주기가 50ms일 때는 350ms를 넘어서는 값을 등록할 수 없다.\n</p>\n<p>만약 슬롯 시간 간격이 1초일 때는, 1시간 23분 15초 주기의 시간 간격을 오버플로(overflow) 없이 처리하려면 4,995개(60x60 &#43; 23x60 &#43; 15)의 타임슬롯이 필요해 많은 메모리를 사용하게 된다. 이 부분에 대해서 좀 더 정확히 말하면 슬롯 시간 간격이 작을수록 정밀한 처리가 가능하고 타임슬롯의 개수가 클수록 큰 주기의 작업을 처리할 수 있게 되는데, 이 두 경우를 하나의 TimingWheel에서 처리하면 메모리 낭비가 심해진다는 말이다. 만약 O(1)의 시간 복잡도가 중요한 요소이고 앞의 두 경우를 모두 만족해야 하는 경우에는 슬롯 시간 간격과 주기에 따라 여러 개의 TimingWheel을 사용하면 될 것이다. O(1) 시간 복잡도가 그리 중요한 요소가 아니고 여러 개의 TimingWheel을 유지하는 것이 번거롭다면 Hashed TimingWheel이나 Hierarchical TimingWheel의 사용을 고려해 볼 수도 있다. 그러나 모든 타이머 요구사항에 TimingWheel을 사용할 수 있는 것은 아니므로, 적합한지 여부를 판단한 후 TimingWheel을 구현하는 것이 좋을 것이다.\n</p>\n<h2>TimingWheel 적용 효과\n</h2><p>2010년 진행한 Comet 프로젝트 이외에도 구현한 TimingWheel을 다른 프로젝트에 적용해 본 경험이 두 번 있다.\n</p>\n<p>첫 번째로, 타임아웃 작업의 처리 로직이 O(n) 시간 복잡도를 가지고 있어서, 평상시에는 CPU 사용률이 1~2%이지만 타임아웃 작업을 처리할 때에는 CPU 사용률이 100%에 이르는 문제가 있던 프로젝트에 적용했다. 처음 방식은 매번 타임아웃 검사 시마다 등록된 타임아웃 작업 전체에 대해서 만료 여부를 검사하고 만료된 것들만 실행시키는 방식이었다. 그래서 한 번에 검사 및 처리해야 하는 타임아웃 작업이 너무 많아 높은 CPU 사용률이 발생했다. TimingWheel을 적용함으로써 타임아웃 작업들이 타임슬롯 전체에 고르게 분산되어 타임아웃 작업의 처리 시에도 안정적인 CPU 사용률을 보일수 있었다.\n</p>\n<p>두 번째로, HTML5 기반 게임 개발에도 적용한 사례가 있다. 브라우저의 JavaScript는 싱글 스레드 기반에서 동작하기 때문에 HTML5 게임 개발 시에 타이머를 너무 많이 사용하면 서로 영향을 주어 시간 지연이 발생되게 되고 전체적인 게임 렌더링 성능이 떨어지게 된다. 또한 게임 개발 시에 사용하는 HTML5 게임 엔진들은 &lt;그림 4&gt;처럼 프레임(frame) 기반으로 동작하는 방식을 제공하는데, 이런 방식을 애니메이션 효과 이외의 부분에서 타이머의 용도로 사용하면 필요 이상의 리소스를 사용하게 되어 역시 게임 렌더링 성능이 떨어지게 된다(&lt;그림 4&gt; 참고).\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 4 HTML5 게임 엔진의 frame 처리 방식\n</strong></p>\n<p>&lt;그림 5&gt;의 C처럼 1분 주기로 동작하는 타이머의 경우, OnAction을 사용하면 3,599번의 불필요한 호출이 일어난다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 5 불필요한 리소스 낭비의 예\n</strong></p>\n<p>이런 문제점을 해결하기 위해서 TimingWheel을 적용했다. 단 한 개의 TimingWheel 타이머만으로도 요구사항을 충분히 만족시킬 수 있었으며, 전체적으로 일정하게 안정된 프레임 수(fps)를 유지할 수 있었다.\n</p>\n<h2>마치며\n</h2><p>지금까지 TimingWheel을 활용한 타임아웃 작업의 등록과 처리 과정에 대해서 간단히 살펴보았다. \n</p>\n<p>간단한 아이디어로 타이머의 만료 여부를 확인할 필요가 없기 때문에 타임아웃 작업의 등록과 처리를 O(1)에 처리할 수 있는 장점이 있었고, 경우에 따라 메모리가 많이 낭비되는 단점도 있었다. \n</p>\n<p>실제 서비스에 적용하는 과정에서는 좀 더 세밀한 부분에 대한 고민이 필요하다. 타임슬롯이 가지고 있는 리스트라는 자료 구조의 특성상 메모리릭(memory leak)이 발생할 가능성이라든지, 등록되는 작업의 처리에 시간이 오래 걸리는 경우는 지연 시의 대책에 대한 고민도 필요하다.\n</p>\n<p>스로틀 밸브(Throttle valve) 성격의 옵션을 잘 활용하여 위의 문제점들을 해결한다면 요즘과 같은 대용량 처리가 필요한 환경에서 TimingWheel은 좋은 선택일 것이다.\n</p>\n<h2>참고 자료\n</h2><ul><li>Implement lower timer granularity for retransmission of TCP: <a href=\"http://www.ibm.com/developerworks/aix/library/au-lowertime/index.html\">http://www.ibm.com/developerworks/aix/library/au-lowertime/index.html</a>\n&#9;&#9;</li><li>Hashed and hierarchical timing wheels: efficient data structures for implementing a timer facility: <a href=\"http://dl.acm.org/citation.cfm?id&#61;270876\">http://dl.acm.org/citation.cfm?id&#61;270876</a>\n&#9;&#9;</li><li>Hashed and Hierarchical Timing Wheels: <a href=\"http://ebookbrowse.com/timingwheels-ppt-d195376642\">http://ebookbrowse.com/timingwheels-ppt-d195376642</a>\n&#9;&#9;</li><li>Real-Time Concepts for Embedded Systems - 11.4 Timer Interrupt Service Routines: <a href=\"http://www.transitmagazine.com/lib0069.html\">http://www.transitmagazine.com/lib0069.html</a>\n</li></ul>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 웹플랫폼개발랩 최동순\n&#9;&#9;알려지지 않은 무언가를 추적해서 알려진 것이 나오면 고통이 줄어들고, 마음이 진정되며, 힘을 얻었다는 느낌이 든다. -니체\n&#9;&#9;<br>\n&#9;&#9;<br>\n&#9;&#9;\n</div></div>"},{"name":"어떤 분산 파일 시스템을 사용해야 하는가?","published":1358404425,"description":"<div><p>NHN Business Platform 클라우드플랫폼개발랩 전성원</p>\n<p>우리는 하나의 데이터를 여러 서버가 공유할 때 분산 파일 시스템을 사용합니다. 최근에는 NFS나 CIFS와 같은 분산 파일 시스템 이외에도 비용이나 성능면 에서 경쟁력이 있는 많은 분산 파일 시스템을 쉽게 접할 수 있습니다. NHN에서도 NFS, CIFS 이외에 OwFS나 HDFS를 사용하고 있습니다. 그러나 각 분산 파일 시스템별로 장단점이나 특징이 있기 때문에 이를 잘 고려하여 선택한다면 좀 더 경쟁력 있는 인터넷 서비스를 만들 수 있을 것입니다. 이 글에서는 여러 분산 파일 시스템의 특징을 알아보고, 사례별로 적합한 분산 파일 시스템을 제시합니다.\n</p>\n<h2>어떤 분산 파일 시스템을 사용해야 하는가?\n</h2><p>현재 NHN에서 사용하고 있는 분산 파일 시스템(Distributed File System)으로는 NFS(Network File System)와 CIFS(Common Internet File System), HDFS(Hadoop Distributed File System), OwFS(Owner-based File System)가 있다.\n</p>\n<p>분산 파일 시스템이란 네트워크를 이용해 접근하는 파일 시스템을 말한다. 이러한 분산 파일 시스템의 장점은 여러 호스트에서 저장된 정보를 공유할 수 있다는 것이다. 2008년 이전 NHN에서는 NAS(Network Attached Storage)를 이용한 NFS와 CIFS만 이용했지만, 2008년 이후 자체 개발한 OwFS를 사용하기 시작하면서 OwFS의 이용량이 많아졌다. HDFS는 널리 알려졌다시피 Google의 GFS(Google File System)에 영향을 받아 만들어진 오픈소스 파일 시스템이다.\n</p>\n<p>NFS나 CIFS를 사용할 때는 보통 고가의 스토리지 시스템인 NAS를 사용한다. 그렇기 때문에 용량을 증가시킬 때마다 높은 인프라 비용이 발생한다는 단점이 있다. 반면 OwFS와 HDFS는 상대적으로 저 비용의 하드웨어(commodity server)를 사용할 수 있게 만들어졌기 때문에 훨씬 더 낮은 비용으로 고용량 저장소를 구축할 수 있다.\n</p>\n<p>그러나 모든 경우에 OwFS나 HDFS가 NAS를 사용하는 것이 NFS나 CIFS를 사용하는 것보다 유리한 것은 아니다. 목적에 따라서는 NAS를 사용해야 하는 경우도 있다. OwFS와 HDFS 또한 마찬가지다. 서로 다른 목적으로 만들어졌기 때문에 구현하려는 인터넷 서비스의 목적에 따라 적합한 파일 시스템을 선택할 필요가 있다.\n</p>\n<p>그래서 이 글에서는 NHN에서 사용하는 대표적인 분산 파일 시스템의 특징을 설명하고, 어떤 분산 파일 시스템을 사용하는 것이 적합할지 설명하려 한다.\n</p>\n<p>추가로 아직 NHN에서는 사용하고 있지 않지만, 최근 등장한 오픈소스 분산 파일 시스템과 Google에서 사용하고 있는 분산 파일 시스템, 그리고 전반적인 분산 파일 시스템의 발전 동향도 소개하겠다.\n</p>\n<h2>NFS와 CIFS \n</h2><p>일반적으로 NFS(Network File System)는 Linux/Unix 환경에서, CIFS는 Micsrosoft Windows 환경에서 사용한다.\n</p>\n<p>NFS는 1984년에 Sun Microsystems에서 개발한 분산 파일 시스템으로, 네트워크를 통하여 다른 호스트에 있는 파일을 공유해 사용할 수 있도록 한 것이다. NFS에는 여러 버전이 있는데, NFSv2부터 널리 사용되기 시작했고 현재 주류를 이루는 것은 NFSv3이다. 성능과 보안을 개선한 NFSv4가 2003년에 나왔으며, 2010년에는 클러스터 기반으로 확장할 수 있는 NFSv4.1이 발표되었다. NFS는 매우 오랜 역사를 지니고 있을 뿐 아니라, 현재까지도 지속적으로 발전하고 있는 분산 파일 시스템이라고 할 수 있겠다.\n</p>\n<p>CIFS는 IBM에서 개발한 SMB(Server Message Block)를 바탕으로 보안 등의 기능을 개선해 Microsoft가 Windows에 적용한 분산 파일 시스템이다.\n</p>\n<p>NFS와 CIFS는 POSIX 표준을 준수한다. 그렇기 때문에 NFS나 CIFS를 사용하는 애플리케이션은 로컬 파일 시스템처럼 분산 파일 시스템을 사용할 수 있다. 즉 애플리케이션을 구현하거나 가동할 때 로컬 파일 시스템과 분산 파일 시스템을 구별해 작성할 필요가 없다는 것이다.\n</p>\n<p>많은 경우 NFS나 CIFS를 사용할 때는 성능과 가용성을 위해 NAS(Network Attached Storage)를 사용한다. NAS 자체에는 고유의 파일 시스템이 있고, NAS 게이트웨이가 NFS나 CIFS 프로토콜을 지원하도록 해 원격에서의 파일 접근 요청을 처리하도록 하고 있다. \n</p>\n<p>일반적으로 NAS는 &lt;그림 1&gt;과 같은 구조를 가진다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 일반적인 NAS의 구조\n</strong></p>\n<p>NFS나 CIFS의 특징은 다음과 같이 정리해 볼 수 있다.\n</p>\n<ul><li>로컬 파일 시스템과 동일한 기능 제공\n</li><li>NAS를 사용하는 경우가 많기 때문에 NAS에 대한 높은 구매 비용 필요\n</li><li>NAS는 OwFS와 HDFS에 비하여 확장성이 크게 떨어짐\n</li></ul><h2>OwFS(Owner-based File System)\n</h2><p>OwFS는 NHN이 자체적으로 개발한 분산 파일 시스템으로, 현재 NHN에서 사용하는 분산 파일 시스템 중 가장 많이 사용하는 시스템이다.\n</p>\n<p>OwFS는 Owner라고 하는 컨테이너 개념을 가지고 있는 것이 특징이다. Owner란 OwFS 내부에서 관리하는 메타데이터의 기본 단위다. OwFS에서는 이 Owner를 기반으로 데이터의 복제본을 관리한다. 각각의 Owner는 독립적인 파일 저장 공간을 가지고 있으며, 그 공간 안에 파일과 디렉터리를 저장할 수 있다. OwFS는 이 Owner들을 모아 하나의 커다란 파일 시스템을 구성하는 것이다. 사용자가 파일에 접근하기 위해서는 먼저 이 Owner에 대한 정보를 얻어야 한다.\n</p>\n<p>OwFS의 전체적인 구조는 다음과 같다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 OwFS 구조\n</strong></p>\n<p>OwFS의 Meta-Data Server(MDS)는 Data Server(DS)들의 상태를 관리한다. 구체적으로 MDS는 각 DS의 용량을 관리하고 장애가 발생했을 때 Owner들의 복제본을 이용해 복구 작업을 실행한다.\n</p>\n<p>OwFS를 HDFS에 비교했을 때 장점은 많은 수의 파일을 효율적으로 처리할 수 있다는 것이다(주로 파일 하나가 수십 메가바이트 이내일 때). 왜냐하면 파일 개수가 많아지더라도 MDS의 부담이 커지지 않도록 설계했기 때문이다. Owner 내에 저장된 파일과 디렉터리에 대한 정보(즉, 파일과 디렉터리에 대한 메타데이터)는 DS가 직접 관리하고, MDS는 오직 Owner에 대한 정보와 해당 Owner에 대한 복제본의 위치 정보만 가지도록 하고 있다. 그렇기 때문에 파일 개수가 많아져도 MDS가 처리해야 하는 메타데이터가 증가하지 않고 MDS의 부담이 그리 커지지 않게 된다.\n</p>\n<p>OwFS의 특징은 다음과 같이 정리해 볼 수 있다.\n</p>\n<ul><li>Owner라는 컨테이너 개념. Owner는 하나의 파일 시스템이며 Owner가 모여 전체 파일 시스템을 이룬다.\n</li><li>DS에 Owner 정보(파일 데이터와 메타데이터)를 저장\n</li><li>하나의 DS에 여러 Owner를 저장할 수 있고, Owner는 서로 다른 DS에 분산 저장(복제)돼 있음\n</li><li>복제본 위치를 포함한 Owner에 대한 위치 정보는 MDS(Metadata Data Server)에 저장\n</li><li>수십 메가바이트 이내의 많은 수의 파일을 처리하기에 적합함\n</li><li>모든 구성 요소가 이중화, 삼중화돼 있어 장애가 발생해도 안정적으로 동작함\n</li></ul><p>OwFS는 자체적인 고유의 인터페이스(API)를 제공하고 있다. 그러나 OwFs_Fuse 모듈 또한 제공하기 때문에 NAS처럼 OwFS를 마운트해 로컬 디스크처럼 사용할 수도 있다. 또한 Apache 웹 서버에서 OwFS에 저장된 파일에 접근할 수 있도록 Apache 모듈도 제공하고 있다.\n</p>\n<h2>HDFS(Hadoop Distributed File System)\n</h2><p>Google은 웹 페이지 정보를 크롤링해 저장할 수 있는 고유의 분산 파일 시스템인 GFS(Google File System)를 만들었다. Google은 2003년 이 GFS에 대한 정보를 논문으로 발표했고, HDFS는 GFS를 모델로 해서 만들어진 오픈소스다.\n</p>\n<p>그렇기 때문에 HDFS는 GFS와 동일한 특징을 가진다. HDFS는 대용량의 파일을 청크(chunk)라는 단위로 분할해 데이터노드(Datanode)에 3개씩 분산 저장한다. 즉 하나의 파일이 분산된 여러 데이터노드에 저장되는 것이다. 하나의 파일에 대한 복제본이 3개씩 있고, 이 청크의 크기 단위는 보통 64MB다.\n</p>\n<p>이 청크가 어느 데이터노드에 저장되었는지에 대한 메타데이터는 네임노드(Namenode)에 저장한다. 그리고 MapReduce 프레임워크를 이용해 분산 저장된 파일을 읽어 연산할 수 있도록 했다.\n</p>\n<p>HDFS의 구성은 &lt;그림 3&gt;에서 볼 수 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 3 HDFS 구조(원본 출처: <a href=\"http://hadoop.apache.org/docs/hdfs/current/hdfs_design.html\">http://hadoop.apache.org/docs/hdfs/current/hdfs_design.html</a>)\n</strong></p>\n<p>HDFS의 네임노드는 모든 파일의 네임스페이스와 메타데이터, 파일의 청크 정보를 관리한다. 청크는 데이터노드에 저장하고, 이 데이터노드가 클라이언트로부터 오는 파일 연산 요청을 처리한다.\n</p>\n<p>앞서 설명한 바와 같이 HDFS에서는 대용량 파일을 효과적으로 분산 저장할 수 있다. 그뿐만 아니라 청크 위치 정보를 기반으로 MapReduce 프레임워크를 이용해 연산마저 분산 처리할 수 있다. \n</p>\n<p>OwFS에 비교해서 HDFS의 취약점은 많은 개수의 파일을 처리하기 적합하지 않다는 것이다. 왜냐하면 네임노드에 병목 현상이 발생하기 때문이다. 파일의 개수가 많아지면 네임노드의 서비스 데몬에 OOM(Out of Memory)이 발생하여 데몬 프로세스가 종료되는 문제가 생긴다.\n</p>\n<p>HDFS의 특징은 다음과 같이 정리해 볼 수 있다.\n</p>\n<ul><li>크기가 큰 파일이 청크 단위로 나뉘어 여러 데이터노드에 분산 복제 저장됨\n</li><li>청크 크기는 보통 64MB이고, 각각의 청크는 3개의 복제본이 존재하며, 서로 다른 데이터 노드에 청크가 저장됨\n</li><li>이 청크들에 대한 정보는 네임노드에 저장돼 있음\n</li><li>대용량의 파일을 저장하는 데 유리하며, 파일의 개수가 많으면 네임노드의 부담이 커짐\n</li><li>네임노드가 SPOF(Single Point Of Failure). 네임노드에 장애가 발생하면 운영 불가 상황이 발생하며 수동 복구 필요\n</li></ul><p>HDFS는 Java로 작성돼 있기 때문에 제공하는 인터페이스(API)도 Java API다. 그러나 JNI(Nava Native Interface)를 이용한 C API도 사용할 수 있다. Hadoop 커뮤니티는 공식적으로 FUSE를 이용한 마운트를 제공하고 있지는 않다. 그러나 서드 파티에서 HDFS에 대한 FUSE 마운트 기능을 제공하고 있다.\n</p>\n<p>HDFS를 이용할 때 가장 주의할 사항은 네임노드에 대한 장애 대비다. 네임노드에 장애가 발생하면 HDFS 자체를 이용할 수 없기 때문에 장애 발생 시간에 대한 고려가 필요하다.\n</p>\n<p><strong>표 1 OwFS와 HDFS비교\n</strong></p>\n<div><table><tbody><tr><td> </td><td><p><strong>OwFS</strong></p>\n</td><td><p><strong>HDFS</strong></p>\n</td></tr><tr><td><p>메타데이터 서버 이중화</p>\n</td><td><p>기본 지원</p>\n</td><td><p>아직 지원하지 않음</p>\n</td></tr><tr><td><p>관리 대상 메타데이터</p>\n</td><td><p>Owner 할당 정보</p>\n</td><td><p>파일 네임스페이스(File name space), 파일 정보(stat 정보), 청크 정보 및 청크 할당 정보</p>\n</td></tr><tr><td><p>파일 저장 방식</p>\n</td><td><p>그대로 저장</p>\n</td><td><p>청크 단위로 나누어 저장</p>\n</td></tr><tr><td><p>장점</p>\n</td><td><p>다수의 파일 저장에 유리</p>\n</td><td><p>큰 파일 저장에 유리</p>\n</td></tr></tbody></table></div><h2><strong>사례로 보는 알아보는 분산 스토리지 선택\n</strong></h2><h3><strong>사례 1\n</strong></h3><p>사용하는 파일의 크기가 그리 크지 않고(보통 수십MB 이내), 파일의 개수는 매우 많아질 가능성이 있다. 전체적으로 약 10~100TB 정도의 용량이 필요할 것으로 예상한다. 그리고 한 번 저장된 파일이 변경되는 경우는 거의 없다.\n</p>\n<p></p>\n<h4>분산 스토리지 선택\n</h4><p></p>\n<p>OwFS가 적합하다. 일단 파일의 크기가 크지 않고 그 수가 많아질 가능성이 높기 때문에 HDFS보다는 OwFS가 유리한 것이다. 파일 내용에 대한 변경이 없으며 전체적으로 필요한 용량도 수십TB 이상 되므로 NAS를 사용하는 것보다 비용 면에서 유리하다.\n</p>\n<h3>사례 2\n</h3><p>웹 서버에서 생성되는 로그 파일을 저장하고 주기적으로 그 내용을 분석해야 한다. 로그 파일의 크기는 평균 1TB 정도며, 하루에 10개 정도 생성되고 유지 기간은 1개월이다.\n</p>\n<p></p>\n<h4>분산 스토리지 선택\n</h4><p></p>\n<p>HDFS가 적합하다. 일단 파일의 크기가 크고, 개수가 그리 많지 않기 때문이다. 이런 대용량 파일을 분석할 때에는 HDFS를 사용하는 것이 좋다. 그러나 HDFS에서는 한 번 저장된 파일을 변경할 수 없다. 그렇기 때문에 하나의 로그 파일이 완전히 생성된 다음에 해당 파일을 HDFS에 저장해야 한다.\n</p>\n<h3>사례 3\n</h3><p>웹 서버에서 생성되는 로그 파일을 저장하고 주기적으로 그 내용을 분석해야 한다. 로그 파일은 하루에 1개가 서버별로 따로 생성되며, 그 크기는 평균 100KB 정도다. 현재 로그를 수집해야 하는 서버는 10,000여 대이며 유지 기간은 100일이다.\n</p>\n<p></p>\n<h4>분산 스토리지 선택\n</h4><p></p>\n<p>OwFS를 사용하는 것이 좋다. 100일간 유지해야 하기 때문에 파일 개수가 많아질 수 밖에 없고 로그 파일의 크기가 그리 크지 않기 때문이다. 분석 작업은 MapReduce 프레임워크로 할 수 있다. MFO(MapReduce Framework for OwFS)를 이용하면 OwFS에서도 MapReduce 프레임워크를 사용할 수 있다.\n</p>\n<h3>사례 4\n</h3><p>각 사용자들은 여러 파일을 가질 수 있고, 이 사용자들이 자신이 가지고 있는 파일을 빠르게 검색할 수 있도록 파일 정보에 대한 인덱스를 구축하려 하는데, 이 인덱스 파일을 저장할 수 있는 스토리지가 필요하다. 파일이 추가되거나 삭제 또는 변경될 때 인덱스 파일이 수정돼야 한다.\n</p>\n<p>파일 개수가 많지 않은 경우 인덱스 파일의 크기는 작지만, 파일 개수가 많은 경우 인덱스 파일은 수백MB 이상으로 커질 수 있다. 전체 사용자 수는 약 10만 명 정도로 예상한다.\n</p>\n<p></p>\n<h4>분산 스토리지 선택\n</h4><p></p>\n<p>NAS를 쓰는 것이 유리하다. 일반적으로 인덱스 파일은 자주 변경돼야 하는데, OwFS나 HDFS에서는 한 번 저장된 파일은 변경할 수 없기 때문이다.\n</p>\n<p>OwFS의 경우 풀 모드(full mode)로 OwFS_FUSE를 사용하면 파일 변경 작업을 할 수 있다. 그러나 이 방식은 전체 파일을 읽어 파일을 변경하여 다시 쓰기를 하는 방식이다. 전체 파일에서 단 1바이트만 변경하더라도 말이다. 또한 전체 용량도 수십TB 정도라면 NAS를 이용한다 해도 많은 비용이 발생하지 않는다.\n</p>\n<h3>사례 5\n</h3><p>약 1KB 크기의 파일이 1,000,000개 이상 된다. 전체적으로 필요한 용량은 3GB 정도다. 그리고 기존에 사용하던 디렉터리 구조를 바꾸기는 어렵다.\n</p>\n<p></p>\n<h4>분산 스토리지 선택\n</h4><p></p>\n<p>NAS를 쓰는 것이 유리하다. OwFS_FUSE를 이용하면 로컬 파일 시스템만큼 유연한 디렉터리 구조를 사용할 수 있지만, 작은 파일이 많을 때는 NAS에 비해 성능이 떨어지는 경우도 있다. HDFS 또한 FUSE를 이용하여 HDFS를 마운트할 수 있지만, 많은 개수의 파일을 사용하는 데 적합하지 않다. 또한 필요한 전체 용량이 워낙 작기 때문에 NAS를 사용해도 운영 비용상의 문제가 발생하지 않는다.\n</p>\n<h3>사례 6\n</h3><p>파일의 크기가 수 MB에서 수 GB 정도며 전체적으로 필요한 용량은 500TB 정도다. 디렉터리 구조는 바꾸지 않았으면 좋겠고, 파일의 내용 변경은 가끔 있을 수 있다.\n</p>\n<p></p>\n<h4>분산 스토리지 선택\n</h4><p></p>\n<p>OwFS를 사용하는 것이 좋다. 500TB 정도의 대용량이 필요하다면 NAS는 비용상 적합하지 않다. 그리고 500TB 정도의 용량이라면 그만큼 파일의 개수 또한 많다는 것을 의미한다. 그러므로 HDFS보다는 OwFS가 유리하다. OwFS_FUSE를 이용해 사용하던 디렉터리 구조 그대로 사용할 수도 있겠지만, 성능을 위해서는 가급적 Owner가 잘 처리할 수 있는 디렉터리 구조 형태로 변경하는 것이 좋다. 파일의 내용을 변경할 때는, 애플리케이션 서버에서 파일을 읽어 변경한 후 애플리케이션 서버에서 OwFS에 덮어 쓰도록 하면 전체 시스템 부하가 커지지 않도록 할 수 있다.\n</p>\n<h3>분산 스토리지 선택 기준\n</h3><p>사례별로 살펴 본 분산 스토리지 선택 기준을 다시 정리해 보면 다음 표와 같다.\n</p>\n<p><strong>표 2 OwFS, HDFS, NFS/CIFS 선택 기준\n</strong></p>\n<div><table><tbody><tr><td> </td><td><p><strong>OwFS</strong></p>\n</td><td><p><strong>HDFS</strong></p>\n</td><td><p><strong>NFS/CIFS</strong></p>\n</td></tr><tr><td><p>파일 크기</p>\n</td><td><ul><li>수십 MB 이내의 작은 파일이 많을 때 유리\n</li><li>수십 GB 이내의 중간 정도 크기의 파일이 많을 때 유리</li></ul></td><td><p>10GB 이상 큰 크기의 파일이 많을 때 유리</p>\n</td><td><p>작거나 중간 정도 크기의 파일이 있을 때 유리</p>\n</td></tr><tr><td><p>파일 개수</p>\n</td><td><p>많을 때</p>\n</td><td><p>적을 때</p>\n</td><td><p>많을 때</p>\n</td></tr><tr><td><p>TCO(Total Cost of Ownership)</p>\n</td><td><p>낮음</p>\n</td><td><p>낮음</p>\n</td><td><p>높음</p>\n</td></tr><tr><td><p>분석 기능</p>\n</td><td><p>O</p>\n</td><td><p>O</p>\n</td><td><p>X</p>\n</td></tr><tr><td><p>선택 기준</p>\n</td><td><ul><li>파일이 크지 않은 경우\n</li><li>파일이 많은 경우\n</li><li>분석이 필요한 경우</li></ul></td><td><ul><li>파일이 큰 경우\n</li><li>파일이 많지 않은 경우\n</li><li>용량이 큰 경우\n</li><li>분석이 필요한 경우</li></ul></td><td><ul><li>용량이 작은 경우\n</li><li>기존에 NAS를 사용하고 있고, 호환성이 꼭 필요한 경우</li></ul></td></tr></tbody></table></div><h2><strong>주목할 만한 분산 파일 시스템들\n</strong></h2><p>NHN에서는 사용하고 있지 않지만 주목할 만한 분산 파일 시스템을 소개하겠다. 여기서 소개할 분산 파일 시스템은 GFS2, Swift, Ceph 그리고 pNFS다. 이들을 간략하게 소개하고 그 특징을 설명하겠다.\n</p>\n<h3>GFS2\n</h3><p>분산 파일 시스템 분야에서 Google의 GFS는 음악계의 서태지와 아이들이나 비틀즈와 같다. HDFS를 비롯해 많은 분산 파일 시스템이 GFS에 영향을 받아 만들어졌기 때문이다.\n</p>\n<p>그러나 이 GFS에도 커다란 구조적인 단점이 있는데, 바로 네임노드의 장애 취약성이다. GFS는 HDFS와 달리 슬레이브 네임노드가 있다. 그래서 GFS는 HDFS에 비해 장애에 덜 취약하다. 그러나 슬레이브 네임노드가 있더라도 마스터 네임노드에 장애가 발생했을 때 절체 시간이 짧지 않다.\n</p>\n<p>그리고 파일 개수가 많아지면 메타데이터의 양 또한 많아지게 돼, 처리 속도가 저하될 뿐만 아니라 마스터 서버의 메모리 크기 제한 때문에 사용할 수 있는 전체 파일 개수에 제한이 발생한다는 문제 또한 있다.\n</p>\n<p>청크 크기가 보통 64MB인데 이보다 작은 데이터를 저장하는 데 너무 비효율적이다. 물론 청크 크기를 줄일 수 있지만 청크 크기를 줄이면 그만큼 많은 메타데이터가 생성되기 때문에 64MB보다 작은 크기의 파일이 많다고 하더라도 청크 크기를 줄이기 어려운 문제가 있었다.\n</p>\n<p>GFS2는 이러한 GFS의 단점을 극복한 것이다. GFS2는 GFS보다 훨씬 더 발전된 메타데이터 관리 방법을 사용한다. GFS2의 네임노드는 싱글 마스터가 아니라 분산 구조를 따르고 있다. 그리고 메타데이터는 수정이 가능한 BigTable과 같은 데이터베이스에 저장한다. 이러한 방법으로 파일 개수의 제한이나 네임노드 장애 취약성을 개선했다.\n</p>\n<p>처리할 수 있는 메타데이터의 양을 손쉽게 늘릴 수 있게 되다 보니 청크 크기를 1MB로 줄일 수 있다고 한다. 이 GFS2의 구조는 현재 대부분의 분산 파일 시스템이 가지고 있는 구조를 개선하는 방향에 많은 영향을 줄 것으로 보인다.\n</p>\n<h3>Swift\n</h3><p>Swift는 OpenStack에서 사용하는 분산 객체 저장소(Object Storage)로 Rackspace Cloud 등에서 이용하고 있다. Swift는 Amazon S3와 같이 마스터 서버를 따로 두지 않는 구조를 사용하는 것이 특징이다. 파일을 관리하기 위해 Account, Container, Object라는 3단계 객체 구조를 사용하고 있다. Account 객체는 계정과 같은 개념으로 Container 객체를 관리하는 객체다. Container 객체는 디렉터리와 같이 Object 객체를 관리는 객체로 Amazon S3의 bucket과 같은 것이다. Object 객체는 파일에 해당하는 객체로 이 Object 객체에 접근하려면 Account 객체와 Container 객체에 차례로 접근해야 한다. Swift는 REST API를 제공하며 이 REST API 제공을 위해 프락시 서버를 따로 두고 있다. 원하는 객체가 할당된 위치를 결정할 때 미리 정한 정적 테이블을 이용하는데, 이것을 Ring이라고 한다. Swift 내의 모든 서버들은 이 Ring 정보를 공유하고 원하는 객체의 위치를 찾아가게 된다.\n</p>\n<p>Swift는 최근 OpenStack의 빠를 발전과 많은 대형 회사들의 참여로 점점 많은 주목을 받고 있다. 국내에서도 kt가 OpenStack에 참여하고 있으며 kt ucloud를 Swift를 이용해 서비스하고 있다.\n</p>\n<h3>Ceph\n</h3><p>Ceph는 분산 파일 시스템으로 메타데이터를 관하는 방식이 독특하다. 메타데이터 서버를 이용해 전체 파일 시스템의 네임스페이스와 메타데이터를 관리하는 것은 다른 분산 파일 시스템과 비슷하지만, 메타데이터 서버들이 클러스터 형태로 동작하며 동적으로 부하 정도에 따라 메타데이터별로 담당하는 네임스페이스 영역을 조정할 수 있다는 것이 특징이다. 이를 통해 부하가 일부에 집중되는 경우에도 쉽게 대처할 수 있으며 쉽게 메타데이터 서버를 확장할 수 있다. 그뿐만 아니라 다른 분산 파일 시스템과 달리 POSIX와 호환하기 때문에 분산 파일 시스템에 저장된 파일에 접근할 때 로컬 파일 시스템처럼 접근할 수 있다는 것이 장점이다.\n</p>\n<p>REST API도 지원하며 Swift나 Amazon S3의 REST API와도 호환이 가능하다.\n</p>\n<p>Ceph를 주목해야 하는 이유는 Linux 커널 소스(kernel source)에 포함돼 있다는 것이다. 아직 출시된 버전이 그리 높지는 않지만, Linux의 발전과 더불어 미래에 Linux의 주력 파일 시스템이 될 수 있는 가능성이 있다는 것이다. 그리고 POSIX 호환 형태이고 커널 마운트를 지원하는 것도 큰 매력이라 할 수 있다.\n</p>\n<h3>pNFS(Parallel Network File System)\n</h3><p>앞서 설명했듯이 NFS에는 여러 버전이 있다. NFSv4까지의 확장성 문제를 해결하기 위해 NFSv4.1는 pNFS 기능을 도입하였다. 파일 내용과 파일의 메타데이터를 분리해 처리할 수 있도록 했으며, 하나의 파일을 여러 곳에 나눠 분산 저장하는 기능도 제공한다. 클라이언트는 어떤 파일에 대한 메타데이터를 가져와 해당 파일의 위치를 알게 되면, 이후 같은 파일에 접근할 때 파일의 내용을 가지고 있는 서버에 연결할 수 있도록 했다. 이때 여러 서버에 존재하는 파일의 내용을 병렬적으로 읽거나 쓸 수 있다. 그리고 메타데이터를 관리하는 메타데이터 서버도 병목현상이 발생하지 않도록 쉽게 확장할 수 있는 기능을 지원한다.\n</p>\n<p>최근 분산 파일 시스템의 트렌드를 반영하여 NFS가 발전한 것이다. 그래서 pNFS는 기존 NFS의 장점을 계승하면서도 최근 분산 파일 시스템의 장점을 가지고 있다고 할 수 있다. 현재 제한적이지만 pNFS 기능을 지원하는 제품들이 나오고 있다.\n</p>\n<p>pNFS를 주목해야 하는 이유의 하나는 현재 NFS 자체를 Oracle(Sun)이 아닌 IETF(Internet Engineering Task Force)에서 관리하고 있다는 것이다. NFS는 여러 Linux/Unix에서 표준처럼 사용하고 있기 때문에, 여러 벤더에서 이 pNFS를 지원하는 제품을 출시하여 pNFS 사용이 대중화될 수 있다는 것이다.\n</p>\n<h2>결론\n</h2><p>지금까지 여러 분산 파일 시스템에는 고유의 특징이 있으며 비즈니스 요구 사항에 따라 적합한 분산 파일 시스템을 적용해야 한다는 것에 대해 알아보았다. 또한 새롭게 주목받기 시작하고 있는 분산 파일 시스템을 소개함으로써 새로운 트렌드와 참고할 만한 사항들을 설명했다.\n</p>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 클라우드플랫폼개발랩 전성원\n&#9;&#9;2007년부터 분산파일시스템을 개발해오고 있다. 분산 시스템의 미묘함은 또 다른 세계를 보는것 같다. 우리가 절대로 일어나지 않을 것이라고 가정하는 것들이 발생하기 때문이다.\n&#9;&#9;<br>\n&#9;&#9;\n</div></div>"},{"name":"Node.js로 CUBRID를","published":1357877852,"description":"<div><p>NHN Business Platform 글로벌플랫폼개발랩 에센 사그노브, 유성덕, 이재익</p>\n<p>최근, 이벤트 기반의 Non-Blocking I/O 프로그래밍 모델이라는 점과 JavaScript로 서버 프로그램을 작성할 수 있다는 점에서 Node.js가 많은 주목을 받고 있습니다. Node.js는 소규모 비즈니스뿐만 아니라 LinkedIn, Yahoo!, Microsoft와 같은 큰 규모의 인터넷 기업에서도 사용하고 있습니다. Node.js의 또 다른 큰 장점은 NPM(Node Packaged Modules) 형태로 많은 모듈이 제작되고 있다는 점입니다. 현재 <a href=\"http://npmjs.org/\">http://npmjs.org</a> 사이트에 20,000개가 넘는 모듈이 등록돼 있고, 2012년 12월 한 달에만 13,000,000회 이상의 다운로드 수치를 보였습니다.\n</p>\n<p>이 글에서는 2012년 10월에 출시한 node-cubrid를 소개합니다. node-cubrid는 Node.js로 CUBRID를 사용할 수 있도록 한 것입니다. NPM으로 제작됐기 때문에 쉽게 설치할 수 있습니다. node-cubrid는 CUBRID에 연결하고, 질의하기 위한 API를 제공합니다. 기본적인 데이터 조작 API뿐 아니라, 입력 값 포맷을 검증하거나 SQL문을 파라미터화하는 API 또한 개발 편의를 위해 제공하고 있습니다.\n</p>\n<h2>호환성과 의존성\n</h2><p>Node.js와 ADO.NET을 제외한 PHP/PDO, Python, Perl, Ruby, OLEDB, ODBC용 CUBRID 드라이버는 CCI (CUBRID C Interface)에 의존성이 있다. CCI가 Linux와 Windows에서만 사용 가능하므로 이들 라이브러리 또한 Linux와 Windows에서만 사용가능하며 CUBRID 버전에도 종속성을 가지고 있다.\n</p>\n<p>반면 node-cubrid는 CCI에 대한 의존성 없이 순수 JavaScript로만 작성돼 있다. 그래서 Node.js를 실행할 수 있는 모든 환경에서 node-cubrid를 사용할 수 있다는 장점이 있다. 여타의 다른 CUBRID 드라이버와 달리 CUBRID 버전에 맞춰 드라이버 버전을 선택할 필요가 없다.\n</p>\n<h2>설치와 사용\n</h2><p>node-cubrid는 NPM 형태로 제공하기 때문에 다른 Node.js 모듈과 마찬가지로 &lt;예제 1&gt;처럼 npm 명령어로 node-cubrid를 쉽게 설치할 수 있다.\n</p>\n<p><strong>예제 1 node-cubrid 설치\n</strong></p>\n<p>npm install node-cubrid\n</p>\n<p>&lt;예제 1&gt;처럼 node-cubrid를 설치하면 <a href=\"https://npmjs.org/\">https://npmjs.org/</a>에 등록된 최신 버전의 node-cubrid가 설치된다.\n</p>\n<p>설치를 마지면 require() 함수를 이용해 node-cubrid 모듈을 불러올 수 있다.\n</p>\n<p><strong>예제 2 node-cubrid 모듈 추가\n</strong></p>\nvar CUBRID &#61; require(&#39;node-cubrid&#39;);\n\n<p>node-cubrid 모듈은 다음과 같은 함수를 제공한다.\n</p>\n<ul><li>Helpers: 유틸리티 함수들\n</li><li>Result2Array: DB 결과 집합(result set)을 JavaScript 배열(Array)로 변환하는 함수들\n</li><li>createDefaultCUBRIDDemodbConnection(): 로컬 demodb에 대한 연결 객체를 반환하는 함수\n</li><li>createCUBRIDConnection(): CUBRID에 대한 연결 객체를 반환하는 함수\n</li></ul><h2>요청 흐름\n</h2><p>node-cubrid로 SQL을 실행할 때 EVENT_QUERY_DATA_AVAILABLE 이벤트와 EVENT_ERROR 이벤트를 처리해야 한다. 또한 서버에서 응답이 왔을 때 호출될 콜백 함수를 등록해야 한다. 이는 일반적인 Node.js 프로그래밍 패턴과 같다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 node-cubrid 요청 흐름\n</strong></p>\n<p>요청에 대한 결과는 쿼리 결과 집합(Query result set)이나 에러 코드다. CUBRID는 요청을 보낸 클라이언트에 대한 ID를 반환하지 않도록 설계돼 있다. 그렇기 때문에 응답이 올 때 어느 요청에 대한 응답인지 알기 위해서는 요청을 하나씩 보내고 응답을 하나씩 받는 방법을 사용해야 한다. 이는 CUBRID뿐 아니라 많은 다른 DBMS에서도 마찬가지다. 여러 질의를 동시에 처리하려면 커넥션 풀(Connection Pool)을 사용해야 한다.\n</p>\n<h2>node-cubrid 사용법\n</h2><h3>데이터베이스 연결\n</h3><p>CUBRID 서버에 연결하려면 호스트 이름, CUBRID Broker 포트, 사용자 ID, 암호, DB 이름을 파라미터로 전달해 createCUBRIDConnection() 함수를 호출한다.\n</p>\n<p><strong>예제 3 콜백 방식의 DB연결 예제 코드</strong></p>\nvar conn &#61; CUBRID.createCUBRIDConnection(&#39;localhost&#39;, 33000, &#39;dba&#39;, &#39;password&#39;, &#39;demodb&#39;);\n \nconn.connect(function (err) {\n&#9;if (err) {\n&#9;&#9;throw err.message;\n&#9;} else {\n&#9;&#9;console.log(&#39;connection is established&#39;);\n&#9;&#9;conn.close(function () {\n&#9;&#9;&#9;console.log(&#39;connection is closed&#39;);\n&#9;&#9;});\n&#9;}\n});\n\n<p>&lt;예제 3&gt;에서 콜백 패턴을 이용해 CUBRID에 연결하는 방법을 알 수 있다. connect() 함수에 콜백 함수를 넘겨주면 연결이 완료된 후에 콜백 함수가 호출된다. &lt;예제 4&gt;는 같은 기능을 이벤트 기반으로 작성한 것이다.\n</p>\n<p><strong>예제 4 이벤트 방식의 DB연결 예제 코드</strong></p>\nconn.connect();\n \nconn.on(conn.EVENT_ERROR, function (err) {\n&#9;throw err.message;\n});\n \nconn.on(conn.EVENT_CONNECTED, function () {\n&#9;// connection is established\n&#9;conn.close();\n});\n \nconn.on(conn.EVENT_CONNECTION_CLOSED,\nfunction () {\n&#9;// connection is closed\n});\n\n<p>이벤트 기반 코딩 방식을 선호한다면, CUBRID.ORG(<a href=\"http://www.cubrid.org/wiki_apis/entry/cubrid-node-js-api-overview\">http://www.cubrid.org/wiki_apis/entry/cubrid-node-js-api-overview</a>)의 관련 문서를 참조하기 바란다.\n</p>\n<h3>SQL 실행\n</h3><p>연결 후에는 SQL을 실행할 수 있다. node-cubrid에서 SQL과 관련해 제공하는 API는 다음 표와 같다.\n</p>\n<p><strong>표 1 node-cubrid의 SQL 관련 API\n</strong></p>\n<div><table><tbody><tr><td><p><strong>함수</strong></p>\n</td><td><p><strong>설명</strong></p>\n</td></tr><tr><td><p>query(sql, callback);</p>\n</td><td><p>쿼리를 실행하고 데이터 레코드를 반환한다.</p>\n</td></tr><tr><td><p>queryWithParams(sql, arrParamsValues, arrDelimiters, callback);</p>\n</td><td><p>파라미터가 있는 쿼리(parameterized SQL queries)를 실행하고 데이터 레코드를 반환한다.</p>\n</td></tr><tr><td><p>execute(sql, callback);</p>\n</td><td><p>쿼리를 실행하고 데이터 레코드를 반환하지 않는다.</p>\n</td></tr><tr><td><p>executeWithParams(sql, arrParamsValues, arrDelimiters, callback);</p>\n</td><td><p>파라미터가 있는 쿼리를 실행하고 데이터 레코드를 반환하지 않는다.</p>\n</td></tr><tr><td><p>batchExecuteNoQuery(sqls, callback)</p>\n</td><td><p>배치 모드로 쿼리를 실행한다.</p>\n</td></tr></tbody></table></div><p>&lt;표 1&gt;에서 모든 API의 첫 번째 파라미터가 SQL임을 알 수 있다. 이름이 query로 시작하는 API는 데이터 레코드를 반환하고, 이름이 execute로 시작하는 API는 레코드를 반환하지 않는다. 따라서 SELECT 쿼리는 query() 함수를 사용하고, INSERT/UPDATE/DELETE 쿼리는 execute() 함수를 사용하면 된다.\n</p>\n<h3>파라미터가 있는 SQL 실행 \n</h3><p>queryWithParams() 함수나 executeWithParams() 함수를 이용하면 파라미터가 있는 쿼리(parameterized SQL queries)를 실행할 수 있다. 이 두 함수는 SQL 파라미터 &#34;?&#34;를 서버와 통신하기 전에 함수 파라미터로 대체한다.\n</p>\n<p><strong>예제 5 SELECT 구문 실행 예제 코드</strong></p>\nvar code &#61; 15214,\nsql &#61; &#39;SELECT * FROM athlete WHERE code &#61; ?&#39;;\n \nconn.queryWithParams(sql, [code], [], function (err, result, queryHandle) {\n&#9;// check the error first then use the result\n});\n\n<p><strong>예제 6 INSERT 구문 실행 예제 코드</strong></p>\nvar host_year &#61; 2008,\nhost_nation &#61; &#39;China&#39;,\nhost_city &#61; &#39;Beijing&#39;,\nopening_date &#61; &#39;08-08-2008&#39;,\nclosing_date &#61; &#39;08-24-2008&#39;,\nsql &#61; &#39;INSERT INTO olympic (host_year, host_nation, host_city, opening_date, closing_date) VALUES (?, ?, ?, ?, ?)&#39;;\nconn.executeWithParams(sql, [host_year, host_nation, host_city, opening_date, closing_date], [&#34;&#34;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#34;&#39;&#34;], function (err) {\n&#9;// check the error first\n});\n\n\n\n\n<p>여러 개의 레코드를 한 번에 VALUES (...), (...), ..., 형식으로 처리하려면 &lt;예제 7&gt;과 같이 helper 함수를 사용해야 한다.\n</p>\n<p><strong>예제 7 helper 함수를 활용한 INSERT 구문 예제\n</strong></p>\nvar sql &#61; &#39;INSERT INTO olympic (host_year, host_nation, host_city, opening_date, closing_date) VALUES &#39;,\n&#9;partialSQL &#61; &#39;(?, ?, ?, ?, ?)&#39;,\n&#9;data &#61; [{...}, {...}, {...}],\n&#9;values &#61; [];\n&#9; \n&#9;data.forEach(function (r) {\n&#9;&#9;var valuesSQL &#61; CUBRID.Helpers._sqlFormat(\n&#9;&#9;partialSQL,\n&#9;&#9;[r.host_year, r.host_nation, r.host_city, r.opening_date, r.closing_date],\n&#9;&#9;[&#34;&#34;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#34;&#39;&#34;]\n&#9;&#9;);\n&#9;&#9; \n&#9;&#9;values.push(valuesSQL);\n&#9;});\n&#9; \n&#9;sql &#43;&#61; values.join(&#39;,&#39;);\n&#9; \n&#9;conn.execute(sql, function (err) {\n&#9;// check the error first\n});\n\n\n\n<h3>대량의 데이터 가져오기\n</h3><p>대량의 데이터를 조회할 때는 한 번에 필요한 데이터를 가져오는 것이 아니라 반복적으로 fetch() 함수를 호출해 데이터를 조금씩 덜어서 가져와야 한다.\n</p>\n<p><strong>예제 8 fetch() 함수를 호출해 대량의 데이터 얻기\n</strong></p>\nvar sql &#61; &#39;SELECT * FROM participant&#39;;\nconn.query(sql, function (err, result, queryHandle) {\n&#9;// assuming no error is returned\n&#9;// the following outputs 916\n&#9;console.log(CUBRID.Result2Array.TotalRowsCount(result));\n&#9; \n&#9;function outputResults (err, result, queryHandle) {\n&#9;&#9;if (result) {\n&#9;&#9;&#9;// 309 records are in the first results se\n&#9;&#9;&#9;// 315 records are in the second results set\n&#9;&#9;&#9;// 292 records are in the third results set\n&#9;&#9;&#9;console.log(CUBRID.Result2Array\n&#9;&#9;&#9;.RowsArray(result).length);\n&#9;&#9;&#9;// try to fetch more data\n&#9;&#9;&#9;conn.fetch(queryHandle, outputResults);\n&#9;&#9;} else {\n&#9;&#9;&#9;// no more result, close this query handle\n&#9;&#9;&#9;conn.closeQuery(queryHandle,\n&#9;&#9;&#9;function (err) {\n&#9;&#9;&#9;&#9;conn.close(function () {\n&#9;&#9;&#9;&#9;&#9;console.log(&#39;connection closed&#39;);\n&#9;&#9;&#9;&#9;});\n&#9;&#9;&#9;});\n&#9;&#9;}\n&#9;}\n&#9; \n&#9;outputResults(err, result, queryHandle);\n});\n\n\n\n<h3>커넥션 풀 사용하기\n</h3><p>node-cubrid는 자체적인 커넥션 풀(Connection Pool) 기능을 제공하고 있지는 않다. 하지만 generic-pool 모듈(<a href=\"https://github.com/coopernurse/node-pool\">https://github.com/coopernurse/node-pool</a>)을 사용해 커넥션 풀을 사용할 수 있다. generic-pool은 npm으로 설치할 수 있다.\n</p>\n<p><strong>예제 9 npm을 이용한 generic-pool 설치\n</strong></p>\n<p>npm install generic-pool\n</p>\n<p>&lt;예제 10&gt;에서 커넥션 풀을 이용하는 방법을 알 수 있다. create() 함수에 CUBRID에 연결하는 코드와 destroy() 함수에 연결을 종료하는 코드를 삽입한다.\n</p>\n<p><strong>예제 10 connection pool 생성 예제 코드\n</strong></p>\nvar poolModule &#61; require(&#39;generic-pool&#39;);\nvar pool &#61; poolModule.Pool({\n&#9;name : &#39;CUBRID&#39;,\n&#9;// connection은 최대 10개까지 생성합니다.\n&#9;max : 10,\n&#9;// 생성된 connection은 30초 동안 유휴 상태(idle)면 destory됩니다.\n&#9;idleTimeoutMillis : 30000,\n&#9;log : true ,\n&#9;create : function(callback) {\n&#9;&#9;var conn &#61; CUBRID.createCUBRIDConnection(&#39;localhost&#39;, 33000, &#39;dba&#39;, &#39;password&#39;, &#39;demodb&#39;);\n&#9;&#9;conn.connect(function (err) {\n&#9;&#9;&#9;&#9;callback(err, conn);\n&#9;&#9;&#9;});\n&#9;&#9;},\n&#9;&#9;destroy : function(con) {\n&#9;&#9;&#9;conn.close();\n&#9;&#9;}\n});\n\n\n\n\n<p>&lt;예제 11&gt;은 generic-pool 모듈의 acquire() 함수를 이용해 DBMS에 대한 연결 객체를 얻은 후, 해당 객체에 질의를 보내는 예제 코드다. acquire() 함수의 콜백 함수에서 질의를 보내고 query() 함수의 콜백 함수에서 커넥션 풀에 연결을 반환하고 있다.\n</p>\n<p><strong>예제 11 generic-pool의 acquire() 함수 활용 예제 코드\n</strong></p>\npool.acquire(function(err, conn) {\n&#9;if (err) {\n&#9;&#9;// handle error - this is generally the err from your\n&#9;&#9;// factory.create function\n&#9;} else {\n&#9;&#9;conn.query(&#34;select * from foo&#34;, [], function() {\n&#9;&#9;&#9;// return object back to pool\n&#9;&#9;&#9;pool.release(conn);\n&#9;&#9;});\n&#9;}\n});\n\n\n\n<h3>async 모듈과 함께 node-cubrid 사용하기\n</h3><p>처음 Node.js를 경험하는 많은 개발자들은 비동기 처리 방식과 수많은 콜백 함수로 인해 혼란을 겪는다. 이런 개발자들을 위해 많은 흐름 제어(flow control) 모듈이 개발됐다. 그 중에서도 async 모듈은 가장 대중적으로 사용되는 모듈이다. node-cubrid에서 제공하는 ActionQueue 모듈을 사용하면 async 모듈의 waterfall과 같은 기능을 사용할 수 있다.\n</p>\n<p><strong>예제 12 ActionQueue 모듈을 활용한 예제 코드</strong></p>\nCUBRID.ActionQueue.enqueue(\n&#9;[\n&#9;&#9;function (cb) {\n&#9;&#9;&#9;conn.connect(cb);\n&#9;&#9;},\n&#9;&#9; \n&#9;&#9;function (cb) {\n&#9;&#9;&#9;conn.getEngineVersion(cb);\n&#9;&#9;},\n&#9;&#9; \n&#9;&#9;function (engineVersion, cb) {\n&#9;&#9;&#9;console.log(&#39;Engine version is: &#39;\n&#9;&#9;&#9;&#43; engineVersion);\n&#9;&#9;&#9;conn.query(&#39;select * from code&#39;, cb);\n&#9;&#9;},\n&#9;&#9; \n&#9;&#9;function (result, queryHandle, cb) {\n&#9;&#9;&#9;console.log(&#39;Query result rows count: &#39;\n&#9;&#9;&#9;&#43; Result2Array.TotalRowsCount(result));\n&#9;&#9;&#9;console.log(&#39;Query results:&#39;);\n&#9;&#9;&#9;var arr &#61; Result2Array.RowsArray(result);\n&#9;&#9;&#9;for (var k &#61; 0; k &lt; arr.length; k&#43;&#43;) {\n&#9;&#9;&#9;&#9;console.log(arr[k].toString());\n&#9;&#9;&#9;}\n&#9;&#9;&#9;conn.closeQuery(queryHandle, cb);\n&#9;&#9;&#9;console.log(&#39;Query closed.&#39;);\n&#9;&#9;},\n&#9;&#9; \n&#9;&#9;function (cb) {\n&#9;&#9;&#9;conn.close(cb);\n&#9;&#9;&#9;console.log(&#39;Connection closed.&#39;);\n&#9;&#9;}\n&#9;],\n&#9;function (err) {\n&#9;&#9;if (err &#61;&#61; null) {\n&#9;&#9;&#9;console.log(&#39;Program closed.&#39;);\n&#9;&#9;} else {\n&#9;&#9;&#9;throw err.message;\n&#9;&#9;}\n&#9;}\n);\n\n<p>&lt;예제 13&gt;은 &lt;예제 12&gt;와 같은 내용을 async 모듈을 사용해서 작성한 것이다.\n</p>\n<p><strong>예제 13 async 모듈의 waterfall을 활용한 예제 코드\n</strong></p>\nasync.waterfall(\n&#9;[\n&#9;&#9;function (cb) {\n&#9;&#9;&#9;conn.connect(cb);\n&#9;&#9;},\n&#9;&#9; \n&#9;&#9;function (cb) {\n&#9;&#9;&#9;conn.getEngineVersion(cb);\n&#9;&#9;},\n&#9;&#9; \n&#9;&#9;function (engineVersion, cb) {\n&#9;&#9;&#9;console.log(&#39;Engine version is: &#39;\n&#9;&#9;&#9;&#43; engineVersion);\n&#9;&#9;&#9;conn.query(&#39;select * from code&#39;, cb);\n&#9;&#9;},\n&#9;&#9; \n&#9;&#9;function (result, queryHandle, cb) {\n&#9;&#9;&#9;console.log(&#39;Query result rows count: &#39;\n&#9;&#9;&#9;&#43; Result2Array.TotalRowsCount(result));\n&#9;&#9;&#9;console.log(&#39;Query results:&#39;);\n&#9;&#9;&#9;var arr &#61; Result2Array.RowsArray(result);\n&#9;&#9;&#9;for (var k &#61; 0; k &lt; arr.length; k&#43;&#43;) {\n&#9;&#9;&#9;&#9;console.log(arr[k].toString());\n&#9;&#9;&#9;}\n&#9;&#9;&#9;conn.closeQuery(queryHandle, cb);\n&#9;&#9;&#9;console.log(&#39;Query closed.&#39;);\n&#9;&#9;},\n&#9;&#9; \n&#9;&#9;function (cb) {\n&#9;&#9;&#9;conn.close(cb);\n&#9;&#9;&#9;console.log(&#39;Connection closed.&#39;);\n&#9;&#9;}\n&#9;],\n&#9; \n&#9;function (err) {\n&#9;&#9;if (err &#61;&#61; null) {\n&#9;&#9;&#9;console.log(&#39;Program closed.&#39;);\n&#9;&#9;} else {\n&#9;&#9;&#9;throw err.message;\n&#9;&#9;}\n&#9;}\n);\n\n\n\n<h2>마치며\n</h2><p>node-cubrid는 2013년 1월 현재 1.1 버전을 릴리스한 상태다. 다음 버전에서는 개발자 편의성을 위한 기능을 많이 추가하려 한다. 파라미터별로 쿼리에 전달하는 대신 프로퍼티를 가지고 있는 객체를 전달하면 가독성과 개발 편의성이 점 더 높아질 것으로 생각한다. CUBRID 설정을 조회하는 기능과 INSERT/UPDATE/DELTE 구문 실행 후 변경된 레코드 수를 반환하는 기능도 추가할 것이다. ORM(Object Relational Mapping) 개발자를 위해 테이블 스키마 정보를 가져오는 API 또한 제공하려 한다. 또한 다른 CUBRID 드라이버처럼 Connection URL을 사용할 수 있도록 하려 한다. 이 기능을 이용하면 CUBRID Broker 장애 극복(failover)을 위한 대체 호스트 목록을 주거나 쿼리 타임아웃을 설정할 수 있기 때문이다.\n</p>\n<h2>참고자료\n</h2><ul><li>node-cubrid 모듈 github: <a href=\"https://github.com/CUBRID/node-cubrid\">https://github.com/CUBRID/node-cubrid</a>\n&#9;&#9;</li><li>NPM 저장소: <a href=\"https://npmjs.org/\">https://npmjs.org/</a>\n&#9;&#9;</li><li>CUBRID 드라이버: <a href=\"http://www.cubrid.org/wiki_apis\">http://www.cubrid.org/wiki_apis</a>\n&#9;&#9;</li><li>CUBRID Node.js API Overview: <a href=\"http://www.cubrid.org/wiki_apis/entry/cubrid-node-js-api-overview\">http://www.cubrid.org/wiki_apis/entry/cubrid-node-js-api-overview</a>\n&#9;&#9;</li><li>node-pool 모듈github: <a href=\"https://github.com/coopernurse/node-pool\">https://github.com/coopernurse/node-pool</a>\n&#9;&#9;</li><li>aync 모듈 github: <a href=\"https://github.com/caolan/async\">https://github.com/caolan/async</a>\n&#9;&#9;</li><li>CUBRID Q&amp;A: <a href=\"http://www.cubrid.org/questions\">http://www.cubrid.org/questions</a>\n&#9;&#9;</li></ul><p> </p>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 글로벌플래폼개발랩 에센 사그노브\n&#9;&#9;<br>\n&#9;&#9;<br>\n&#9;&#9;<br>\n&#9;&#9;\n</div>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 글로벌플래폼개발랩 유성덕\n&#9;&#9;오픈소스를 이용하여 대용량 로그 분석 시스템을 개발하였으며, 현재는 WorkFlow 엔진을 이용한 새로운 프로젝트를 진행 중입니다. 2012년에 사랑하는 딸이 생겨서 행복한 삶을 영위하고 있습니다.\n&#9;&#9;<br>\n&#9;&#9;\n</div>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NBP 글로벌플래폼개발랩 이재익\n&#9;&#9;글로벌플랫폼개발랩에서 중국개발자들과 로그시스템을 개발하고 있다. 최근 elasticsearch, node.js, iOS 개발에 관심을 가지고 업무에 활용하고 있으며, 여가시간에는 무지함에서 벗어나기위해 독서를 하거나 여행을 하려고 노력 중이다. \n&#9;&#9;<br>\n&#9;&#9;\n</div></div>"},{"name":"Hadoop에서의 실시간 SQL 질의: Impala","published":1357284318,"description":"<div><p>NHN 데이터인프라랩 권동훈</p>\n<p>Impala는 HDFS에 저장돼 있는 데이터를 SQL을 이용해 실시간으로 분석할 수 있는 시스템입니다. MapReduce 프레임워크를 이용하지 않고 분산 질의 엔진을 이용해 분석하기 때문에 빠른 결과를 제공할 수 있습니다. 아직 베타 버전이고 구현되지 않은 중요한 기능들이 있지만 많은 주목을 받고 있는 시스템입니다.\n</p>\n<p>이 글에서는 Impala의 구조와 기능을 알아보고 간략한 성능 테스트를 통해 실시간 대용량 처리에서 Impala가 보여주는 성능을 확인해 보겠습니다.\n</p>\n<h2>Hadoop에서 실시간으로 결과 분석을\n</h2><p>2006년 등장한 Hadoop으로 인해 대용량 데이터 분석 작업은 더 이상 소수의 몇몇 회사나 단체만이 할 수 있는 것이 아니게 되었다. Hadoop은 오픈소스여서 대용량 데이터 분석이 필요한 많은 곳에서 낮은 비용으로 쉽게 Hadoop을 사용할 수 있기 때문이다. 대용량 데이터 분석 작업이 보편적인 기술이 된 것이다.\n</p>\n<p>Hadoop의 핵심은 HDFS(Hadoop Distributed File System)와 MapReduce 프레임워크다. 분산 파일 시스템 형태로 용량을 확장할 수 있는 파일 시스템인 HDFS에 데이터를 저장하고, 이렇게 저장된 데이터를 바탕으로 MapReduce 연산을 실행해 원하는 데이터를 얻어낼 수 있다.\n</p>\n<p>그러나 앉으면 눕고 싶은 것이 사람의 욕심인 만큼, Hadoop 사용자 그룹은 Hadoop의 기능/성능 제약을 극복하고 Hadoop을 더 발전시키려 했다. 불만은 MapReduce 프레임워크를 사용하는 것에 좀 더 집중되었다. MapReduce 프레임워크의 대표적인 단점은 두 가지다.\n</p>\n<ul><li>사용하기에 불편한 점이 많다.\n</li><li>처리가 느리다.\n</li></ul><p>MapReduce 프레임워크의 사용 편의성을 높이기 위해 2008년에 Pig나 Hive같은 플랫폼이 등장했다. Pig와 Hive 모두 Hadoop의 서브 프로젝트다(Hadoop은 여러 플랫폼의 생태계이기도 하다. Hadoop을 기반으로 하는 여러 제품들이 제작되고 있다). Pig와 Hive 모두 하이레벨 언어 형태라는 점에서는 같지만, Pig는 절차적인 형태임에 비해 Hive는 SQL과 유사한 선언적인 언어 형태다. Pig와 Hive의 등장으로 Hadoop 사용자들은 더 편하게 대용량 데이터 분석 작업을 수행할 수 있게 되었다.\n</p>\n<p>하지만 Hive나 Pig는 데이터 조회 인터페이스에 관한 기술이라 대용량 데이터 분석 작업의 속도를 높이지는 않는다. Hive나 Pig 모두 내부적으로는 MapReduce 프레임워크를 사용한다.\n</p>\n<p>그래서 등장한 것이 칼럼 기반 NoSQL인 HBase다. 키-값(Key-Value) 데이터에 대한 빠른 입출력이 가능한 HBase는 Hadoop기반의 시스템에서 실시간으로 데이터 처리가 가능한 환경을 비로소 제공했다.\n</p>\n<p>Hadoop 에코 시스템(eco-System)의 이러한 발전은 Google의 영향을 많이 받았다. HDFS 자체도 Google에서 발표한 GFS(Google File System) 논문을 바탕으로 구현된 것이고, HBase 또한 Google의 BigTable 논문을 바탕으로 제작될 수 있었다. 이러한 영향 관계는 &lt;표 1&gt;에서 볼 수 있다.\n</p>\n<p>이 글에서 소개하는 Cloudera(<a href=\"http://www.cloudera.com\">http://www.cloudera.com</a>)의 <a href=\"https://ccp.cloudera.com/display/IMPALA10BETADOC/Introducing&#43;Cloudera&#43;Impala\">Impala</a> 또한 Google의 영향을 받았다. 2010년에 Google에서 소개한 Dremel 논문을 바탕으로 제작된 것이다. Impala는 Apache 라이선스를 가진 오픈소스며, HDFS에서 동작하는 &#39;즉각적인 실시간 SQL 질의 시스템(interactive/real-time SQL queries system)&#39;이다.\n</p>\n<p>SQL은 많은 개발자들에게 친숙하다는 것뿐만 아니라, 데이터 조작과 조회를 간결하게 표현할 수 있다는 장점이 있다. Impala는 SQL을 지원하면서 실시간 대용량 데이터의 실시간 처리 기능을 제공하기 때문에, BI(Business Intelligence) 시스템으로 활용될 수 있는 잠재력을 가지고 있다. 이런 이유로 몇몇 BI 업체(vendor)들은 이미 Impala를 이용한 BI 시스템 개발을 시작했다고 한다. SQL을 이용해 실시간 분석 결과를 얻을 수 있다는 것은 빅데이터의 전망을 더욱 밝게 하는 것이고, Hadoop의 적용 외연을 넓히는 것이라 할 수 있겠다.\n</p>\n<p><strong>표 1 Google Gives Us A Map(출처: Strata &#43; Hadoop World 2012 Keynote: Beyond Batch - Doug Cutting)\n</strong></p>\n<div><table><tbody><tr><td><p><strong>Google Publication</strong></p>\n</td><td><p><strong>Hadoop</strong></p>\n</td><td><p><strong>특성</strong></p>\n</td></tr><tr><td><p>GFS &amp; MapReduce(2004)</p>\n</td><td><p>HDFS &amp; MapReduce(2006)</p>\n</td><td><ul><li>Batch\n</li><li>Programs</li></ul></td></tr><tr><td><p>Sawzall(2005)</p>\n</td><td><p>Pig &amp; Hive(2008)</p>\n</td><td><ul><li>Batch\n</li><li>Queries</li></ul></td></tr><tr><td><p>BigTable(2006)</p>\n</td><td><p>HBase(2008)</p>\n</td><td><ul><li>Online\n</li><li>key/value</li></ul></td></tr><tr><td><p><strong>Dremel(2010)</strong></p>\n</td><td><p><strong>Impala(2012)</strong></p>\n</td><td><ul><li><strong>Online\n</strong></li><li><strong>Queries</strong></li></ul></td></tr><tr><td><p>Spanner(2012)</p>\n</td><td><p>????</p>\n</td><td><ul><li>Transactions\n</li><li>기타 등등</li></ul></td></tr></tbody></table></div><h2>Cloudera Impala\n</h2><p>Impala를 제작한 Cloudera는 Dremel의 논문 &#34;<a href=\"http://research.google.com/pubs/pub36632.html\">Interactive Analysis of Web-Scale Datasets</a>&#34;을 읽고 나니 Apache와 Hadoop 위에서 실시간, 애드혹(ad-hoc) 질의가 가능할 것 같다는 기술적 영감을 얻었다고 한다.\n</p>\n<p>2012년 10월 Cloudera사는 Impala를 발표하면서 다음과 같이 Impala를 소개했다.\n</p>\n<p><strong>&#34;Real-Time Queries in Apache Hadoop, For Real&#34;\n</strong></p>\n<p>Impala는 인터페이스로 <a href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual\">Hive-SQL</a>을 채택했다. 앞에서 언급했듯이 Hive-SQL은 보편적으로 사용되는 질의 언어인 SQL과 문법적으로 유사하다. 그래서 사용자가 매우 친숙한 방법으로 HDFS에 저장된 데이터에 접근할 수 있다.\n</p>\n<p>Hive-SQL은 Hive의 것을 사용한 것이기 때문에, 동일 데이터에 대해 동일한 방법으로 접근할 수 있다(단, Impala는 모든 Hive-SQL을 지원하는 것은 아니다. Impala에서 사용하는 Hive-SQL을 Hive에서도 이용할 수 있다라고 이해하는 것이 좋다).\n</p>\n<p>Impala와 Hive의 차이는 실시간성 여부다. Hive는 데이터 접근을 위해 MapReduce 프레임워크를 이용하는 반면에, Impala는 응답 시간을 최소한으로 줄이기 위해 고유의 분산 질의 엔진을 사용한다. 이 분산 질의 엔진은 클러스터 내 모든 데이터 노드에 설치되도록 했다.\n</p>\n<p>그래서 Impala와 Hive는 동일 데이터에 대한 응답 시간에 있어서 확연한 성능 차이를 보이고 있다. Cloudera는 Impala의 성능이 좋은 이유로 다음 세 가지를 언급한다.\n</p>\n<ul><li>Impala는 Hive보다 CPU 부하를 줄였고, 줄인 만큼 I/O 대역폭을 이용할 수 있다. 그래서 순수 I/O bound 질의의 경우 Impala는 Hive보다 3~4배 좋은 성능 결과를 보여준다.\n</li><li>질의가 복잡해지면 Hive는 여러 단계의 MapReduce 작업 또는, Reduce-side 조인(JOIN) 작업이 필요하다. 이처럼 MapReduce 프레임워크로 처리하기에 비효율적인 질의(적어도 하나 이상의 JOIN 연산이 들어간 질의)의 경우 Impala가 7~45배 정도 더 좋은 성능을 보인다.\n</li><li>분석할 데이터블록이 파일 캐시되어 있는 상태라면 매우 빠른 성능을 보여주고, 이 경우 Hive보다 20~90배 빠른 성능을 보여준다.\n</li></ul><h3>Real-time in Data Analytics\n</h3><p>Impala 소개에는 실시간(real-time)이란 용어가 매우 강조되어 있다.\n</p>\n<p>그럼 과연 &#34;어느 정도의 시간을 실시간이라 말하는 것일까?&#34;라는 의문을 누구나 한 번쯤 해 볼 만하다. 이 궁금증에 Doug Cutting(Hadoop을 만든 사람<sup>)</sup>과 Cloudera의 수석 아키텍트는 무엇을 실시간이라고 할 수 있는지 각각 다음과 같이 의견을 밝힌바 있다.\n</p>\n<blockquote><p>&#34;끝날 때까지 앉아서 기다릴 수 있다면 실시간이다. 결과를 얻을 때까지 커피를 마시러 가거나, 밤새도록 가동을 시켜 놓아야 한다면 그것은 실시간이 아니다.<br>(It&#39;s when you sit and wait for it to finish, as opposed to going for a cup of coffee or even letting it run overnight. That&#39;s real time)&#34;\n</p>\n</blockquote><blockquote><p>&#34;데이터 분석에서 실시간이란 &#39;기다림 없음&#39;을 추구하는 것을 말한다.<br>(real-time&#39; in data analytics is better framed as &#39;waiting less.)&#34;\n</p>\n</blockquote><p>실시간 판단에 대한 기준을 수치적으로 명확하게 정하는 것은 어렵겠지만, 모니터를 바라보면서 결과가 나오는 것을 기다릴 수 있다면 실시간이라 부를 만하다라고 생각할 수 있겠다.\n</p>\n<h2>Impala 아키텍처\n</h2><p>Impala는 크게 impalad와 impala state store라는 프로세스로 구성돼 있다. \n</p>\n<p>impalad는 분산 질의 엔진 역할을 담당하는 프로세스로, Hadoop 클러스터 내 데이터노드 위에서 질의에 대한 plan 설계와 질의 처리 작업을 한다. 그리고 impala state store 프로세스는 각 데이터노드에서 수행되는 impalad에 대한 메타데이터를 유지하는 역할을 담당한다. impalad 프로세스가 클러스터 내에 추가 또는 제거될 때, impala state store 프로세스를 통해 메타데이터가 업데이트된다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 1 Impala high-level architectural view(원본 출처: <a href=\"http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/\">http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/</a>)\n</strong></p>\n<h3>Data locality tracking and Direct reads\n</h3><p>Impala는 기존 Hadoop의 전통적인 분석 프레임워크인 MapReduce 프레임워크대신 impalad 프로세스가 클러스터 내 모든 데이터노드 위에서 질의를 처리하도록 했다. 이와 같은 구성에서 Impala가 얻으려는 이점 중 하나가 바로 data locality와 direct read다. 즉 자신이 속한 데이터노드에 존재하는 데이터 블록만을 처리 대상으로, 그리고 해당 데이터는 로컬 디렉터리에서 직접 읽겠다는 것이다. 이를 통해 네트워크 부하를 최소화했다. 또한 파일 캐시의 효과를 누릴 수 있는 기회가 주어지기도 한다.\n</p>\n<h3>Scale Out\n</h3><p>Hadoop 클러스터와 같이 수평적 확장이 가능하다. 일반적으로 클러스터가 수평 확장을 하면 Impala도 같이 확장되면 된다. 즉 데이터노드가 추가될 때 impalad 프로세스를 해당 서버에서 실행하기만 하면 자연스럽게 확장된다(impala state store을 통해 impalad 추가에 따른 메타정보가 업데이트될 것이다). 이는 MPP(Massively Parallel Processing) 기반의 데이터베이스와 매우 유사한 모습이다.\n</p>\n<h3>Failover\n</h3><p>Impala는 Hive와 HBase에 저장되어 있는 데이터를 분석한다. 그리고 Hive와 HBase가 사용하는 HDFS는 Replication을 통해 어느 정도의 failover를 제공한다. 그래서 Impala는 데이터 블록의 replica가 존재하고, 최소 한 개 이상의 impalad 프로세스가 존재한다면 질의 수행이 가능하다.\n</p>\n<h3>SPOF(Single Point of Failure)\n</h3><p>HDFS를 저장매체로 이용하는 시스템의 가장 큰 고민 중 하나가 바로 네임노드가 SPOF란 점이다. 이를 방지하기 위한 솔루션이 나오고 있지만 근본적으로 해결하기는 어렵다. Impala에서도 역시 네임노드가 SPOF이다. 데이터블록의 위치를 알 수 없으면 질의 수행도 불가능해지기 때문이다.\n</p>\n<h3>질의 수행 절차\n</h3><p>Impala에서 질의가 수행되는 절차를 간단하게 정리하면 다음과 같다.\n</p>\n<ol><li>사용자는 클러스터 내 특정 impalad를 선택해 impala shell, ODBC 등을 이용해 질의를 등록한다.\n</li><li><div>사용자로부터 질의를 받은 impalad는 다음과 같은 선행 작업을 수행한다.\n</div><ol><li>Hive metastore에서 테이블 스키마를 가져와 질의문의 적합성을 판단한다.\n</li><li>HDFS 네임노드에서 질의 수행에 필요한 데이터 블록과 각각의 위치 정보를 수집한다.\n</li><li>최근에 업데이트된 Impala 메타데이터를 기반으로 클러스터 내 모든 impalad에게 질의 수행에 필요한 정보들을 전파한다.\n</li><li>질의와 메타데이터를 전달받은 모든 impalad는 각자 처리할 데이터 블록을 로컬 디렉터리에서 읽어와 질의 처리를 수행한다.\n</li><li>모든 impalad에서 작업이 완료되면 사용자로부터 질의를 받았던 impalad는 결과를 취합해 사용자에게 전달한다.\n</li></ol></li></ol><h2>Impala가 지원하는 Hive-SQL\n</h2><p>Impala는 모든 Hive-SQL을 지원하는 것은 아니다. 일부 Hive-SQL만 지원하기 때문에 어떤 구문이 지원되는지 확인해 볼 필요가 있다.\n</p>\n<ul><li>SELECT QUERY: Impala에서는 Hive-SQL의 SELECT 관련 구문 대부분을 지원하고 있다.\n</li><li><div>Data Definition Language: Impala에서는 테이블을 생성하거나 변경하지 못하고 아래와 같이 데이터베이스, 테이블 스키마 조회만 가능하다. 테이블 생성 및 변경은 Hive를 통해서만 가능하다.\n</div><ul><li>SHOW TABLES\n</li><li>SHOW DATABASES\n</li><li>SHOW SCHEMAS\n</li><li>DESCRIBE TABLE\n</li><li>USE DATABASE\n</li></ul></li><li><div>Data Manipulation: Impala는 생성되어 있는 테이블과 파티션에 데이터 추가 기능만을 제공한다.\n</div><ul><li>INSERT INTO\n</li><li>INSERT OVERWRITE\n</li></ul></li><li><div>Unsupported Language Elements: Impala에서는 다음과 같이 아직 지원하지 않는 Hive-SQL이 많이 있다. 사용하기 전에 레퍼런스(<a href=\"https://ccp.cloudera.com/display/IMPALA10BETADOC/Language&#43;Reference\">https://ccp.cloudera.com/display/IMPALA10BETADOC/Language&#43;Reference</a>)를 통해 확인해야 한다.\n</div><ul><li>Data Definition Language (DDL) such as CREATE, ALTER, DROP\n</li><li>Non-scalar data types: maps, arrays, structs\n</li><li>LOAD DATA to load raw files\n</li><li>Extensibility mechanisms such as TRANSFORM, custom User Defined Functions (UDFs), custom file formats, custom SerDes\n</li><li>XML and JSON functions\n</li><li>User Defined Aggregate Functions (UDAFs)\n</li><li>User Defined Table Generating Functions (UDTFs)\n</li><li>Lateral Views\n</li></ul></li></ul><h2>Data Model\n</h2><p>현재 베타 버전인 Impala에서는 텍스트 파일과 Hadoop sequence file만을 입력 포맷으로 지원하고 있다. 추후 Snappy, Gzip, Bzip과 같은 압축 파일 포맷도 지원한다고 한다. \n</p>\n<p>그러나 최대 관심사는 바로 column file format인 Trevni의 지원이다. Impala에서 Trevni 지원이 중요한 관심사인 이유는 Trevni 지원으로 지금보다 더 나은 성능을 제공해 줄 수 있기 때문이다. 아직 Trevni는 개발 진행 중이기 때문에, Dremel 논문에서 언급된 column file format 내용을 잠시 소개하겠다.\n</p>\n<blockquote><p><strong>Trevni<br></strong>Trevni는 Doug Cutting이 현재 진행 중인 프로젝트로, rows와 columns로 이뤄진 테이블 레코드를 기존의 row-major format이 아닌 column-major format으로 저장하는 파일 포맷이다. Trevni에 관한 자세한 내용은 <a href=\"http://avro.apache.org/docs/current/trevni/spec.html\">http://avro.apache.org/docs/current/trevni/spec.html</a>를 참조한다.\n</p>\n</blockquote><p>Dremel 논문에서는 성능에 영향을 주는 요소 중 하나로 칼럼 파일 포맷(Column File Format)을 말하고 있다. 칼럼 파일 포맷으로 가장 크게 이득을 보는 부분이 바로 디스크 I/O다. 칼럼 파일 포맷은 하나의 레코드를 각각의 칼럼으로 분할해 쓰기 때문에, 레코드에서 일부 칼럼만을 조회할 때 더 큰 효과를 본다. 기존 로우 단위 저장 방식으로는 하나의 칼럼을 보거나 전체 칼럼을 보나 동일한 디스크 I/O가 발생할 수 있지만, 칼럼 파일 포맷에서는 필요한 칼럼 접근 시에만 디스크 I/O가 일어나기에 더 효율적으로 디스크 I/O를 사용할 수 있다는 장점이 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 2 로우 단위 저장과 칼럼 단위 기반의 비교 (출처: Dremel: Interactive Analysis of Web-Scale Datasets)\n</strong></p>\n<p>Dremel에서 칼럼 파일 포맷에 관련해 수행한 두 가지 테스트 결과를 보면 칼럼 파일 포맷이 성능에 기여하는 정도를 가늠해 볼 수 있다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 3 칼럼 단위 저장과 로우 단위 저장의 성능 비교  (출처: Dremel: Interactive Analysis of Web-Scale Datasets)\n</strong></p>\n<p>&lt;그림 3&gt;에서 (a), (b), (c)는 칼럼 파일 포맷에서 랜덤하게 선택된 칼럼의 개수에 따른 수행 시간을 보여주고 있고, (d), (e)는 기존 레코드(record)를 읽는 수행 시간을 보여주고 있다. 테스트 결과를 보면 칼럼 파일 포맷의 수행 시간이 빠르다. 특히 적은 수의 칼럼을 접근할 때 수행 시간의 차이는 더 벌어진다. 기존 방법으로 레코드를 읽을 때는 하나의 칼럼에 접근해도 항상 전체를 읽는 것과 같은 최악의 수행 시간을 보여주지만, 칼럼 파일 포맷(a, b, c)은 선택된 칼럼 개수가 적을수록 더 좋은 성능을 보여준다.\n</p>\n<p>\n&#9;</p>\n<p><strong>그림 4 칼럼 단위 저장과 로우 단위 저장에서 MapReduce를수행 했을 때와 Dremel에 대한 성능 비교 (300nodes, 85 billion records) (출처: Dremel: Interactive Analysis of Web-Scale Datasets)\n</strong></p>\n<p>&lt;그림 4&gt;는 MapReduce 작업을 칼럼 파일 포맷 데이터로 처리하는 경우와 그렇지 않은 경우에 따른 수행 시간을 보여준다(MapReduce와 Dremel과의 비교 테스트지만 그 이전에 칼럼 파일 포맷을 MapReduce에 적용/미적용한 결과만을 보도록 하자). 이처럼 칼럼 파일 포맷은 디스크 I/O를 줄이는 방법으로 상당한 성능 향상을 보여주고 있다.\n</p>\n<p>물론 위의 내용과 실험 결과는 Dremel에서 구현된 칼럼 파일 포맷에 대한 것이기에 Impala에 적용될 Trevni의 결과는 이와 다를 수 있다. 그렇지만, Trevni도 Dremel에서 보여준 칼럼 파일 포맷과 같은 목표로 개발되고 있기에 위 테스트와 비슷한 결과를 보여줄 것으로 기대할 수 있다.\n</p>\n<h2>Impala 설치, 설정, 가동\n</h2><h3>설치\n</h3><p>Impala을 설치하려면 기본적으로 아래와 같은 소프트웨어가 필수적으로 설치돼 있어야 한다. Impala 설치 방법에 관한 자세한 정보는 &#34;<a href=\"https://ccp.cloudera.com/display/IMPALA10BETADOC/Installing&#43;and&#43;Using&#43;Cloudera&#43;Impala\">Installing and Using Cloudera Impala</a>&#34; 문서에서 얻을 수 있다.\n</p>\n<ul><li>Red Hat Enterprise Linux(RHEL)/CentOS 6.2(64bit) 이상\n</li><li>Hadoop 2.0\n</li><li>Hive\n</li><li>MySQL\n</li></ul><p>MySQL은 Hive metastore로 사용하기 위해서 필수적이다. Hive에서는 metastore으로 사용할 수 있는 다양한 데이터베이스를 지원하고 있다. 하지만 Impala와 Hive가 연동되기 위해서는 현재는 MySQL로 연동되어야 한다. Hive metastore에 설치에 관한 자세한 내용은 &#34;<a href=\"https://ccp.cloudera.com/display/CDH4DOC/Hive&#43;Installation\">Configuring Impala for Performance</a>&#34; 문서를 참조한다.\n</p>\n<p>만약 HBase와의 연동이 필요하다면 HBase설치도 필요하다. 여기서는 각 소프트웨어의 자세한 설치 방법은 생략하겠다.\n</p>\n<p>필요한 소프트웨어가 모두 설치됐다면 Impala 패키지를 클러스터 내 모든 데이터노드에 설치한다. 그리고 클라이언트 호스트에는 impala shell을 설치한다.\n</p>\n<h3>설정\n</h3><p>impalad가 로컬 디렉터리에서 HDFS의 파일 블록(file block)에 직접 접근하기 위해서, 그리고 locality tracking을 위해 Hadoop의 core-site.xml 파일과 hdfs-site.xml 파일에 몇 가지를 설정해야 한다. 이 부분은 Impala의 성능에 매우 중요한 설정이니 잊지 않고 추가해야 한다. 변경 후에는 HDFS를 재부팅해야 한다. 더 자세한 내용은 &#34;<a href=\"https://ccp.cloudera.com/display/IMPALA10BETADOC/Configuring&#43;Impala&#43;for&#43;Performance\">Configuring Impala for Performance</a>&#34; 문서를 참조한다.\n</p>\n<h3>가동\n</h3><p>현재 Impala에서는 테이블 생성 및 데이터 로딩이 지원되지 않기 때문에 Impala를 실행하기 전에 Hive Client를 통한 테이블 생성 및 데이터 로딩이 선행 작업으로 이뤄져야 한다. 만약 HBase에 존재하거나 새롭게 생성될 테이블 분석이 필요하다면 Hive를 통해 extern table로 재정의해 사용한다. 더 자세한 내용은 &#34;<a href=\"https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration\">Hive HBase Integration</a>&#34; 문서를 참조한다.\n</p>\n<p>Impala에 질의를 입력하는 방법에는 impala shell이나 Cloudera Beeswaw, ODBC를 통하는 방법이 있다. <a href=\"https://ccp.cloudera.com/display/CDHDOC/Beeswax\">Beeswax</a>는 사용자가 쉽게 Hive를 이용하도록 도와주는 애플리케이션이다. 여기서는 impala shell을 이용한 질의 방법을 예로 들어보겠다.\n</p>\n$sudo –u impala impala-shell\nWelcome to the Impala shell. Press TAB twice to see a list of available commands.\n \nCopyright (c) 2012 Cloudera, Inc. All rights reserved.\n(Build version: Impala v0.1 (1fafe67) built on Mon Oct 22 13:06:45 PDT 2012)\n[Not connected] &gt; connect impalad-host:21000\n[impalad-host:21000] &gt; show tables\ncustom_url\n[impalad-host:21000] &gt; select sum(pv) from custom_url group by url limit 50\n20390\n34001\n3049203\n[impalad-host:21000] &gt;\n\n<p>질의 입력에 앞서 클러스터 내 impalad 중에서 메인 서버가 될 impalad를 하나 선택해 접속한다. 접속이 완료되면 원하는 질의를 입력해 결과를 확인해 보자.\n</p>\n<h2>Impala 기능/성능 테스트 \n</h2><p>아직 Impala가 베타 버전이고 해결되지 않은 문제들이 있지만, 사용 가능한 범위 내에서 어느 정도의 성능을 보여주는지 간단하게 테스트해 보았다.\n</p>\n<p>사용한 장비와 설치된 소프트웨어 버전은 &lt;표 2&gt;와 같고 Hadoop 클러스터는 Namenode/JobTracker 1대, Data/Task node는 3~5대, 그리고 commander 1대로 구성했다. 그리고 HDFS replication은 &#34;2&#34;로 설정했다. 노드의 Map/Reduce capacity는 각각 &#34;2&#34;다.\n</p>\n<p>테스트를 위한 데이터는 14개의 칼럼 데이터를 가진 약 13억 개의 레코드며, 크기가 약 65GB 정도다.\n</p>\n<p><strong>표 2 하드웨어 및 소프트웨어 버전\n</strong></p>\n<div><table><tbody><tr><td> </td><td><p><strong>구분</strong></p>\n</td><td><p><strong>정보</strong></p>\n</td></tr><tr><td><p>장비</p>\n</td><td><p>CPU</p>\n</td><td><p>Intel Xeon 2.00GHz</p>\n</td></tr><tr><td><p>Memory</p>\n</td><td><p>16GB</p>\n</td></tr><tr><td><p>소프트웨어</p>\n</td><td><p>OS</p>\n</td><td><p>CentOS release 6.3(Final)</p>\n</td></tr><tr><td><p>Hadoop</p>\n</td><td><p>2.0.0-cdh4.1.2</p>\n</td></tr><tr><td><p>HBase</p>\n</td><td><p>0.92.1-cdh4.1.2</p>\n</td></tr><tr><td><p>Hive</p>\n</td><td><p>0.9.0-cdh4.1.2</p>\n</td></tr><tr><td><p>Impala</p>\n</td><td><p>0.1.0-beta</p>\n</td></tr></tbody></table></div><p>테스트에 사용한 테이블은 15개의 칼럼으로 이뤄진 단순한 형태며, 질의는 SQL에서 많이 사용하는 SELECT, FROM,. GROUPBY, ORDERBY, LIMIT로 구성했다.\n</p>\n<p><strong>예제 2 테스트 질의\n</strong></p>\nselect …. from xxx WHERE …. group by sr, url order by sumvalue desc limit 50\n\n<h3>테스트 수행 결과\n</h3><p>테스트는 3대와 5대의 클러스터의 규모에서 동일한 테이블에 동일한 질의를 Impala와 Hive를 통해서 수행했고, 각각의 평균 응답시간을 측정했다.\n</p>\n<p><strong>표 3 클러스터 규모 별 Impala, Hive에서 동일 질의에 대한 수행 시간 비교\n</strong></p>\n<div><table><tbody><tr><td> </td><td><p><strong>Impala</strong></p>\n</td><td><p><strong>Hive</strong></p>\n</td><td><p><strong>Hive/Impala</strong></p>\n</td></tr><tr><td><p>3 노드</p>\n</td><td><p>265s</p>\n</td><td><p>3,688s</p>\n</td><td><p>13.96</p>\n</td></tr><tr><td><p>5 노드</p>\n</td><td><p>187s</p>\n</td><td><p>2,377s</p>\n</td><td><p>13.71</p>\n</td></tr></tbody></table></div><p>앞에서 소개했듯이 Impala는 MapReduce를 이용한 분석 작업보다 월등하게 뛰어난 성능을 보여준다. 그리고 클러스터 규모가 커짐에 따라 선형적으로 더 나은 응답 시간을 보여주고 있다(클러스터 확장 후 rebalance를 통해 데이터 블록을 균등하게 분산 배치 후 테스트했다).\n</p>\n<p>\n&#9;&#9;&#9;</p>\n<p><strong>그림 5 클러스터 규모에 따른 Impala 응답 속도\n</strong></p>\n<p>추가로 현재 많이 이용하고 있는 상용 데이터베이스를 대상으로도 테스트해 봤다. Impala와 MPP란 공통분모를 가지고 있는 칼럼 기반의 상용 데이터베이스인 Infobright, infiniDB, 그리고 Vertica에서 동일한 데이터와 질의로 테스트했다. Infobright, infiniDB는 오픈소스, Vertica는 커뮤니티 에디션 버전을 이용했다. 이 3개의 데이터베이스에 대한 테스트는 1개의 서버에서 수행했다.\n</p>\n<p><strong>표 4 칼럼 기반의 상용 데이터베이스 수행 속도\n</strong></p>\n<div><table><tbody><tr><td><p><strong>데이터베이스</strong></p>\n</td><td><p><strong>수행 시간</strong></p>\n</td></tr><tr><td><p>Infobright</p>\n</td><td><p>200s</p>\n</td></tr><tr><td><p>infiniDB</p>\n</td><td><p>32s</p>\n</td></tr><tr><td><p>Vertica</p>\n</td><td><p>15s</p>\n</td></tr></tbody></table></div><p>&lt;표 4&gt;의 테스트 결과에서 알 수 있듯이, 상용 엔터프라이즈 제품인 Infobright, infiniDB, Vertica가 Impala보다는 훨씬 더 좋은 수행 결과를 내고 있다. Impala는 아직 개발 초기 단계여서 구조적, 기술적으로 미흡한 면이 있을 수 있기 때문이다.\n</p>\n<p>가장 성능이 좋은 Vertica의 경우 3대 서버로 확장했을 때 &lt;표 4&gt;의 자료보다 30% 정도 더 나은 성능을 보였다. 하지만 상용 제품인 만큼 2대 이상의 클러스터로 구성하려면 높은 비용을 지불해야 한다는 것이 단점이라 할 수 있다.\n</p>\n<h2>마치며\n</h2><p>Impala가 세상에 소개된 지 한 달 정도 밖에 되지 않았다. 아직 베타 버전이라 많은 자료나 데이터가 없는 상황이며 지원하는 파일 포맷도 한정적이다. JOIN 연산 시 서버 메인 메모리보다 큰 데이터라 할지라도 in-memory 처리를 해 OOM(Out Of Memory) 발생과 같은 위험 요소를 가지고 있는 등 기술적 한계가 있지만, 2013년 1/4분기로 계획 된 production release에는 Trevni 지원 등 많은 부분이 개선될 것으로 보인다.\n</p>\n<p>또한 이와 별개로, Cloudera와 같이 Hadoop을 이용해 사업을 하는 MapR은 본사 개발자들을 주축으로 Impala와 같이 Dremel 논문 기반의 시스템인 &#34;<a href=\"http://wiki.apache.org/incubator/DrillProposal\">Drill</a>&#34;을 Apache incubator에 제안했다. 말 그대로 아직 Proposal 상태이긴 하지만, MapR 개발자들이 주축으로 이뤄진 프로젝트라 시작된다면 빠르게 진행되지 않을까 기대한다.\n</p>\n<p><strong></strong></p>\n<div>\n&#9;<div>\n&#9;&#9;\n&#9;</div>\n&#9;&#9;\n&#9;&#9;NHN 데이터인프라랩 권동훈\n&#9;&#9;2008년부터 데이터인프라랩에서 대용량 데이터 저장 및 분석 시스템을 개발 및 성능향상 작업을 해왔다. 현재는 대용량 실시간 스트림 분석 분야에 관심을 가지고 있으며, 이와 관련해서 다양한 시도를 해보고 있다. \n                <br>\n&#9;&#9;\n</div></div>"},{"name":"NHN 개발자 블로그 hello world가 1주년을 맞아 이벤트를 진행합니다.","published":1356595348,"description":"<div><p></p>\n<p></p>\n<p><b>hello world Top 10 </b></p>\n<p><b>1.&#9;<a href=\"http://helloworld.naver.com/helloworld/59361\">브라우저는 어떻게 동작하는가</a></b></p>\n<p><b>2.&#9;<a href=\"http://helloworld.naver.com/helloworld/24942\">OAuth와 춤을</a></b></p>\n<p><b>3.&#9;<a href=\"http://helloworld.naver.com/helloworld/111111\">3G 모바일 네트워크의 이해</a></b></p>\n<p><b>4.&#9;<a href=\"http://helloworld.naver.com/helloworld/81480\">Hello World 블로그 반응형 웹 개편</a></b></p>\n<p><b>5.&#9;<a href=\"http://helloworld.naver.com/helloworld/162498\">SSD는 소프트웨어 아키텍처를 어떻게 바꾸고 있는가?</a></b></p>\n<p><b>6.&#9;<a href=\"http://helloworld.naver.com/helloworld/8180\">PhoneGap을 이용한 앱 개발</a></b></p>\n<p><b>7.&#9;<a href=\"http://helloworld.naver.com/helloworld/19187\">한글 인코딩의 이해 1편</a></b></p>\n<p><b>8.&#9;<a href=\"http://helloworld.naver.com/helloworld/8794\">FFmpeg을 이용한 Android 동영상 플레이어 개발</a></b></p>\n<p><b>9.&#9;<a href=\"http://helloworld.naver.com/helloworld/47667\">TCP/IP 네트워크 스택 이해하기</a></b></p>\n<p><b>10.&#9;<a href=\"http://helloworld.naver.com/helloworld/29533\">빅데이터를 위한 플랫폼</a></b></p>\n<p><br></p>\n<p><b>•&#9;이벤트기간: 2012년 12월 27일 ~2013년 1월 25일</b></p>\n<p><b>•&#9;당첨자 발표:  2013년 1월 30일, HELLO WORLD 블로그</b></p>\n<p><b>•&#9;참여방법: </b></p>\n<p><b>① 자신이 자주 사용하는 SNS에서 HELLO WORLD와 친구인지 확인해주세요. </b></p>\n<p><b>    아직 친구가 아니라면, 이번 기회에 친구(페북은&#39; 좋아요&#39;)가 되어보세요.</b></p>\n<p>     - ME2DAY: http://me2day.net/helloworld_nhn/</p>\n<p>     - FACEBOOK: https://www.facebook.com/pages/Helloworld_nhn/235817773158003</p>\n<p>     - TWITTER: http://twitter.com/helloworld_nhn/</p>\n<p><b><br></b></p>\n<p><b>② 위의 TOP10 콘텐츠 중 가장 마음에 드는 콘텐츠 번호와 간략한 이유를 덧글로 달아주세요.</b></p>\n<p><b>•&#9;경품: </b>리얼포스 키보드(1명), 로지텍 트리플파이 이어폰 (1명), 삼성 SSD 128GB(2명), </p>\n<p>                    벨킨 백팩(2명), 레고 테크닉 9393 (2명), 폴프랭크 노트북 파우치 (2명)</p>\n<div><br></div><p></p>\n<p>\n</p></div>"},{"name":"웹페이지 성능측정 도구 NSPEED를 소개합니다.","published":1356332752,"description":"<div class=\"xe_content\"><p style=\"padding: 0px; \"><span style=\"font-family: 나눔고딕, NanumGothic, sans-serif; \">NHN 개발자들이 웹페이지 속도측정 도구로 사용 중인 NSPEED가&nbsp;</span>외부 개발자분들도 사용할 수 있도록&nbsp;<span style=\"font-family: 나눔고딕, NanumGothic, sans-serif; \">지난&nbsp;</span><span style=\"line-height: 18px; \">12월20일에&nbsp;</span>공개되었습니다.&nbsp;웹페이지 성능측정이 필요한 Front-End 개발자 분들의 많은 사용을 부탁드립니다.</p>\n<p style=\"padding: 0px; \"><strong style=\"font-size: 10pt; background-color: rgb(255, 255, 255); \">NSPEED Public</strong><span style=\"font-family: 나눔고딕; font-size: 10pt; line-height: 19px; background-color: rgb(255, 255, 255); \">:&nbsp;</span><a href=\"http://nspeed.naver.com/\" target=\"_blank\" style=\"font-size: 10pt; background-color: rgb(255, 255, 255); \">http://nspeed.naver.com</a></p>\n<span style=\"background-color: rgb(255, 255, 255); line-height: 19px; font-family: 나눔고딕; \"></span><p style=\"padding: 0px; font-size: 10pt; background-color: rgb(255, 255, 255); line-height: 19px; font-family: 나눔고딕; \"><strong style=\"font-size: 10pt; \">NSPEED</strong><strong>&nbsp;개발자센터</strong>&nbsp;:&nbsp;<a href=\"http://dev.naver.com/projects/nspeed\" target=\"_blank\">http://dev.naver.com/projects/nspeed</a></p>\n<p style=\"padding: 0px; font-size: 10pt; background-color: rgb(255, 255, 255); line-height: 19px; font-family: 나눔고딕; \"><br /></p>\n<p style=\"padding: 0px; \">&nbsp;<strong><span style=\"font-family: 나눔고딕, NanumGothic, sans-serif; font-size: 12pt; \">[주요기능]</span></strong></p>\n<p style=\"padding: 0px; \"><span style=\"font-family: 나눔고딕, NanumGothic, sans-serif; \">&nbsp;&nbsp; - profile 기반의 반복 테스트 지원<br />&nbsp;&nbsp; - 로그인 사용자의 테스트 내역 보호 / 테스트 결과 페이지의 URL 공유<br />&nbsp;&nbsp; - 국내 사용자 웹 환경분포에 가까운한 브라우저 / 네트워크 성능의 재현<br />&nbsp;&nbsp; - 모바일 웹 성능을 네트워크 단에서 측정하여 단말 성능 부족으로 인한 왜곡 최소화<br />&nbsp;&nbsp; - 모바일 waterfall chart 재현<br />&nbsp;&nbsp; - filmstrip 및 시각성능의 측정</span></p>\n<p style=\"padding: 0px; \">&nbsp;<span style=\"font-family: 나눔고딕, NanumGothic, sans-serif; \">&nbsp;&nbsp;&nbsp;</span>&nbsp;&nbsp;</p>\n<p style=\"padding: 0px; \">&nbsp;<strong><span style=\"font-family: 나눔고딕, NanumGothic, sans-serif; font-size: 12pt; \">[스크린샷]</span></strong></p>\n<p style=\"padding: 0px; \">&nbsp;- 측정결과 조회 화면</p>\n<p style=\"padding: 0px; \"><img src=\"http://helloworld.naver.com/files/attach/images/61/357/236/321f61f0ea0b65b55ec0d6a42e077109.png\" alt=\"nhn.png\" class=\"iePngFix\" width=\"777\" height=\"512\" style=\"\" />\n</p>\n<p style=\"padding: 0px; \">&nbsp;- 측정결과 Waterfall&nbsp;화면</p>\n<p style=\"padding: 0px; \">&nbsp;</p>\n<p style=\"padding: 0px; \"><img src=\"http://helloworld.naver.com/files/attach/images/61/357/236/5789f7f47b46d7c781b5d1eecbd2efd4.png\" alt=\"nhn-1.png\" class=\"iePngFix\" width=\"808\" height=\"741\" style=\"\" />\n</p>\n<p style=\"padding: 0px; \">&nbsp;</p>\n<p style=\"padding: 0px; \">&nbsp;- 측정결과 filmstrip 화면</p>\n<p style=\"padding: 0px; \"><img src=\"http://helloworld.naver.com/files/attach/images/61/357/236/a858f6c442d55f738a606b94d9aecbf9.png\" alt=\"nhn-2.png\" class=\"iePngFix\" width=\"792\" height=\"251\" style=\"\" />\n</p>\n<p style=\"padding: 0px; \">&nbsp;</p>\n<p style=\"padding: 0px; \">&nbsp;</p>\n<p style=\"padding: 0px; \"><br /></p></div>"}]